{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de827958-8584-401f-9d62-1c3ecb4de85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformers import AdamW\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9715e073-3876-4b8a-8d27-9987e232a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('filtered_30_filled_money.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94099074-a4c5-4800-877c-2d657cd73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bd270e-abd8-44ab-a486-48469d26853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f5153d-187c-494f-bc74-1194a8f7c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates = {'USD': 1, 'KRW': 0.00078, 'EUR': 1.18, 'JPY': 0.0091}\n",
    "\n",
    "# usd기준해서 금액 통일함 \n",
    "data['converted_price'] = data.apply(lambda x: x['견적단가'] * exchange_rates[x['견적화폐']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b45129-3e52-490c-a953-21ef3b1756d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USD' 'KRW' 'EUR' 'JPY'] 0\n"
     ]
    }
   ],
   "source": [
    "print(data['견적화폐'].unique(), data['견적화폐'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c8df14-38bf-4da4-9c92-3f8a5305c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_ohe = OneHotEncoder(sparse_output=False) \n",
    "currency_encoded = currency_ohe.fit_transform(data[['견적화폐']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4655b8ab-ae1b-4280-b44b-1d0d2ae15695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "machinery_label_encoder = LabelEncoder()\n",
    "y_machinery= machinery_label_encoder.fit_transform(data['Machinery'])\n",
    "\n",
    "assembly_label_encoder = LabelEncoder()\n",
    "y_assembly = assembly_label_encoder.fit_transform(data['Assembly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8522452-bdfc-4c8a-9027-d460b64428bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_text shape: (13882,)\n",
      "currency_encoded shape: (13882, 4)\n",
      "converted_price shape: (13882,)\n",
      "X shape after concatenation: (13882, 6)\n",
      "X_train size: (10029, 6)\n",
      "X_val size: (1770, 6)\n",
      "X_test size: (2083, 6)\n"
     ]
    }
   ],
   "source": [
    "# train_test split 을 위해 하나로 모으고, 분할하고 다시 텍스트랑 추가피쳐로 분리해줄거임 \n",
    "\n",
    "# 1. 텍스트 + 추가 피처 결합\n",
    "X = np.concatenate([\n",
    "    data['combined_text'].values.reshape(-1, 1),  # 2차원 배열로 바꿔서 결합해줌 \n",
    "    currency_encoded, \n",
    "    data['converted_price'].values.reshape(-1, 1)  # 통일한단가\n",
    "], axis=1)\n",
    "\n",
    "X_train_val, X_test, y_train_val_machinery, y_test_machinery, y_train_val_assembly, y_test_assembly = train_test_split(\n",
    "    X, y_machinery, y_assembly, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_assembly)  # stratify는 주로 메인 레이블 기준으로 설정\n",
    "\n",
    "X_train, X_val, y_train_machinery, y_val_machinery, y_train_assembly, y_val_assembly = train_test_split(\n",
    "    X_train_val, y_train_val_machinery, y_train_val_assembly, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_train_val_assembly)  # 다시 stratify 기준으로 설정\n",
    "\n",
    "# 크기 확인\n",
    "print(f\"combined_text shape: {data['combined_text'].shape}\")\n",
    "print(f\"currency_encoded shape: {currency_encoded.shape}\")\n",
    "print(f\"converted_price shape: {data['converted_price'].shape}\")\n",
    "print(f\"X shape after concatenation: {X.shape}\")\n",
    "\n",
    "print(f\"X_train size: {X_train.shape}\")\n",
    "print(f\"X_val size: {X_val.shape}\")\n",
    "print(f\"X_test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1205a554-0603-4f20-b3b1-bbf075614ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트분리\n",
    "train_combined_text = X_train[:, 0] \n",
    "val_combined_text = X_val[:, 0]\n",
    "test_combined_text = X_test[:, 0]\n",
    "\n",
    "train_extra_features = X_train[:, 1:]  # 이 부분에서 이미 2차원으로 분리됨\n",
    "val_extra_features = X_val[:, 1:]\n",
    "test_extra_features = X_test[:, 1:]\n",
    "\n",
    "# object타입이 섞여있다고 해서 astype float 명시해줌\n",
    "train_extra_features = np.nan_to_num(train_extra_features, nan=0.0).astype(float)\n",
    "val_extra_features = np.nan_to_num(val_extra_features, nan=0.0).astype(float)\n",
    "test_extra_features = np.nan_to_num(test_extra_features, nan=0.0).astype(float)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "train_extra_features = scaler.fit_transform(train_extra_features)\n",
    "val_extra_features = scaler.transform(val_extra_features)\n",
    "test_extra_features = scaler.transform(test_extra_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecdda32-f4f2-43c5-825a-dd17b34b404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# 클러스터링을 통한 추가 피처 생성\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "train_clusters = kmeans.fit_predict(train_extra_features[:, -1].reshape(-1, 1))  # converted_price 컬럼 클러스터링\n",
    "val_clusters = kmeans.predict(val_extra_features[:, -1].reshape(-1, 1))\n",
    "test_clusters = kmeans.predict(test_extra_features[:, -1].reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fe5901-9c93-4782-8826-b73337fdb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터 레이블을 원-핫 인코딩\n",
    "cluster_ohe = OneHotEncoder(sparse_output=False)\n",
    "train_clusters_encoded = cluster_ohe.fit_transform(train_clusters.reshape(-1, 1))\n",
    "val_clusters_encoded = cluster_ohe.transform(val_clusters.reshape(-1, 1))\n",
    "test_clusters_encoded = cluster_ohe.transform(test_clusters.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6793518f-4c42-43bf-b8e6-583d35b3b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 피처에 클러스터 인코딩 결합\n",
    "train_extra_features = np.concatenate([train_extra_features, train_clusters_encoded], axis=1)\n",
    "val_extra_features = np.concatenate([val_extra_features, val_clusters_encoded], axis=1)\n",
    "test_extra_features = np.concatenate([test_extra_features, test_clusters_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e1270e8-9b60-4454-9851-b0c1d80e44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10224\\2767559813.py:4: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  train_extra_features_tensor = torch.tensor(train_extra_features, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor로 변환 후 디바이스 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_extra_features_tensor = torch.tensor(train_extra_features, dtype=torch.float32).to(device)\n",
    "val_extra_features_tensor = torch.tensor(val_extra_features, dtype=torch.float32).to(device)\n",
    "test_extra_features_tensor = torch.tensor(test_extra_features, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12affe13-a536-4714-913c-70912dd1abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저 (텍스트처리)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44558653-ff97-42cb-a192-c6b0dd9e8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X중 텍스트만 BERT 입력 형식으로 변환\n",
    "def encode_data(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_encodings = encode_data(train_combined_text)\n",
    "val_encodings = encode_data(val_combined_text)\n",
    "test_encodings = encode_data(test_combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e97158-70b4-4ece-99f5-8bf3c78f476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_machinery_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'],\n",
    "    train_encodings['attention_mask'],\n",
    "    train_extra_features_tensor,\n",
    "    torch.tensor(y_train_machinery, dtype=torch.long).to(device)  # Machinery 레이블\n",
    ")\n",
    "\n",
    "val_machinery_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'],\n",
    "    val_encodings['attention_mask'],\n",
    "    val_extra_features_tensor,\n",
    "    torch.tensor(y_val_machinery, dtype=torch.long).to(device)\n",
    ")\n",
    "\n",
    "test_machinery_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'],\n",
    "    test_encodings['attention_mask'],\n",
    "    test_extra_features_tensor,\n",
    "    torch.tensor(y_test_machinery, dtype=torch.long).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05c6fc79-7f45-4a76-b7ca-001707c64f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train size: (10029,)\n",
      "y_val size: (1770,)\n",
      "y_test size: (2083,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train size: {y_train_machinery.shape}\")\n",
    "print(f\"y_val size: {y_val_machinery.shape}\")\n",
    "print(f\"y_test size: {y_test_machinery.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79c5b89d-d987-4d05-9d72-e1ba20c3e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DataLoader 생성\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader_machinery = DataLoader(train_machinery_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_machinery  = DataLoader(val_machinery_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader_machinery = DataLoader(test_machinery_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38a8452c-0350-448f-b5c5-641b8e512ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMachinery(nn.Module):\n",
    "    def __init__(self, num_machinery_labels, extra_features_dim):\n",
    "        super(BertForMachinery, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size + extra_features_dim, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.machinery_classifier = nn.Linear(256, num_machinery_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, extra_features):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        if extra_features.dim() == 1:\n",
    "            extra_features = extra_features.unsqueeze(1)\n",
    "        \n",
    "        machinery_combined_features = torch.cat((pooled_output, extra_features), dim=1)\n",
    "        x = self.fc1(machinery_combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        machinery_outputs = self.machinery_classifier(x)\n",
    "        \n",
    "        return machinery_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f8589d-d1e7-4fcd-9d91-0634e8e6249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62779f71-0ceb-44dd-be47-bf9b697296aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMachinery(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=778, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (machinery_classifier): Linear(in_features=256, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "machinery_model = BertForMachinery(num_machinery_labels=len(machinery_label_encoder.classes_), extra_features_dim=10) \n",
    "machinery_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4db600-e114-4be6-834e-5d153ba444b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 학습률 스케줄러 설정\n",
    "optimizer_machinery = AdamW(machinery_model.parameters(), lr=2e-5)\n",
    "loss_fn_machinery=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "772d3add-051f-4e5c-b5d0-c9c7ce008715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_machinery(model, dataloader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]  # 순서 수정\n",
    "        \n",
    "        if labels.dim() > 1:\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "        labels = labels.to(torch.int64)  # CrossEntropyLoss에 맞게 변환\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9990e338-c952-4a12-ba6e-b5d960e884ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# 평가 함수 - logits-62개짜리 각각의 자신감\n",
    "def evaluate_machinery(model, dataloader, device, loss_fn_machinery):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    machinery_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = loss_fn_machinery(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)  # softmax 없이 직접 logits에서 최대값 클래스 예측\n",
    "            \n",
    "            # 예측값을 저장\n",
    "            machinery_predictions.append(predicted.cpu().numpy())  # 리스트에 추가\n",
    "            \n",
    "            # 정확도 계산\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    machinery_predictions = np.concatenate(machinery_predictions, axis=0)  \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, accuracy, machinery_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1505a3-0786-4beb-82b8-b897c930f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "381695c8-99af-44f7-b5d6-425661364fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/627 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 2.2436, Val Loss: 1.4900, Val Acc: 0.6232, Test Acc: 0.6207\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 1.3356, Val Loss: 1.1412, Val Acc: 0.6989, Test Acc: 0.6961\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 1.0550, Val Loss: 0.9203, Val Acc: 0.7412, Test Acc: 0.7408\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.8936, Val Loss: 0.8294, Val Acc: 0.7655, Test Acc: 0.7571\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.7785, Val Loss: 0.7455, Val Acc: 0.7915, Test Acc: 0.7916\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.6703, Val Loss: 0.7176, Val Acc: 0.7972, Test Acc: 0.8008\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.5998, Val Loss: 0.6557, Val Acc: 0.8141, Test Acc: 0.8133\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.5363, Val Loss: 0.6060, Val Acc: 0.8209, Test Acc: 0.8147\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4834, Val Loss: 0.5831, Val Acc: 0.8186, Test Acc: 0.8238\n",
      "Trigger Times (Machinery): 1\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4433, Val Loss: 0.5829, Val Acc: 0.8249, Test Acc: 0.8272\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4091, Val Loss: 0.5549, Val Acc: 0.8328, Test Acc: 0.8382\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3821, Val Loss: 0.5626, Val Acc: 0.8328, Test Acc: 0.8243\n",
      "Trigger Times (Machinery): 1\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3660, Val Loss: 0.5904, Val Acc: 0.8328, Test Acc: 0.8320\n",
      "Trigger Times (Machinery): 2\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3404, Val Loss: 0.5610, Val Acc: 0.8367, Test Acc: 0.8368\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3314, Val Loss: 0.5801, Val Acc: 0.8418, Test Acc: 0.8401\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3042, Val Loss: 0.5583, Val Acc: 0.8424, Test Acc: 0.8421\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2983, Val Loss: 0.6133, Val Acc: 0.8362, Test Acc: 0.8358\n",
      "Trigger Times (Machinery): 1\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2847, Val Loss: 0.5576, Val Acc: 0.8407, Test Acc: 0.8406\n",
      "Trigger Times (Machinery): 2\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2753, Val Loss: 0.5670, Val Acc: 0.8441, Test Acc: 0.8425\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2764, Val Loss: 0.5816, Val Acc: 0.8458, Test Acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy (Machinery): 0.8387\n"
     ]
    }
   ],
   "source": [
    "# Machinery 모델 학습 실행\n",
    "num_epochs = 20\n",
    "best_val_acc_machinery = 0\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Machinery 모델 학습\n",
    "    train_loss_machinery = train_machinery(\n",
    "        machinery_model, \n",
    "        train_loader_machinery, \n",
    "        optimizer_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    \n",
    "    # Machinery 모델 평가\n",
    "    val_loss_machinery, val_acc_machinery, val_preds_machinery = evaluate_machinery(\n",
    "        machinery_model, \n",
    "        val_loader_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    test_loss_machinery, test_acc_machinery, test_preds_machinery = evaluate_machinery(\n",
    "        machinery_model, \n",
    "        test_loader_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    \n",
    "    print(f\"Machinery - Train Loss: {train_loss_machinery:.4f}, Val Loss: {val_loss_machinery:.4f}, Val Acc: {val_acc_machinery:.4f}, Test Acc: {test_acc_machinery:.4f}\")\n",
    "    \n",
    "    # Early Stopping for Machinery\n",
    "    if val_acc_machinery > best_val_acc_machinery:\n",
    "        best_val_acc_machinery = val_acc_machinery\n",
    "        trigger_times = 0\n",
    "        torch.save(machinery_model.state_dict(), \"best_machinery_model.pth\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"Trigger Times (Machinery): {trigger_times}\")\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping for Machinery!\")\n",
    "            break\n",
    "\n",
    "# 최종 테스트 성능 평가\n",
    "final_test_loss_machinery, final_test_acc_machinery, final_machinery_predictions = evaluate_machinery(\n",
    "    machinery_model, \n",
    "    test_loader_machinery, \n",
    "    device, \n",
    "    loss_fn_machinery\n",
    ")\n",
    "print(f\"Final Test Accuracy (Machinery): {final_test_acc_machinery:.4f}\")\n",
    "torch.save(machinery_model.state_dict(), \"best_machinery_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aea936-31d1-4027-8cad-f4c5baa664b7",
   "metadata": {},
   "source": [
    "### 전이 학습으로 Assembly 모델\n",
    "\n",
    "> 프로토타입-1개 최상위 예측 가져오도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3fa58e3-c59b-4f5a-a8f3-4d0fefab3977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10224\\3052808221.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  machinery_model.load_state_dict(torch.load(\"best_machinery_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Machinery 모델 로드 및 가중치 고정\n",
    "num_machinery_labels = len(np.unique(y_machinery))\n",
    "\n",
    "machinery_model = BertForMachinery(\n",
    "    num_machinery_labels=len(machinery_label_encoder.classes_), \n",
    "    extra_features_dim=train_extra_features.shape[1]\n",
    ").to(device)\n",
    "\n",
    "machinery_model.load_state_dict(torch.load(\"best_machinery_model.pth\"))\n",
    "machinery_model.eval()\n",
    "\n",
    "for param in machinery_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81db3137-4cdc-4924-a471-8ba12fe32996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-K 예측값과 확률값 함께 가져오기 함수\n",
    "def get_top_k_machinery_predictions_with_probs(model, dataloader, k=3):\n",
    "    model.eval()\n",
    "    top_k_predictions = []\n",
    "    top_k_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating Top-K Machinery Predictions\"):\n",
    "            input_ids, attention_mask, extra_features = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "            \n",
    "            # 상위 K개의 예측값과 확률 가져오기\n",
    "            topk_prob, topk_predicted = torch.topk(F.softmax(outputs, dim=1), k, dim=1)\n",
    "            top_k_predictions.append(topk_predicted.cpu())\n",
    "            top_k_probs.append(topk_prob.cpu())\n",
    "    return torch.cat(top_k_predictions, dim=0), torch.cat(top_k_probs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46aa5ad1-42b1-48a7-9d10-d5b7876ae3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d97b551-bc6e-4f79-87cf-c21fe4916a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-K Machinery Predictions:   0%|                                                  | 0/627 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Generating Top-K Machinery Predictions: 100%|████████████████████████████████████████| 627/627 [01:11<00:00,  8.71it/s]\n",
      "Generating Top-K Machinery Predictions: 100%|████████████████████████████████████████| 111/111 [00:12<00:00,  8.97it/s]\n",
      "Generating Top-K Machinery Predictions: 100%|████████████████████████████████████████| 131/131 [00:10<00:00, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# 예측 생성 (상위 1개)\n",
    "train_machinery_predictions_top_3, train_machinery_probs_top_3 = get_top_k_machinery_predictions_with_probs(\n",
    "    machinery_model, \n",
    "    DataLoader(TensorDataset(\n",
    "        train_encodings['input_ids'], \n",
    "        train_encodings['attention_mask'], \n",
    "        train_extra_features_tensor\n",
    "    ), batch_size=16, shuffle=False), \n",
    "    k=3\n",
    ")\n",
    "\n",
    "val_machinery_predictions_top_3, val_machinery_probs_top_3 = get_top_k_machinery_predictions_with_probs(\n",
    "    machinery_model, \n",
    "    DataLoader(TensorDataset(\n",
    "        val_encodings['input_ids'], \n",
    "        val_encodings['attention_mask'], \n",
    "        val_extra_features_tensor\n",
    "    ), batch_size=16, shuffle=False), \n",
    "    k=3\n",
    ")\n",
    "\n",
    "test_machinery_predictions_top_3, test_machinery_probs_top_3 = get_top_k_machinery_predictions_with_probs(\n",
    "    machinery_model, \n",
    "    DataLoader(TensorDataset(\n",
    "        test_encodings['input_ids'], \n",
    "        test_encodings['attention_mask'], \n",
    "        test_extra_features_tensor\n",
    "    ), batch_size=16, shuffle=False), \n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611fbef1-7449-455a-9b68-cc97c4041a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly 데이터셋에 Top-3 예측값과 확률 추가\n",
    "train_assembly_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'],\n",
    "    train_encodings['attention_mask'],\n",
    "    train_extra_features_tensor,\n",
    "    train_machinery_predictions_top_3,   # Top-3 예측값 추가\n",
    "    train_machinery_probs_top_3,         # Top-3 확률값 추가\n",
    "    torch.tensor(y_train_assembly, dtype=torch.long).to(device)  # Assembly 레이블\n",
    ")\n",
    "\n",
    "val_assembly_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'],\n",
    "    val_encodings['attention_mask'],\n",
    "    val_extra_features_tensor,\n",
    "    val_machinery_predictions_top_3,     # Top-3 예측값 추가\n",
    "    val_machinery_probs_top_3,           # Top-3 확률값 추가\n",
    "    torch.tensor(y_val_assembly, dtype=torch.long).to(device)\n",
    ")\n",
    "\n",
    "test_assembly_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'],\n",
    "    test_encodings['attention_mask'],\n",
    "    test_extra_features_tensor,\n",
    "    test_machinery_predictions_top_3,    # Top-3 예측값 추가\n",
    "    test_machinery_probs_top_3,          # Top-3 확률값 추가\n",
    "    torch.tensor(y_test_assembly, dtype=torch.long).to(device)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4516fcaa-2013-4153-b5e0-c3c87c5f19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "batch_size = 16\n",
    "train_loader_assembly = DataLoader(train_assembly_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_assembly  = DataLoader(val_assembly_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader_assembly = DataLoader(test_assembly_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6541ef10-6f4f-412b-92be-0490fb5cc8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# FocalLoss 정의 (클래스 불균형 처리)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c5489b7-800a-4735-9aa6-55039e95e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assembly_labels = len(assembly_label_encoder.classes_)\n",
    "machinery_output_dim = 62 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28355938-0a2c-4317-bdef-6fe2504aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssemblyModel(nn.Module):\n",
    "    def __init__(self, num_assembly_labels, extra_features_dim):\n",
    "        super(AssemblyModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # BERT는 학습 가능 상태로 유지\n",
    "        \n",
    "        # combined_features 크기 조정: pooled_output (768) + machinery_predictions_top_3 (3) + machinery_probs_top_3 (3) + extra_features_dim\n",
    "        self.fc1 = nn.Linear(768 + 3 + 3 + extra_features_dim, 128)\n",
    "        self.batchnorm = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(128, num_assembly_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, machinery_predictions_top_k, machinery_probs_top_k, extra_features):\n",
    "        # BERT 출력\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_outputs.pooler_output\n",
    "        \n",
    "        # combined_features 크기 = (batch_size, 768 + 3 + 3 + extra_features_dim)\n",
    "        combined_features = torch.cat((\n",
    "            pooled_output, \n",
    "            machinery_predictions_top_k.float(), \n",
    "            machinery_probs_top_k.float(), \n",
    "            extra_features.float()\n",
    "        ), dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.batchnorm(x)  # BatchNorm 먼저 적용\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        assembly_outputs = self.fc2(x)\n",
    "        \n",
    "        return assembly_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbe2d3a9-1037-49a1-a980-2dadefc841b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44b1f66b-0ada-4bac-8def-d65fd51cda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly 모델 초기화\n",
    "num_assembly_labels = len(np.unique(y_assembly))  # 혹은 len(assembly_label_encoder.classes_)\n",
    "assembly_model = AssemblyModel(\n",
    "    num_assembly_labels=num_assembly_labels, \n",
    "    extra_features_dim=train_extra_features.shape[1]\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "884e4789-a0da-4a86-bc33-ff81287eb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 일반적인 CrossEntropyLoss 사용\n",
    "loss_fn_assembly = FocalLoss(alpha=1, gamma=2, reduction='mean')\n",
    "\n",
    "# Optimizer 설정\n",
    "\n",
    "optimizer_assembly = AdamW(filter(lambda p: p.requires_grad, assembly_model.parameters()), lr=2e-5, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer_assembly, step_size=3, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97840c80-15a1-4f33-93ef-3f88c6d10b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec52308b-f51a-452d-9bcb-5ecc80e826cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMachinery(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=778, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (machinery_classifier): Linear(in_features=256, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "assembly_model.to(device)\n",
    "machinery_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4d65cc0-a1b1-4143-aa6c-25ae3d5ec897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly 모델 학습 및 평가 함수 정의\n",
    "def train_assembly(model, dataloader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training Assembly\"):\n",
    "        input_ids, attention_mask, extra_features, machinery_predictions_top_3, machinery_probs_top_3, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        extra_features = extra_features.to(device)\n",
    "        machinery_predictions_top_3 = machinery_predictions_top_3.to(device)\n",
    "        machinery_probs_top_3 = machinery_probs_top_3.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Assembly 모델 예측: machinery_predictions_top_3 및 machinery_probs_top_3 추가\n",
    "        outputs = model(\n",
    "            input_ids, \n",
    "            attention_mask, \n",
    "            machinery_predictions_top_3, \n",
    "            machinery_probs_top_3, \n",
    "            extra_features\n",
    "        )\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df772767-a7b4-48de-b958-3f7df967744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_assembly(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating Assembly\"):\n",
    "            input_ids, attention_mask, extra_features, machinery_predictions_top_3, machinery_probs_top_3, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            extra_features = extra_features.to(device)\n",
    "            machinery_predictions_top_3 = machinery_predictions_top_3.to(device)\n",
    "            machinery_probs_top_3 = machinery_probs_top_3.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Assembly 모델 예측\n",
    "            outputs = model(\n",
    "                input_ids, \n",
    "                attention_mask, \n",
    "                machinery_predictions_top_3, \n",
    "                machinery_probs_top_3, \n",
    "                extra_features\n",
    "            )\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            all_predictions.append(predicted.cpu().numpy())\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    return accuracy, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f60ae27e-61d9-4744-9a82-1afe4b909f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1a2420e-989b-463d-adef-b0ab856965ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:09<00:00,  3.32it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:11<00:00,  8.75it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.80it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.1436\n",
      "Train Accuracy: 0.1310\n",
      "Validation Accuracy: 0.1373\n",
      "Test Accuracy: 0.1301\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:08<00:00,  3.32it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:11<00:00,  8.76it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.5336\n",
      "Train Accuracy: 0.2575\n",
      "Validation Accuracy: 0.2469\n",
      "Test Accuracy: 0.2578\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.93it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.98it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.0872\n",
      "Train Accuracy: 0.3599\n",
      "Validation Accuracy: 0.3514\n",
      "Test Accuracy: 0.3577\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.92it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.97it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.8333\n",
      "Train Accuracy: 0.3841\n",
      "Validation Accuracy: 0.3582\n",
      "Test Accuracy: 0.3812\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:08<00:00,  3.33it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.93it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.98it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.7731\n",
      "Train Accuracy: 0.4053\n",
      "Validation Accuracy: 0.3740\n",
      "Test Accuracy: 0.4028\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.93it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.97it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.7336\n",
      "Train Accuracy: 0.4197\n",
      "Validation Accuracy: 0.4023\n",
      "Test Accuracy: 0.4157\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.00it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6895\n",
      "Train Accuracy: 0.4189\n",
      "Validation Accuracy: 0.3949\n",
      "Test Accuracy: 0.4114\n",
      "Trigger Times: 1\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.00it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6912\n",
      "Train Accuracy: 0.4220\n",
      "Validation Accuracy: 0.3989\n",
      "Test Accuracy: 0.4143\n",
      "Trigger Times: 2\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.00it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6909\n",
      "Train Accuracy: 0.4248\n",
      "Validation Accuracy: 0.4062\n",
      "Test Accuracy: 0.4201\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.00it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6820\n",
      "Train Accuracy: 0.4173\n",
      "Validation Accuracy: 0.3932\n",
      "Test Accuracy: 0.4090\n",
      "Trigger Times: 1\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.00it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6870\n",
      "Train Accuracy: 0.4247\n",
      "Validation Accuracy: 0.3994\n",
      "Test Accuracy: 0.4196\n",
      "Trigger Times: 2\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assembly: 100%|█████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 627/627 [01:10<00:00,  8.95it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  9.01it/s]\n",
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6796\n",
      "Train Accuracy: 0.4185\n",
      "Validation Accuracy: 0.3983\n",
      "Test Accuracy: 0.4186\n",
      "Trigger Times: 3\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Assembly: 100%|███████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy (Assembly): 0.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assembly 모델 학습 실행\n",
    "num_epochs = 20\n",
    "best_val_acc_assembly = 0\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Assembly 모델 학습\n",
    "    train_loss_assembly = train_assembly(\n",
    "        assembly_model, \n",
    "        train_loader_assembly, \n",
    "        optimizer_assembly, \n",
    "        device, \n",
    "        loss_fn_assembly\n",
    "    )\n",
    "    \n",
    "    # Assembly 모델 평가\n",
    "    train_acc_assembly, _ = evaluate_assembly(\n",
    "        assembly_model, \n",
    "        train_loader_assembly, \n",
    "        device\n",
    "    )\n",
    "    val_acc_assembly, _ = evaluate_assembly(\n",
    "        assembly_model, \n",
    "        val_loader_assembly, \n",
    "        device\n",
    "    )\n",
    "    scheduler.step()  # 매 에포크 후 학습률 조정\n",
    "\n",
    "    test_acc_assembly, _ = evaluate_assembly(\n",
    "        assembly_model, \n",
    "        test_loader_assembly, \n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(f\"Train Loss: {train_loss_assembly:.4f}\")\n",
    "    print(f\"Train Accuracy: {train_acc_assembly:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc_assembly:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc_assembly:.4f}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_acc_assembly > best_val_acc_assembly:\n",
    "        best_val_acc_assembly = val_acc_assembly\n",
    "        trigger_times = 0\n",
    "        # Best 모델 저장\n",
    "        torch.save(assembly_model.state_dict(), \"best_assembly_model.pth\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"Trigger Times: {trigger_times}\")\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# 최종 테스트 성능 평가\n",
    "final_test_acc_assembly, final_assembly_predictions = evaluate_assembly(\n",
    "    assembly_model, \n",
    "    test_loader_assembly, \n",
    "    device\n",
    ")\n",
    "print(f\"Final Test Accuracy (Assembly): {final_test_acc_assembly:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44071b-9711-45c5-87fa-e7b86bd3c63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999115a-fd7b-448c-939f-a12ebec64c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
