{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83a08e1-5041-4642-99f5-c82449e37554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6526e20d-c98e-48d0-b5bb-b5f808ede823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663325ee-80a8-448e-9d0d-06d76ae99d18",
   "metadata": {},
   "source": [
    "## 모델이 클래스 특성을 학습하기에 충분한 표본 갯수로 데이터 제거\n",
    "\n",
    "> Machinery에서 데이터가 30개 이하인 클래스 수: 100\n",
    "> \n",
    "> Assembly에서 데이터가 30개 이하인 클래스 수: 1583\n",
    ">\n",
    "> 제거 후, 남은 데이터: 13882, MACHINERY : 62 ASSEMBLY:209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c7432c-d7d4-4f38-8baa-ef842df72dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('filtered_dataset_30.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cb3b8e-7afc-406b-b683-e9fc57c549b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 209\n"
     ]
    }
   ],
   "source": [
    "print(len(data['Machinery'].unique()),len(data['Assembly'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb48e7ee-af89-4345-b401-698b61cafa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13882 entries, 0 to 13881\n",
      "Data columns (total 32 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   청구서번호        13882 non-null  object \n",
      " 1   No.          13882 non-null  int64  \n",
      " 2   Subject      13872 non-null  object \n",
      " 3   Machinery    13882 non-null  object \n",
      " 4   Assembly     13882 non-null  object \n",
      " 5   청구품목         13882 non-null  object \n",
      " 6   Unnamed: 6   0 non-null      float64\n",
      " 7   Part No.1    13881 non-null  object \n",
      " 8   Part No.2    2430 non-null   object \n",
      " 9   청구량          13818 non-null  float64\n",
      " 10  견적           13698 non-null  object \n",
      " 11  견적수량         13818 non-null  float64\n",
      " 12  견적화폐         13818 non-null  object \n",
      " 13  견적단가         13882 non-null  float64\n",
      " 14  발주번호         13882 non-null  object \n",
      " 15  발주처          13882 non-null  object \n",
      " 16  발주           13882 non-null  object \n",
      " 17  발주수량         13818 non-null  float64\n",
      " 18  발주금액         13818 non-null  float64\n",
      " 19  D/T          12461 non-null  object \n",
      " 20  미입고 기간       998 non-null    object \n",
      " 21  창고입고         11867 non-null  object \n",
      " 22  창고입고수량       13882 non-null  int64  \n",
      " 23  Control No.  8571 non-null   object \n",
      " 24  입고창고         11867 non-null  object \n",
      " 25  창고출고         10595 non-null  object \n",
      " 26  창고출고수량       13882 non-null  int64  \n",
      " 27  출고선박         10595 non-null  object \n",
      " 28  출고운반선        10595 non-null  object \n",
      " 29  선박입고         3071 non-null   object \n",
      " 30  선박입고수량       13882 non-null  int64  \n",
      " 31  완료 여부        3065 non-null   object \n",
      "dtypes: float64(6), int64(4), object(22)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e456473-b382-4547-ad15-529b584ad2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GE POWER PACK FORK - E7(B)'\n",
      " 'SAMSON SUPER STRONG DOUBLE BRAID ROPE 1 3/4\", 300FT'\n",
      " 'WIRE ROPE G)6X(S)19 A3 CMP SLPP 28MM X 400M' ... 'BRACKET '\n",
      " 'WASHER, 10 ' 'COVER,MANIFOLD.EXH ']\n"
     ]
    }
   ],
   "source": [
    "print(data['청구품목'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa141-ec18-48b5-9d38-39ea85bdf2bd",
   "metadata": {},
   "source": [
    "### 청구품목 전처리 \n",
    "\n",
    "1. 텍스트 전처리\n",
    "2. TF-IDF 기반 강조 (엠퍼사이징)\n",
    "3. FastText 임베딩\n",
    "   \n",
    "### part no.1 전처리\n",
    "\n",
    "> 콤마 위치에 따른 세부적인 차이가 많은 텍스트이므로 특수기호 및 문자 유지 필요 => 별도 전처리 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f68d784-6d51-43a8-8ef6-bbad5d5109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)   \n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)    \n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)    \n",
    "    text = text.strip()    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b42583-0c68-48a8-ac07-ac3df468e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 클리닝\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb665627-f3fe-4e78-ad87-29fc63c7ec43",
   "metadata": {},
   "source": [
    "> 청구품목 데이터에서는 각 단어 의미적 연관성보다 주요단어가 있는 것이므로, 가중치 부여하는 것으로 접근함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4cb6a1-43d8-40ce-ade2-57c1bd046dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청구품목 내 주요단어: ['as' 'bearing' 'bolt' 'charges' 'core' 'cover' 'cylinder' 'for' 'fuel'\n",
      " 'gasket' 'gear' 'gp' 'head' 'hex' 'in' 'kit' 'nut' 'oil' 'plate' 'pump'\n",
      " 'ring' 'screw' 'seal' 'sensor' 'set' 'shaft' 'spring' 'valve' 'washer'\n",
      " 'water']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 확인용\n",
    "claim_items = data['청구품목'].tolist() \n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30)\n",
    "tfidf_matrix = tfidf.fit_transform(claim_items)\n",
    "\n",
    "# 중요한 단어 추출\n",
    "important_words = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"청구품목 내 주요단어:\", important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978a32ad-6eab-40b1-b6e6-9f0072d24d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2. TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30) \n",
    "tfidf_matrix = tfidf.fit_transform(data['cleaned_item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590b98d-a4ec-4fa7-b9a3-a885f465b885",
   "metadata": {},
   "source": [
    "### 발주처 전처리 강화\n",
    "\n",
    "> 부가단어 (CORPORATION, Corp, CO., Ltd, GmbH, Co., Inc, 주식회사, 상사, 공사, Co.,Ltd, Ltd, Pte Ltd, LLC) 제거\n",
    "\n",
    "> 핵심 정보(회사명 직접 관련) emphasizing 함 > 증강함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a047f01f-acfa-4bf9-b772-c35b47e279e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93715f68-009b-424f-b42b-1e928ec887ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa', 'kti', '대광기업', 'kth mar', 'haein _cheonan', 'korea ucd', 'east wind', '인스알파', 'in international', '한국쉘석유', 'euro kytex engineering bv', '대동베아링', 'marine hydrotec', '금안', 'test', 'port relief engineering', 'caterpillar marine asia pacific', '혜인', 'sanwa mmercial', 'yusinhr', '선진종합', 'furuno', 'nissin refrigeration engineerin', '우림', 'haein _cheonan', 'kemel', 'rexnord -falk marine group', '유신에이치알', 'gea korea', '안에너지', 'sunjin etech', '디에스알제강', '한국에프에이디', 'albert', 'wartsila korea', '선진엔텍', 'piriou naval', '프러스', 'taeyoung enterprise', 'shina', 'ins alfa', 'kemelkomarine', '누리', 'rnk tech', 'os system', '씨코리아', '두원알앤에이', '합동듸젤사', '하이에어코리아', 'desmi pumping technologysuzhou', '한국마이콤', 'human engineering']\n"
     ]
    }
   ],
   "source": [
    "suppliers = [\n",
    "    'MATSUI(U.S.A) COROPRATION', 'KTI', '대광기업(주)', 'K.TH MARCO',\n",
    "    'HAEIN Coporation_Cheonan', 'KOREA UCD CO.,LTD.', 'EAST WIND Gmbh', '인스알파',\n",
    "    'ICON INTERNATIONAL, INC', '한국쉘석유㈜', 'EURO KYTEX ENGINEERING BV', '대동베아링상사',\n",
    "    'MARINE HYDROTEC CO.,LTD.', '금안상사', 'TEST COMPANY',\n",
    "    'PORT RELIEF ENGINEERING CO.,LTD.',\n",
    "    'Caterpillar Marine Asia Pacific Pte Ltd', '(주)혜인',\n",
    "    'SANWA COMMERCIAL CO.,LTD.', 'yusinHR Co., Ltd.', '(주)선진종합', 'FURUNO',\n",
    "    'NISSIN REFRIGERATION  ENGINEERIN', '(주)우림공사',\n",
    "    'HAEIN Coporation_Cheonan(사용금지)', 'KEMEL', 'REXNORD LLC-FALK MARINE GROUP',\n",
    "    '유신에이치알(사용금지)', 'GEA KOREA LTD', '주안에너지㈜', 'SUNJIN ETECH Co.,Ltd.',\n",
    "    '디에스알제강주식회사', '(주)한국에프에이디', 'ALBERT GMBH', 'Wartsila Korea Ltd.',\n",
    "    '(주)선진엔텍(사용금지)', 'PIRIOU NAVAL', '(주)프러스엔지니어링', 'Taeyoung Enterprise',\n",
    "    'SHINA', 'INS ALFA', 'KEMEL(KOMARINE)', '누리엔지니어링', 'RNK TECH CO.,LTD',\n",
    "    'OS SYSTEM CO.,LTD', '씨코리아엔지니어링(주)', '(주)두원알앤에이', '합동듸젤사', '하이에어코리아(주)',\n",
    "    'DESMI PUMPING TECHNOLOGY(SUZHOU) CO.,LTD', '한국마이콤',\n",
    "    'HUMAN & ENGINEERING CO.,LTD'\n",
    "]\n",
    "\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]\n",
    "print(cleaned_suppliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "668b9875-82a8-43c5-bb4f-c1b6bd535e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  HAEIN Corporation => HAEIN\n",
    "def extract_important_part(name):\n",
    "    if re.search(r'[가-힣]', name):\n",
    "        name = re.sub(r'(기업|상사|종합|공사)', '', name)\n",
    "        important_part = name.split()[0]  # 첫 단어 추출\n",
    "    else:\n",
    "        # 영문 이름의 경우 첫 번째 단어만 추출\n",
    "        important_part = name.split()[0]\n",
    "    \n",
    "    return important_part\n",
    "\n",
    "# 한번더 반복 HAEIN HAEIN Corporation\n",
    "def emphasize_supplier_name(name):\n",
    "    important_part = extract_important_part(name)\n",
    "    emphasized_name = f\"{important_part} {important_part} {name}\"  # 중요한 부분을 반복\n",
    "    return emphasized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ece38a1f-a83e-4021-afb4-057883d6e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa matsui_usa matsui_usa', 'taeyoung taeyoung taeyoung enterprise', 'haein haein haein _cheonan']\n"
     ]
    }
   ],
   "source": [
    "suppliers = ['MATSUI(U.S.A) COROPRATION', 'taeyoung enterprise','HAEIN Coporation_Cheonan(사용금지)']\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]  # 전처리\n",
    "emphasized_suppliers = [emphasize_supplier_name(supplier) for supplier in cleaned_suppliers]  # 강조\n",
    "\n",
    "print(emphasized_suppliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8078a0c-6a95-46d3-bb74-ac2798e556fd",
   "metadata": {},
   "source": [
    "### 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1977ab6f-cdc6-4bef-a91f-2bbb62b77a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 전처리 (TF-IDF 벡터화 적용)\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "\n",
    "# 파트 넘버 전처리 (별도 전처리 없음)\n",
    "data['Part No.1'] = data['Part No.1'].astype(str)\n",
    "\n",
    "# 발주처 전처리\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "# data['emphasized_supplier'] = data['cleaned_supplier'].apply(emphasize_supplier_name)\n",
    "\n",
    "# 4. 청구품목 + Part No.1 + 발주처 결합 (증강 없이)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad01688-8522-4ee4-9221-5fe32a61b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 6. combined_text에서 중요한 단어 강조 함수 (단어 경계 사용)\n",
    "#def emphasize_important_words_in_combined_text(combined_text, important_words):\n",
    "#    for word in important_words:\n",
    "#        # 정확한 단어를 찾아서 반복 (단어 경계 \\b 사용)\n",
    "#        combined_text = re.sub(rf'\\b{word}\\b', f'{word} {word}', combined_text)\n",
    "#    return combined_text\n",
    "\n",
    "# 7. combined_text에서 중요한 단어 강조 적용\n",
    "# data['emphasized_combined_text'] = data['combined_text'].apply(\n",
    "#    lambda x: emphasize_important_words_in_combined_text(x, important_words)\n",
    "#)\n",
    "\n",
    "# 최종 출력 확인\n",
    "#print(data[['combined_text', 'emphasized_combined_text']].tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867bc16f-a891-4527-9db4-392aa3569d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. TF-IDF 벡터화 (combined_text)\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "X_tfidf = tfidf.fit_transform(data['combined_text'])  # TF-IDF 벡터화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922f66bc-16c3-4811-8184-26fe89dacb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 2. Word2Vec 학습 (combined_text)\n",
    "sentences = [text.split() for text in data['combined_text'].tolist()]\n",
    "w2v_model = Word2Vec(sentences, vector_size=120, window=5, min_count=1, sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5bb31b0-5f53-401f-bcec-080f8f8daac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13882, 120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11752\\355956493.py:34: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  combined_embeddings_tensor = torch.tensor(combined_embeddings)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. TF-IDF 가중치를 적용한 Word2Vec 임베딩 계산\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "def get_weighted_word2vec(text, model, tfidf_vector, feature_names):\n",
    "    words = text.split()\n",
    "    weighted_embedding = np.zeros(model.vector_size)\n",
    "    total_weight = 0.0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            # 단어가 TF-IDF 벡터에서 존재할 경우 가중치 부여\n",
    "            try:\n",
    "                idx = feature_names.tolist().index(word)\n",
    "                weight = tfidf_vector[0, idx]  # TF-IDF 가중치\n",
    "                weighted_embedding += weight * model.wv[word]\n",
    "                total_weight += weight\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    if total_weight > 0:\n",
    "        weighted_embedding /= total_weight  # 가중합 계산\n",
    "    \n",
    "    return weighted_embedding\n",
    "\n",
    "# 4. TF-IDF와 Word2Vec 결합 임베딩 생성\n",
    "combined_embeddings = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    tfidf_vector = X_tfidf[i]\n",
    "    embedding = get_weighted_word2vec(row['combined_text'], w2v_model, tfidf_vector, tfidf_feature_names)\n",
    "    combined_embeddings.append(embedding)\n",
    "\n",
    "# 5. Tensor로 변환\n",
    "combined_embeddings_tensor = torch.tensor(combined_embeddings)\n",
    "\n",
    "print(combined_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf009e4d-8dd6-4e58-a3ad-df4efd1bdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np shape: (8884, 120)\n",
      "X_train_tensor shape: torch.Size([8884, 120])\n",
      "y_train_machinery shape: (8884,)\n",
      "y_train_assembly shape: (8884,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11752\\2655928270.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11752\\2655928270.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11752\\2655928270.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "\n",
    "# 2. 레이블 준비 (Machinery, Asembly 등)\n",
    "machinery_labels = data['Machinery'].values\n",
    "assembly_labels = data['Assembly'].values\n",
    "\n",
    "label_encoder_machinery = LabelEncoder()\n",
    "y_machinery = label_encoder_machinery.fit_transform(machinery_labels)\n",
    "\n",
    "label_encoder_assembly = LabelEncoder()\n",
    "y_assembly = label_encoder_assembly.fit_transform(assembly_labels)\n",
    "\n",
    "# 3. 스케일러 \n",
    "# TF-IDF 벡터는 이미 스케일링된 값(0~1)\n",
    "\n",
    "X=combined_embeddings_tensor\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train_val, X_test, y_train_val_machinery, y_test_machinery, y_train_val_assembly, y_test_assembly = train_test_split(\n",
    "    X, y_machinery, y_assembly, test_size=0.2, random_state=42, stratify=y_machinery\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train_machinery, y_val_machinery, y_train_assembly, y_val_assembly = train_test_split(\n",
    "    X_train_val, y_train_val_machinery, y_train_val_assembly, test_size=0.2, random_state=42, stratify=y_train_val_machinery\n",
    ")\n",
    "\n",
    "# 5. 텐서 정리 해놓기(이미 텐서 형태임)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor_machinery = torch.tensor(y_train_machinery, dtype=torch.long)\n",
    "y_val_tensor_machinery = torch.tensor(y_val_machinery, dtype=torch.long)\n",
    "y_test_tensor_machinery = torch.tensor(y_test_machinery, dtype=torch.long)\n",
    "\n",
    "y_train_tensor_assembly = torch.tensor(y_train_assembly, dtype=torch.long)\n",
    "y_val_tensor_assembly = torch.tensor(y_val_assembly, dtype=torch.long)\n",
    "y_test_tensor_assembly = torch.tensor(y_test_assembly, dtype=torch.long)\n",
    "\n",
    "\n",
    "# MLP나 XGBoost용 NumPy 배열로 변환\n",
    "X_train_np = X_train_tensor.numpy()\n",
    "X_val_np = X_val_tensor.numpy()\n",
    "X_test_np = X_test_tensor.numpy()\n",
    "\n",
    "y_train_np_machinery = y_train_machinery  # 이미 NumPy 배열 상태\n",
    "y_val_np_machinery = y_val_machinery\n",
    "y_test_np_machinery = y_test_machinery\n",
    "\n",
    "y_train_np_assembly = y_train_assembly\n",
    "y_val_np_assembly = y_val_assembly\n",
    "y_test_np_assembly = y_test_assembly\n",
    "\n",
    "print(f\"X_train_np shape: {X_train_np.shape}\")\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_machinery shape: {y_train_np_machinery.shape}\")\n",
    "print(f\"y_train_assembly shape: {y_train_np_assembly.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cb8b0-7a6c-4f48-9792-dc44cbe61a9e",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eee6727-d855-41bb-be38-1fe540793f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_mlp_model(dropout_rate=[0.3, 0.3, 0.3], learning_rate=0.005):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),  # 입력 크기 맞춤\n",
    "        Dropout(dropout_rate[0]),  # 첫 번째 Dropout 비율\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(dropout_rate[1]),  # 두 번째 Dropout 비율\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate[2]),  # 세 번째 Dropout 비율\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate[1]),  \n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(62, activation='softmax')  # Machinery 클래스 수\n",
    "    ])\n",
    "\n",
    "    # 옵티마이저와 학습률 설정\n",
    "    optimizer = Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bebfc072-09a3-4c80-966b-83d81d18a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4286 - loss: 2.4623 - val_accuracy: 0.5385 - val_loss: 1.6300 - learning_rate: 0.0050\n",
      "Epoch 2/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5266 - loss: 1.7535 - val_accuracy: 0.5543 - val_loss: 1.5286 - learning_rate: 0.0050\n",
      "Epoch 3/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 1.6200 - val_accuracy: 0.5592 - val_loss: 1.4859 - learning_rate: 0.0050\n",
      "Epoch 4/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 1.6046 - val_accuracy: 0.5723 - val_loss: 1.4349 - learning_rate: 0.0050\n",
      "Epoch 5/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5478 - loss: 1.5399 - val_accuracy: 0.5606 - val_loss: 1.4536 - learning_rate: 0.0050\n",
      "Epoch 6/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 1.5306 - val_accuracy: 0.5705 - val_loss: 1.4159 - learning_rate: 0.0050\n",
      "Epoch 7/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5641 - loss: 1.5001 - val_accuracy: 0.5768 - val_loss: 1.4023 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5636 - loss: 1.4738 - val_accuracy: 0.5705 - val_loss: 1.3970 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5493 - loss: 1.5141 - val_accuracy: 0.5574 - val_loss: 1.4012 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5656 - loss: 1.4789 - val_accuracy: 0.5831 - val_loss: 1.3876 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 1.4840 - val_accuracy: 0.5912 - val_loss: 1.3617 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5572 - loss: 1.4744 - val_accuracy: 0.5867 - val_loss: 1.3465 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 1.4310 - val_accuracy: 0.5898 - val_loss: 1.3317 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5728 - loss: 1.4049 - val_accuracy: 0.5777 - val_loss: 1.3665 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5680 - loss: 1.4516 - val_accuracy: 0.5849 - val_loss: 1.3642 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 1.4055 - val_accuracy: 0.6015 - val_loss: 1.3417 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5764 - loss: 1.3940 - val_accuracy: 0.6024 - val_loss: 1.3065 - learning_rate: 0.0025\n",
      "Epoch 18/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5786 - loss: 1.3856 - val_accuracy: 0.6015 - val_loss: 1.3057 - learning_rate: 0.0025\n",
      "Epoch 19/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 1.3827 - val_accuracy: 0.6038 - val_loss: 1.3021 - learning_rate: 0.0025\n",
      "Epoch 20/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 1.3666 - val_accuracy: 0.5912 - val_loss: 1.3055 - learning_rate: 0.0025\n",
      "Epoch 21/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 1.3426 - val_accuracy: 0.5984 - val_loss: 1.3080 - learning_rate: 0.0025\n",
      "Epoch 22/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 1.3605 - val_accuracy: 0.6069 - val_loss: 1.2843 - learning_rate: 0.0025\n",
      "Epoch 23/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 1.3458 - val_accuracy: 0.6011 - val_loss: 1.2990 - learning_rate: 0.0025\n",
      "Epoch 24/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5739 - loss: 1.3613 - val_accuracy: 0.6065 - val_loss: 1.2824 - learning_rate: 0.0025\n",
      "Epoch 25/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 1.3512 - val_accuracy: 0.6083 - val_loss: 1.2775 - learning_rate: 0.0025\n",
      "Epoch 26/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 1.3104 - val_accuracy: 0.6078 - val_loss: 1.2838 - learning_rate: 0.0025\n",
      "Epoch 27/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 1.3124 - val_accuracy: 0.6056 - val_loss: 1.2796 - learning_rate: 0.0025\n",
      "Epoch 28/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 1.3306 - val_accuracy: 0.6024 - val_loss: 1.2737 - learning_rate: 0.0025\n",
      "Epoch 29/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 1.3098 - val_accuracy: 0.6092 - val_loss: 1.2655 - learning_rate: 0.0025\n",
      "Epoch 30/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 1.3067 - val_accuracy: 0.6069 - val_loss: 1.2723 - learning_rate: 0.0025\n",
      "Epoch 31/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 1.3140 - val_accuracy: 0.6065 - val_loss: 1.2835 - learning_rate: 0.0025\n",
      "Epoch 32/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5953 - loss: 1.3168 - val_accuracy: 0.6159 - val_loss: 1.2614 - learning_rate: 0.0025\n",
      "Epoch 33/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5861 - loss: 1.3374 - val_accuracy: 0.6110 - val_loss: 1.2622 - learning_rate: 0.0025\n",
      "Epoch 34/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 1.2983 - val_accuracy: 0.6123 - val_loss: 1.2554 - learning_rate: 0.0025\n",
      "Epoch 35/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 1.2823 - val_accuracy: 0.6105 - val_loss: 1.2549 - learning_rate: 0.0025\n",
      "Epoch 36/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 1.2942 - val_accuracy: 0.6087 - val_loss: 1.2517 - learning_rate: 0.0025\n",
      "Epoch 37/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 1.2725 - val_accuracy: 0.6092 - val_loss: 1.2633 - learning_rate: 0.0025\n",
      "Epoch 38/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 1.2880 - val_accuracy: 0.6137 - val_loss: 1.2409 - learning_rate: 0.0025\n",
      "Epoch 39/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 1.2746 - val_accuracy: 0.6164 - val_loss: 1.2349 - learning_rate: 0.0025\n",
      "Epoch 40/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 1.2977 - val_accuracy: 0.6024 - val_loss: 1.2552 - learning_rate: 0.0025\n",
      "Epoch 41/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5904 - loss: 1.3217 - val_accuracy: 0.6087 - val_loss: 1.2445 - learning_rate: 0.0025\n",
      "Epoch 42/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5966 - loss: 1.3087 - val_accuracy: 0.6074 - val_loss: 1.2470 - learning_rate: 0.0025\n",
      "Epoch 43/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 1.2678 - val_accuracy: 0.6164 - val_loss: 1.2316 - learning_rate: 0.0012\n",
      "Epoch 44/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 1.2726 - val_accuracy: 0.6132 - val_loss: 1.2239 - learning_rate: 0.0012\n",
      "Epoch 45/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 1.2808 - val_accuracy: 0.6114 - val_loss: 1.2342 - learning_rate: 0.0012\n",
      "Epoch 46/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 1.2574 - val_accuracy: 0.6146 - val_loss: 1.2240 - learning_rate: 0.0012\n",
      "Epoch 47/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 1.2550 - val_accuracy: 0.6204 - val_loss: 1.2211 - learning_rate: 0.0012\n",
      "Epoch 48/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6102 - loss: 1.2441 - val_accuracy: 0.6159 - val_loss: 1.2162 - learning_rate: 0.0012\n",
      "Epoch 49/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 1.2428 - val_accuracy: 0.6200 - val_loss: 1.2232 - learning_rate: 0.0012\n",
      "Epoch 50/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 1.2335 - val_accuracy: 0.6218 - val_loss: 1.2142 - learning_rate: 0.0012\n",
      "Epoch 51/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 1.2421 - val_accuracy: 0.6168 - val_loss: 1.2178 - learning_rate: 0.0012\n",
      "Epoch 52/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6051 - loss: 1.2599 - val_accuracy: 0.6168 - val_loss: 1.2184 - learning_rate: 0.0012\n",
      "Epoch 53/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6051 - loss: 1.2623 - val_accuracy: 0.6150 - val_loss: 1.2106 - learning_rate: 0.0012\n",
      "Epoch 54/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 1.2570 - val_accuracy: 0.6137 - val_loss: 1.2236 - learning_rate: 0.0012\n",
      "Epoch 55/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 1.2407 - val_accuracy: 0.6200 - val_loss: 1.2139 - learning_rate: 0.0012\n",
      "Epoch 56/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 1.2484 - val_accuracy: 0.6276 - val_loss: 1.2081 - learning_rate: 0.0012\n",
      "Epoch 57/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 1.2383 - val_accuracy: 0.6209 - val_loss: 1.2121 - learning_rate: 0.0012\n",
      "Epoch 58/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 1.2432 - val_accuracy: 0.6182 - val_loss: 1.2130 - learning_rate: 0.0012\n",
      "Epoch 59/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 1.2549 - val_accuracy: 0.6209 - val_loss: 1.2040 - learning_rate: 0.0012\n",
      "Epoch 60/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 1.2457 - val_accuracy: 0.6209 - val_loss: 1.2054 - learning_rate: 0.0012\n",
      "Epoch 61/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 1.2347 - val_accuracy: 0.6168 - val_loss: 1.2023 - learning_rate: 0.0012\n",
      "Epoch 62/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 1.2268 - val_accuracy: 0.6254 - val_loss: 1.1975 - learning_rate: 0.0012\n",
      "Epoch 63/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 1.2350 - val_accuracy: 0.6209 - val_loss: 1.2042 - learning_rate: 0.0012\n",
      "Epoch 64/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 1.2391 - val_accuracy: 0.6231 - val_loss: 1.2051 - learning_rate: 0.0012\n",
      "Epoch 65/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 1.2446 - val_accuracy: 0.6200 - val_loss: 1.2024 - learning_rate: 0.0012\n",
      "Epoch 66/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6051 - loss: 1.2547 - val_accuracy: 0.6231 - val_loss: 1.1959 - learning_rate: 6.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 1.2275 - val_accuracy: 0.6276 - val_loss: 1.1841 - learning_rate: 6.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 1.2115 - val_accuracy: 0.6240 - val_loss: 1.1935 - learning_rate: 6.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 1.1986 - val_accuracy: 0.6240 - val_loss: 1.1909 - learning_rate: 6.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 1.2269 - val_accuracy: 0.6263 - val_loss: 1.1828 - learning_rate: 6.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 1.2103 - val_accuracy: 0.6276 - val_loss: 1.1843 - learning_rate: 6.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6233 - loss: 1.2033 - val_accuracy: 0.6236 - val_loss: 1.1917 - learning_rate: 6.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 1.2118 - val_accuracy: 0.6263 - val_loss: 1.1889 - learning_rate: 6.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.2156 - val_accuracy: 0.6272 - val_loss: 1.1830 - learning_rate: 3.1250e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 1.1777 - val_accuracy: 0.6299 - val_loss: 1.1832 - learning_rate: 3.1250e-04\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.6334 - loss: 1.1840\n",
      "Test Loss: 1.1880210638046265, Test Accuracy: 0.6370183825492859\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 및 평가\n",
    "def train_and_evaluate(dropout_rate=[0.3, 0.3, 0.3], learning_rate=0.005, batch_size=32):\n",
    "    model = build_mlp_model(dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
    "    \n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_np, y_train_machinery, \n",
    "        epochs=100, batch_size=batch_size, \n",
    "        validation_data=(X_val, y_val_machinery), \n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1  # 학습 진행 상황을 출력\n",
    "    )\n",
    "\n",
    "    # 성능 평가\n",
    "    loss, accuracy = model.evaluate(X_test_np, y_test_machinery, verbose=1)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "model, history = train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "087567b1-68ac-494b-9981-38ce70a3d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'torch.Tensor'>\n",
      "X_train_np type: <class 'numpy.ndarray'>\n",
      "X_train shape: torch.Size([8884, 120])\n",
      "X_train_np shape: (8884, 120)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train type:\", type(X_train))\n",
    "print(\"X_train_np type:\", type(X_train_np))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train_np shape:\", X_train_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd912c9-c409-485d-a1ab-822b74afba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with dropout_rate=[0.3, 0.4, 0.5], learning_rate=0.0001, batch_size=32\n",
      "Epoch 1/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3476 - loss: 2.8334 - val_accuracy: 0.5493 - val_loss: 1.8859 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4986 - loss: 1.9063 - val_accuracy: 0.5687 - val_loss: 1.4998 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 1.6818 - val_accuracy: 0.5727 - val_loss: 1.4658 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5508 - loss: 1.5990 - val_accuracy: 0.5844 - val_loss: 1.4090 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 1.5509 - val_accuracy: 0.5691 - val_loss: 1.3807 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5608 - loss: 1.5308 - val_accuracy: 0.5849 - val_loss: 1.3530 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5608 - loss: 1.4894 - val_accuracy: 0.5939 - val_loss: 1.3386 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 1.4635 - val_accuracy: 0.5970 - val_loss: 1.3294 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 1.4644 - val_accuracy: 0.5993 - val_loss: 1.3157 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5719 - loss: 1.4481 - val_accuracy: 0.5961 - val_loss: 1.3225 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 1.4100 - val_accuracy: 0.5957 - val_loss: 1.3122 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5710 - loss: 1.4323 - val_accuracy: 0.5970 - val_loss: 1.3082 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 1.3677 - val_accuracy: 0.5961 - val_loss: 1.2995 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5838 - loss: 1.3803 - val_accuracy: 0.5975 - val_loss: 1.3029 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 1.3895 - val_accuracy: 0.6038 - val_loss: 1.2922 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 1.3706 - val_accuracy: 0.5916 - val_loss: 1.2832 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5821 - loss: 1.3684 - val_accuracy: 0.6047 - val_loss: 1.2767 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 1.3410 - val_accuracy: 0.6038 - val_loss: 1.2826 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 1.3587 - val_accuracy: 0.6105 - val_loss: 1.2727 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 1.3635 - val_accuracy: 0.6078 - val_loss: 1.2658 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 1.3078 - val_accuracy: 0.6020 - val_loss: 1.2675 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 1.3580 - val_accuracy: 0.6056 - val_loss: 1.2638 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5821 - loss: 1.3545 - val_accuracy: 0.6060 - val_loss: 1.2729 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 1.3205 - val_accuracy: 0.6060 - val_loss: 1.2752 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 1.3358 - val_accuracy: 0.6132 - val_loss: 1.2555 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 1.3096 - val_accuracy: 0.6069 - val_loss: 1.2597 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5994 - loss: 1.2931 - val_accuracy: 0.6087 - val_loss: 1.2596 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5863 - loss: 1.3367 - val_accuracy: 0.6128 - val_loss: 1.2465 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 1.3111 - val_accuracy: 0.6105 - val_loss: 1.2565 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 1.3024 - val_accuracy: 0.6092 - val_loss: 1.2554 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 1.2890 - val_accuracy: 0.6101 - val_loss: 1.2512 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 1.2788 - val_accuracy: 0.6159 - val_loss: 1.2286 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 1.2366 - val_accuracy: 0.6168 - val_loss: 1.2327 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 1.2743 - val_accuracy: 0.6182 - val_loss: 1.2211 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 1.2638 - val_accuracy: 0.6137 - val_loss: 1.2205 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 1.2447 - val_accuracy: 0.6155 - val_loss: 1.2112 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 1.2426 - val_accuracy: 0.6141 - val_loss: 1.2113 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 1.2454 - val_accuracy: 0.6191 - val_loss: 1.2125 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 1.2445 - val_accuracy: 0.6218 - val_loss: 1.2058 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 1.2511 - val_accuracy: 0.6195 - val_loss: 1.2074 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 1.2357 - val_accuracy: 0.6204 - val_loss: 1.1983 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 1.2043 - val_accuracy: 0.6159 - val_loss: 1.1956 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 1.2540 - val_accuracy: 0.6231 - val_loss: 1.1937 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 1.2092 - val_accuracy: 0.6200 - val_loss: 1.1957 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 1.2167 - val_accuracy: 0.6281 - val_loss: 1.1957 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 1.2297 - val_accuracy: 0.6267 - val_loss: 1.1970 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 1.1995 - val_accuracy: 0.6263 - val_loss: 1.1876 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 1.2133 - val_accuracy: 0.6245 - val_loss: 1.1854 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6133 - loss: 1.2102 - val_accuracy: 0.6330 - val_loss: 1.1830 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 1.1875 - val_accuracy: 0.6308 - val_loss: 1.1839 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 1.1981 - val_accuracy: 0.6335 - val_loss: 1.1814 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 1.1721 - val_accuracy: 0.6317 - val_loss: 1.1797 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6180 - loss: 1.1913 - val_accuracy: 0.6281 - val_loss: 1.1795 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6149 - loss: 1.1985 - val_accuracy: 0.6303 - val_loss: 1.1789 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 1.1832 - val_accuracy: 0.6312 - val_loss: 1.1825 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 1.2092 - val_accuracy: 0.6353 - val_loss: 1.1765 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6240 - loss: 1.1698 - val_accuracy: 0.6326 - val_loss: 1.1738 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 1.1703 - val_accuracy: 0.6348 - val_loss: 1.1749 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 1.1833 - val_accuracy: 0.6380 - val_loss: 1.1694 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6272 - loss: 1.1736 - val_accuracy: 0.6344 - val_loss: 1.1731 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6247 - loss: 1.1825 - val_accuracy: 0.6303 - val_loss: 1.1764 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 1.1557 - val_accuracy: 0.6376 - val_loss: 1.1677 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 1.1733 - val_accuracy: 0.6317 - val_loss: 1.1718 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 1.1818 - val_accuracy: 0.6376 - val_loss: 1.1688 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 1.1615 - val_accuracy: 0.6353 - val_loss: 1.1714 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 1.1859 - val_accuracy: 0.6312 - val_loss: 1.1682 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.1681 - val_accuracy: 0.6312 - val_loss: 1.1674 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6321 - loss: 1.1447 - val_accuracy: 0.6385 - val_loss: 1.1650 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 1.1463 - val_accuracy: 0.6394 - val_loss: 1.1621 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6349 - loss: 1.1482 - val_accuracy: 0.6398 - val_loss: 1.1649 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6268 - loss: 1.1549 - val_accuracy: 0.6330 - val_loss: 1.1629 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 1.1581 - val_accuracy: 0.6371 - val_loss: 1.1657 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6331 - loss: 1.1600 - val_accuracy: 0.6371 - val_loss: 1.1639 - learning_rate: 6.2500e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 1.1227 - val_accuracy: 0.6380 - val_loss: 1.1615 - learning_rate: 6.2500e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6394 - loss: 1.1225 - val_accuracy: 0.6389 - val_loss: 1.1598 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6328 - loss: 1.1539 - val_accuracy: 0.6371 - val_loss: 1.1600 - learning_rate: 6.2500e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 1.1461 - val_accuracy: 0.6376 - val_loss: 1.1591 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6267 - loss: 1.1411 - val_accuracy: 0.6371 - val_loss: 1.1586 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 1.1436 - val_accuracy: 0.6398 - val_loss: 1.1584 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 1.1454 - val_accuracy: 0.6389 - val_loss: 1.1580 - learning_rate: 6.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6291 - loss: 1.1435 - val_accuracy: 0.6389 - val_loss: 1.1576 - learning_rate: 6.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6267 - loss: 1.1453 - val_accuracy: 0.6380 - val_loss: 1.1578 - learning_rate: 6.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6394 - loss: 1.1269 - val_accuracy: 0.6403 - val_loss: 1.1577 - learning_rate: 6.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 1.1615 - val_accuracy: 0.6394 - val_loss: 1.1573 - learning_rate: 6.2500e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 1.1449 - val_accuracy: 0.6398 - val_loss: 1.1569 - learning_rate: 6.2500e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 1.1415 - val_accuracy: 0.6389 - val_loss: 1.1561 - learning_rate: 6.2500e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 1.1324 - val_accuracy: 0.6376 - val_loss: 1.1549 - learning_rate: 6.2500e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6324 - loss: 1.1267 - val_accuracy: 0.6367 - val_loss: 1.1550 - learning_rate: 6.2500e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 1.1358 - val_accuracy: 0.6357 - val_loss: 1.1552 - learning_rate: 6.2500e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 1.1708 - val_accuracy: 0.6389 - val_loss: 1.1551 - learning_rate: 6.2500e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 1.1267 - val_accuracy: 0.6380 - val_loss: 1.1554 - learning_rate: 3.1250e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6296 - loss: 1.1417 - val_accuracy: 0.6421 - val_loss: 1.1541 - learning_rate: 3.1250e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6406 - loss: 1.1052 - val_accuracy: 0.6407 - val_loss: 1.1544 - learning_rate: 3.1250e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 1.1363 - val_accuracy: 0.6416 - val_loss: 1.1541 - learning_rate: 3.1250e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6342 - loss: 1.1410 - val_accuracy: 0.6421 - val_loss: 1.1542 - learning_rate: 3.1250e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6406 - loss: 1.1288 - val_accuracy: 0.6412 - val_loss: 1.1529 - learning_rate: 1.5625e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6359 - loss: 1.1309 - val_accuracy: 0.6403 - val_loss: 1.1533 - learning_rate: 1.5625e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6259 - loss: 1.1447 - val_accuracy: 0.6416 - val_loss: 1.1511 - learning_rate: 1.5625e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 1.1297 - val_accuracy: 0.6430 - val_loss: 1.1532 - learning_rate: 1.5625e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6296 - loss: 1.1479 - val_accuracy: 0.6430 - val_loss: 1.1529 - learning_rate: 1.5625e-05\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.6402 - loss: 1.1387\n",
      "Test Loss: 1.1579055786132812, Test Accuracy: 0.6427800059318542\n",
      "\n",
      "Training with dropout_rate=[0.3, 0.4, 0.5], learning_rate=0.0001, batch_size=64\n",
      "Epoch 1/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3373 - loss: 2.9928 - val_accuracy: 0.4741 - val_loss: 2.5611 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5115 - loss: 1.8729 - val_accuracy: 0.5543 - val_loss: 1.8903 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5350 - loss: 1.6815 - val_accuracy: 0.5687 - val_loss: 1.5020 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5511 - loss: 1.6047 - val_accuracy: 0.5912 - val_loss: 1.4126 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5582 - loss: 1.5253 - val_accuracy: 0.5957 - val_loss: 1.3672 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 1.4847 - val_accuracy: 0.5957 - val_loss: 1.3377 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 1.4462 - val_accuracy: 0.5984 - val_loss: 1.3341 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5763 - loss: 1.4549 - val_accuracy: 0.5988 - val_loss: 1.3272 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 1.4474 - val_accuracy: 0.6092 - val_loss: 1.3031 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 1.3804 - val_accuracy: 0.6024 - val_loss: 1.2930 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 1.3868 - val_accuracy: 0.6110 - val_loss: 1.2973 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 1.3470 - val_accuracy: 0.6074 - val_loss: 1.2690 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 1.3383 - val_accuracy: 0.6096 - val_loss: 1.2756 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 1.3366 - val_accuracy: 0.6074 - val_loss: 1.2680 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 1.3305 - val_accuracy: 0.6123 - val_loss: 1.2732 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 1.3146 - val_accuracy: 0.6096 - val_loss: 1.2697 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 1.2975 - val_accuracy: 0.6227 - val_loss: 1.2495 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5937 - loss: 1.3059 - val_accuracy: 0.6092 - val_loss: 1.2434 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 1.3171 - val_accuracy: 0.6101 - val_loss: 1.2302 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 1.3096 - val_accuracy: 0.6137 - val_loss: 1.2317 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 1.2859 - val_accuracy: 0.6150 - val_loss: 1.2282 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 1.2639 - val_accuracy: 0.6123 - val_loss: 1.2375 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 1.3288 - val_accuracy: 0.6191 - val_loss: 1.2242 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 1.2467 - val_accuracy: 0.6227 - val_loss: 1.2203 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 1.2622 - val_accuracy: 0.6128 - val_loss: 1.2416 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6088 - loss: 1.2642 - val_accuracy: 0.6200 - val_loss: 1.2399 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6124 - loss: 1.2568 - val_accuracy: 0.6204 - val_loss: 1.2114 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 1.2685 - val_accuracy: 0.6222 - val_loss: 1.2129 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6130 - loss: 1.2472 - val_accuracy: 0.6200 - val_loss: 1.2213 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 1.2523 - val_accuracy: 0.6204 - val_loss: 1.2144 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 1.2575 - val_accuracy: 0.6299 - val_loss: 1.1862 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6207 - loss: 1.2267 - val_accuracy: 0.6276 - val_loss: 1.1854 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 1.2013 - val_accuracy: 0.6303 - val_loss: 1.1799 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 1.1951 - val_accuracy: 0.6308 - val_loss: 1.1753 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6170 - loss: 1.1873 - val_accuracy: 0.6330 - val_loss: 1.1747 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 1.1777 - val_accuracy: 0.6389 - val_loss: 1.1616 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6214 - loss: 1.1792 - val_accuracy: 0.6303 - val_loss: 1.1682 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 1.1833 - val_accuracy: 0.6376 - val_loss: 1.1575 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 1.1944 - val_accuracy: 0.6335 - val_loss: 1.1636 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6299 - loss: 1.1795 - val_accuracy: 0.6317 - val_loss: 1.1717 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6217 - loss: 1.1818 - val_accuracy: 0.6330 - val_loss: 1.1578 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6390 - loss: 1.1566 - val_accuracy: 0.6362 - val_loss: 1.1491 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 1.1414 - val_accuracy: 0.6380 - val_loss: 1.1479 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6361 - loss: 1.1444 - val_accuracy: 0.6362 - val_loss: 1.1452 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 1.1324 - val_accuracy: 0.6407 - val_loss: 1.1489 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6448 - loss: 1.1087 - val_accuracy: 0.6452 - val_loss: 1.1428 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 1.1456 - val_accuracy: 0.6452 - val_loss: 1.1400 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6265 - loss: 1.1318 - val_accuracy: 0.6479 - val_loss: 1.1387 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6398 - loss: 1.1257 - val_accuracy: 0.6376 - val_loss: 1.1399 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6417 - loss: 1.1314 - val_accuracy: 0.6425 - val_loss: 1.1356 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6403 - loss: 1.1360 - val_accuracy: 0.6443 - val_loss: 1.1344 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m127/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 1.1462"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining with dropout_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 10\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(dropout_rate, learning_rate, batch_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_machinery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_machinery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습 진행 상황을 출력\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 성능 평가\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_np, y_test_machinery, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:345\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    336\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    337\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m     )\n\u001b[1;32m--> 345\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    357\u001b[0m }\n\u001b[0;32m    358\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:431\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:689\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 689\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    691\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    692\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    693\u001b[0m         ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3509\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3508\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3509\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3512\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 조정\n",
    "dropout_rates = [[0.3, 0.4, 0.5], [0.2, 0.3, 0.4]] \n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "batch_sizes = [32, 64]\n",
    "\n",
    "# 여러 하이퍼파라미터 조합에 대해 학습 및 평가\n",
    "for dropout_rate in dropout_rates:\n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"\\nTraining with dropout_rate={dropout_rate}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "            train_and_evaluate(dropout_rate, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41084a8-2ba7-4c8a-9677-7fbf9d361119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
