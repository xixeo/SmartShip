{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de827958-8584-401f-9d62-1c3ecb4de85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformers import AdamW\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9715e073-3876-4b8a-8d27-9987e232a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('filtered_30_filled_money.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94099074-a4c5-4800-877c-2d657cd73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bd270e-abd8-44ab-a486-48469d26853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f5153d-187c-494f-bc74-1194a8f7c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates = {'USD': 1, 'KRW': 0.00078, 'EUR': 1.18, 'JPY': 0.0091}\n",
    "\n",
    "# usd기준해서 금액 통일함 \n",
    "data['converted_price'] = data.apply(lambda x: x['견적단가'] * exchange_rates[x['견적화폐']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b45129-3e52-490c-a953-21ef3b1756d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# '견적화폐' 컬럼을 OneHotEncoder를 통해 인코딩\n",
    "currency_ohe = OneHotEncoder(sparse_output=False) \n",
    "currency_encoded = currency_ohe.fit_transform(data[['견적화폐']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468f76da-0af7-455f-86ba-f4ccd69b12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['converted_price_log'] = np.log1p(data['converted_price'])  # 로그 변환된 가격\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4655b8ab-ae1b-4280-b44b-1d0d2ae15695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "machinery_label_encoder = LabelEncoder()\n",
    "y_machinery= machinery_label_encoder.fit_transform(data['Machinery'])\n",
    "\n",
    "assembly_label_encoder = LabelEncoder()\n",
    "y_assembly = assembly_label_encoder.fit_transform(data['Assembly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8522452-bdfc-4c8a-9027-d460b64428bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_text shape: (13882,)\n",
      "currency_encoded shape: (13882, 4)\n",
      "converted_price shape: (13882,)\n",
      "X shape after concatenation: (13882, 6)\n",
      "X_train size: (10029, 6)\n",
      "X_val size: (1770, 6)\n",
      "X_test size: (2083, 6)\n"
     ]
    }
   ],
   "source": [
    "# train_test split 을 위해 하나로 모으고, 분할하고 다시 텍스트랑 추가피쳐로 분리해줄거임 \n",
    "\n",
    "# 1. 텍스트 + 추가 피처 결합\n",
    "X = np.concatenate([\n",
    "    data['combined_text'].values.reshape(-1, 1),  # 2차원 배열로 바꿔서 결합해줌 \n",
    "    currency_encoded, \n",
    "    data['converted_price_log'].values.reshape(-1, 1)  # 통일한단가\n",
    "], axis=1)\n",
    "\n",
    "X_train_val, X_test, y_train_val_machinery, y_test_machinery, y_train_val_assembly, y_test_assembly = train_test_split(\n",
    "    X, y_machinery, y_assembly, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_assembly)  # stratify는 주로 메인 레이블 기준으로 설정\n",
    "\n",
    "X_train, X_val, y_train_machinery, y_val_machinery, y_train_assembly, y_val_assembly = train_test_split(\n",
    "    X_train_val, y_train_val_machinery, y_train_val_assembly, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_train_val_assembly)  # 다시 stratify 기준으로 설정\n",
    "\n",
    "# 크기 확인\n",
    "print(f\"combined_text shape: {data['combined_text'].shape}\")\n",
    "print(f\"currency_encoded shape: {currency_encoded.shape}\")\n",
    "print(f\"converted_price shape: {data['converted_price'].shape}\")\n",
    "print(f\"X shape after concatenation: {X.shape}\")\n",
    "\n",
    "print(f\"X_train size: {X_train.shape}\")\n",
    "print(f\"X_val size: {X_val.shape}\")\n",
    "print(f\"X_test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1205a554-0603-4f20-b3b1-bbf075614ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분리\n",
    "train_combined_text = X_train[:, 0]\n",
    "val_combined_text = X_val[:, 0]\n",
    "test_combined_text = X_test[:, 0]\n",
    "\n",
    "# 추가 피처 분리 (currency_encoded와 로그 변환된 가격)\n",
    "train_extra_features = X_train[:, 1:]\n",
    "val_extra_features = X_val[:, 1:]\n",
    "test_extra_features = X_test[:, 1:]\n",
    "\n",
    "# 값이 float으로 변환되도록 nan 처리\n",
    "train_extra_features = np.nan_to_num(train_extra_features, nan=0.0).astype(float)\n",
    "val_extra_features = np.nan_to_num(val_extra_features, nan=0.0).astype(float)\n",
    "test_extra_features = np.nan_to_num(test_extra_features, nan=0.0).astype(float)\n",
    "\n",
    "# 스케일링 적용\n",
    "scaler = StandardScaler()\n",
    "train_extra_features = scaler.fit_transform(train_extra_features)\n",
    "val_extra_features = scaler.transform(val_extra_features)\n",
    "test_extra_features = scaler.transform(test_extra_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e1270e8-9b60-4454-9851-b0c1d80e44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13736\\840112757.py:3: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  train_extra_features_tensor = torch.tensor(train_extra_features, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor로 변환 후 디바이스 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_extra_features_tensor = torch.tensor(train_extra_features, dtype=torch.float32).to(device)\n",
    "val_extra_features_tensor = torch.tensor(val_extra_features, dtype=torch.float32).to(device)\n",
    "test_extra_features_tensor = torch.tensor(test_extra_features, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12affe13-a536-4714-913c-70912dd1abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저 (텍스트처리)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44558653-ff97-42cb-a192-c6b0dd9e8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X중 텍스트만 BERT 입력 형식으로 변환\n",
    "def encode_data(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_machinery_encodings = encode_data(train_combined_text)\n",
    "val_machinery_encodings = encode_data(val_combined_text)\n",
    "test_machinery_encodings = encode_data(test_combined_text)\n",
    "\n",
    "# Assembly용 인코딩\n",
    "train_assembly_encodings = encode_data(train_combined_text)  # 같은 텍스트지만 독립적으로 관리\n",
    "val_assembly_encodings = encode_data(val_combined_text)\n",
    "test_assembly_encodings = encode_data(test_combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e97158-70b4-4ece-99f5-8bf3c78f476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_machinery_dataset = TensorDataset(\n",
    "    train_machinery_encodings['input_ids'],\n",
    "    train_machinery_encodings['attention_mask'],\n",
    "    train_extra_features_tensor,\n",
    "    torch.tensor(y_train_machinery, dtype=torch.long).to(device)  # Machinery 레이블\n",
    ")\n",
    "\n",
    "val_machinery_dataset = TensorDataset(\n",
    "    val_machinery_encodings['input_ids'],\n",
    "    val_machinery_encodings['attention_mask'],\n",
    "    val_extra_features_tensor,\n",
    "    torch.tensor(y_val_machinery, dtype=torch.long).to(device)\n",
    ")\n",
    "\n",
    "test_machinery_dataset = TensorDataset(\n",
    "    test_machinery_encodings['input_ids'],\n",
    "    test_machinery_encodings['attention_mask'],\n",
    "    test_extra_features_tensor,\n",
    "    torch.tensor(y_test_machinery, dtype=torch.long).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c6fc79-7f45-4a76-b7ca-001707c64f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train size: (10029,)\n",
      "y_val size: (1770,)\n",
      "y_test size: (2083,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train size: {y_train_machinery.shape}\")\n",
    "print(f\"y_val size: {y_val_machinery.shape}\")\n",
    "print(f\"y_test size: {y_test_machinery.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c5b89d-d987-4d05-9d72-e1ba20c3e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DataLoader 생성\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader_machinery = DataLoader(train_machinery_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_machinery  = DataLoader(val_machinery_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader_machinery = DataLoader(test_machinery_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a8452c-0350-448f-b5c5-641b8e512ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMachinery(nn.Module):\n",
    "    def __init__(self, num_machinery_labels, extra_features_dim):\n",
    "        super(BertForMachinery, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc1 = nn.Linear(773, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.machinery_classifier = nn.Linear(256, num_machinery_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, extra_features):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        if extra_features.dim() == 1:\n",
    "            extra_features = extra_features.unsqueeze(1)\n",
    "        \n",
    "        machinery_combined_features = torch.cat((pooled_output, extra_features), dim=1)\n",
    "        x = self.fc1(machinery_combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        machinery_outputs = self.machinery_classifier(x)\n",
    "        \n",
    "        return machinery_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8e4c15-b3a6-4aad-bd4b-94fe86c70dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install conda-forge::optuna -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f8589d-d1e7-4fcd-9d91-0634e8e6249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "772d3add-051f-4e5c-b5d0-c9c7ce008715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_machinery(model, dataloader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]  # 순서 수정\n",
    "        \n",
    "        if labels.dim() > 1:\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "        labels = labels.to(torch.int64)  # CrossEntropyLoss에 맞게 변환\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9990e338-c952-4a12-ba6e-b5d960e884ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# 평가 함수 - logits-62개짜리 각각의 자신감\n",
    "def evaluate_machinery(model, dataloader, device, loss_fn_machinery):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    machinery_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = loss_fn_machinery(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            machinery_predictions.append(predicted.cpu().numpy())  # 리스트에 추가\n",
    "            \n",
    "            # 정확도 계산\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    machinery_predictions = np.concatenate(machinery_predictions, axis=0)  # 최종 예측값\n",
    "    \n",
    "    return avg_loss, accuracy, machinery_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100fc00f-28d4-4923-a2db-04d7d02be454",
   "metadata": {},
   "source": [
    "> class, train, evaluate define 하고 모델 피팅 전 \"하이퍼파라미터 튜닝\" => 최적의 param 나온 걸로 모델 정의하고 피팅함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b627579-896d-4f95-a0dc-fd395199d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-20 10:15:53,588] A new study created in memory with name: no-name-dedb0b86-950e-4fcb-b45e-d8628cb10483\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13976\\2021244979.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # 1e-5 ~ 1e-2\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13976\\2021244979.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)         # 0.1 ~ 0.5\n",
      "  0%|                                                                                          | 0/627 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "[I 2024-09-20 10:18:57,436] Trial 0 finished with value: 0.576271186440678 and parameters: {'learning_rate': 0.001013134137284379, 'dropout_rate': 0.4811521460895716, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:11<00:00,  3.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.62it/s]\n",
      "[I 2024-09-20 10:22:22,786] Trial 1 finished with value: 0.211864406779661 and parameters: {'learning_rate': 0.0001480200507825191, 'dropout_rate': 0.44082635754220845, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.78it/s]\n",
      "[I 2024-09-20 10:25:27,010] Trial 2 finished with value: 0.211864406779661 and parameters: {'learning_rate': 4.839348383598535e-05, 'dropout_rate': 0.431713045330951, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.83it/s]\n",
      "[I 2024-09-20 10:28:47,229] Trial 3 finished with value: 0.211864406779661 and parameters: {'learning_rate': 0.0026729103622046674, 'dropout_rate': 0.41952480113041835, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 10:31:49,703] Trial 4 finished with value: 0.4559322033898305 and parameters: {'learning_rate': 0.00021651120319222223, 'dropout_rate': 0.49471446229454286, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  7.97it/s]\n",
      "[I 2024-09-20 10:34:53,387] Trial 5 finished with value: 0.3587570621468927 and parameters: {'learning_rate': 0.003327379302018792, 'dropout_rate': 0.3258110437133881, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.85it/s]\n",
      "[I 2024-09-20 10:37:57,066] Trial 6 finished with value: 0.5508474576271186 and parameters: {'learning_rate': 0.003182431273002245, 'dropout_rate': 0.4373771432344179, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:52<00:00,  3.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.74it/s]\n",
      "[I 2024-09-20 10:41:03,028] Trial 7 finished with value: 0.211864406779661 and parameters: {'learning_rate': 5.482046577738807e-05, 'dropout_rate': 0.2361810293403971, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.62it/s]\n",
      "[I 2024-09-20 10:44:07,501] Trial 8 finished with value: 0.211864406779661 and parameters: {'learning_rate': 1.7961028342393543e-05, 'dropout_rate': 0.2349248341518686, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.75it/s]\n",
      "[I 2024-09-20 10:47:10,958] Trial 9 finished with value: 0.211864406779661 and parameters: {'learning_rate': 8.701571752685895e-05, 'dropout_rate': 0.10938275149996751, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:11<00:00,  3.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  8.24it/s]\n",
      "[I 2024-09-20 10:50:37,085] Trial 10 finished with value: 0.211864406779661 and parameters: {'learning_rate': 0.0007487909853973806, 'dropout_rate': 0.28428958301318097, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:51<00:00,  3.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "[I 2024-09-20 10:53:42,216] Trial 11 finished with value: 0.32655367231638416 and parameters: {'learning_rate': 0.008901227016884172, 'dropout_rate': 0.49541543282296296, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:54<00:00,  3.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.70it/s]\n",
      "[I 2024-09-20 10:56:50,554] Trial 12 finished with value: 0.5632768361581921 and parameters: {'learning_rate': 0.0007779159359084243, 'dropout_rate': 0.36762585981029333, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:52<00:00,  3.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.94it/s]\n",
      "[I 2024-09-20 10:59:56,342] Trial 13 finished with value: 0.56045197740113 and parameters: {'learning_rate': 0.0006620857617662046, 'dropout_rate': 0.3584262204241947, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:10<00:00,  3.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.63it/s]\n",
      "[I 2024-09-20 11:03:21,039] Trial 14 finished with value: 0.37401129943502825 and parameters: {'learning_rate': 0.0006874953497047672, 'dropout_rate': 0.3834527717504386, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:53<00:00,  3.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 11:06:27,648] Trial 15 finished with value: 0.53954802259887 and parameters: {'learning_rate': 0.0013612325107741085, 'dropout_rate': 0.28866622195949676, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.95it/s]\n",
      "[I 2024-09-20 11:09:30,416] Trial 16 finished with value: 0.5389830508474577 and parameters: {'learning_rate': 0.0004245820455646285, 'dropout_rate': 0.13487021435225668, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:47<00:00,  3.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.95it/s]\n",
      "[I 2024-09-20 11:12:31,165] Trial 17 finished with value: 0.37401129943502825 and parameters: {'learning_rate': 0.009678172020941388, 'dropout_rate': 0.38438373831222483, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.88it/s]\n",
      "[I 2024-09-20 11:15:51,404] Trial 18 finished with value: 0.35988700564971754 and parameters: {'learning_rate': 0.0014405327871957324, 'dropout_rate': 0.18045714907151544, 'optimizer': 'adamw'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "[I 2024-09-20 11:18:53,651] Trial 19 finished with value: 0.5344632768361582 and parameters: {'learning_rate': 0.00038024583030741633, 'dropout_rate': 0.468525414201506, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.576271186440678.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:51<00:00,  3.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  8.33it/s]\n",
      "[I 2024-09-20 11:21:58,860] Trial 20 finished with value: 0.5779661016949152 and parameters: {'learning_rate': 0.0013771081833928132, 'dropout_rate': 0.3538491020710155, 'optimizer': 'sgd'}. Best is trial 20 with value: 0.5779661016949152.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:52<00:00,  3.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.65it/s]\n",
      "[I 2024-09-20 11:25:05,302] Trial 21 finished with value: 0.5389830508474577 and parameters: {'learning_rate': 0.0015607180355868902, 'dropout_rate': 0.33753845063802906, 'optimizer': 'sgd'}. Best is trial 20 with value: 0.5779661016949152.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:55<00:00,  3.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.60it/s]\n",
      "[I 2024-09-20 11:28:13,963] Trial 22 finished with value: 0.46497175141242936 and parameters: {'learning_rate': 0.005120813438877185, 'dropout_rate': 0.39744165355400163, 'optimizer': 'sgd'}. Best is trial 20 with value: 0.5779661016949152.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:53<00:00,  3.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  8.52it/s]\n",
      "[I 2024-09-20 11:31:20,725] Trial 23 finished with value: 0.5689265536723164 and parameters: {'learning_rate': 0.0010707041803687581, 'dropout_rate': 0.2562813617344705, 'optimizer': 'sgd'}. Best is trial 20 with value: 0.5779661016949152.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:52<00:00,  3.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.71it/s]\n",
      "[I 2024-09-20 11:34:26,280] Trial 24 finished with value: 0.5898305084745763 and parameters: {'learning_rate': 0.001615087572794635, 'dropout_rate': 0.2273761601207174, 'optimizer': 'sgd'}. Best is trial 24 with value: 0.5898305084745763.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.95it/s]\n",
      "[I 2024-09-20 11:37:29,135] Trial 25 finished with value: 0.6186440677966102 and parameters: {'learning_rate': 0.002361194991533609, 'dropout_rate': 0.18317574580310583, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.94it/s]\n",
      "[I 2024-09-20 11:40:47,341] Trial 26 finished with value: 0.3446327683615819 and parameters: {'learning_rate': 0.002148411418107354, 'dropout_rate': 0.18782505079131867, 'optimizer': 'adamw'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:52<00:00,  3.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.60it/s]\n",
      "[I 2024-09-20 11:43:52,996] Trial 27 finished with value: 0.35480225988700564 and parameters: {'learning_rate': 0.004594446706870838, 'dropout_rate': 0.17133433781495314, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:54<00:00,  3.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.59it/s]\n",
      "[I 2024-09-20 11:47:00,843] Trial 28 finished with value: 0.3649717514124294 and parameters: {'learning_rate': 0.005824727561978353, 'dropout_rate': 0.21023489948873045, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:51<00:00,  3.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.79it/s]\n",
      "[I 2024-09-20 11:50:06,013] Trial 29 finished with value: 0.5683615819209039 and parameters: {'learning_rate': 0.001813763928652335, 'dropout_rate': 0.15230717955841094, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:51<00:00,  3.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "[I 2024-09-20 11:53:10,993] Trial 30 finished with value: 0.4101694915254237 and parameters: {'learning_rate': 0.00026358182988921283, 'dropout_rate': 0.271200199992199, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 11:56:13,942] Trial 31 finished with value: 0.5949152542372881 and parameters: {'learning_rate': 0.0010673600302074193, 'dropout_rate': 0.2067970604047851, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:51<00:00,  3.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.86it/s]\n",
      "[I 2024-09-20 11:59:18,260] Trial 32 finished with value: 0.5700564971751413 and parameters: {'learning_rate': 0.000527433741580148, 'dropout_rate': 0.20365798918380365, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 12:02:20,766] Trial 33 finished with value: 0.5598870056497175 and parameters: {'learning_rate': 0.0010290017250282806, 'dropout_rate': 0.31628350099103014, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.71it/s]\n",
      "[I 2024-09-20 12:05:40,753] Trial 34 finished with value: 0.27796610169491526 and parameters: {'learning_rate': 0.0024786225896260153, 'dropout_rate': 0.21571973549686346, 'optimizer': 'adamw'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:48<00:00,  3.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "[I 2024-09-20 12:08:42,589] Trial 35 finished with value: 0.5983050847457627 and parameters: {'learning_rate': 0.003971902094103017, 'dropout_rate': 0.1491567679048052, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.89it/s]\n",
      "[I 2024-09-20 12:11:45,436] Trial 36 finished with value: 0.588135593220339 and parameters: {'learning_rate': 0.004109962792513249, 'dropout_rate': 0.10010726112162552, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.85it/s]\n",
      "[I 2024-09-20 12:14:47,654] Trial 37 finished with value: 0.37796610169491524 and parameters: {'learning_rate': 0.00017477973885380576, 'dropout_rate': 0.14135171878709146, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 12:18:07,918] Trial 38 finished with value: 0.34519774011299437 and parameters: {'learning_rate': 0.006974308887899964, 'dropout_rate': 0.16083977984376813, 'optimizer': 'adamw'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.56it/s]\n",
      "[I 2024-09-20 12:21:11,001] Trial 39 finished with value: 0.3581920903954802 and parameters: {'learning_rate': 0.0031914850832929684, 'dropout_rate': 0.24210420117606313, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "[I 2024-09-20 12:24:14,913] Trial 40 finished with value: 0.5932203389830508 and parameters: {'learning_rate': 0.0024027786124053967, 'dropout_rate': 0.18972535565812593, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.82it/s]\n",
      "[I 2024-09-20 12:27:17,856] Trial 41 finished with value: 0.611864406779661 and parameters: {'learning_rate': 0.0024083438611716738, 'dropout_rate': 0.1252150360947482, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:48<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.85it/s]\n",
      "[I 2024-09-20 12:30:19,976] Trial 42 finished with value: 0.5909604519774011 and parameters: {'learning_rate': 0.0024034038482800934, 'dropout_rate': 0.13176336907167516, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:48<00:00,  3.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "[I 2024-09-20 12:33:22,073] Trial 43 finished with value: 0.5677966101694916 and parameters: {'learning_rate': 0.0033157392392933905, 'dropout_rate': 0.12024646259667214, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:49<00:00,  3.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.80it/s]\n",
      "[I 2024-09-20 12:36:24,368] Trial 44 finished with value: 0.3649717514124294 and parameters: {'learning_rate': 0.006872498500869527, 'dropout_rate': 0.1928511077475646, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:50<00:00,  3.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.87it/s]\n",
      "[I 2024-09-20 12:39:27,603] Trial 45 finished with value: 0.3655367231638418 and parameters: {'learning_rate': 0.004124918981625993, 'dropout_rate': 0.14864832959846208, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:48<00:00,  3.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "[I 2024-09-20 12:42:28,939] Trial 46 finished with value: 0.211864406779661 and parameters: {'learning_rate': 1.422737325762167e-05, 'dropout_rate': 0.17007038368492516, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:47<00:00,  3.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.93it/s]\n",
      "[I 2024-09-20 12:45:29,760] Trial 47 finished with value: 0.576271186440678 and parameters: {'learning_rate': 0.002161571618294078, 'dropout_rate': 0.11781984895618294, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [02:47<00:00,  3.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.79it/s]\n",
      "[I 2024-09-20 12:48:30,704] Trial 48 finished with value: 0.5615819209039548 and parameters: {'learning_rate': 0.0009223820286102329, 'dropout_rate': 0.16634868025488628, 'optimizer': 'sgd'}. Best is trial 25 with value: 0.6186440677966102.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:09<00:00,  3.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.84it/s]\n",
      "[I 2024-09-20 12:51:53,110] Trial 49 finished with value: 0.6163841807909605 and parameters: {'learning_rate': 0.00010577773062341664, 'dropout_rate': 0.19414312819248103, 'optimizer': 'adamw'}. Best is trial 25 with value: 0.6186440677966102.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.002361194991533609, 'dropout_rate': 0.18317574580310583, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AdamW\n",
    "\n",
    "loss_fn_machinery=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Objective Function 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # 1e-5 ~ 1e-2\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)         # 0.1 ~ 0.5\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adamw', 'sgd'])  # AdamW, SGD 선택\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = BertForMachinery(num_machinery_labels=len(machinery_label_encoder.classes_), extra_features_dim=10)\n",
    "    model.dropout = nn.Dropout(dropout_rate)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer 선택\n",
    "    if optimizer_name == 'adamw':\n",
    "        optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    else:  # 'sgd'\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    # Training 및 Validation 평가\n",
    "    train_loss = train_machinery(model, train_loader_machinery, optimizer, device, loss_fn_machinery)\n",
    "    val_loss, val_acc, machinery_predictions = evaluate_machinery(model, val_loader_machinery, device, loss_fn_machinery)\n",
    "\n",
    "    return val_acc  # Validation accuracy 최대화\n",
    "\n",
    "# Optuna로 Hyperparameter Optimization 실행\n",
    "study = optuna.create_study(direction='maximize')  # 최대화 방향 설정\n",
    "study.optimize(objective, n_trials=50)  # 50번의 시도\n",
    "\n",
    "# 최적 하이퍼파라미터 출력\n",
    "print(\"Best hyperparameters: \", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62779f71-0ceb-44dd-be47-bf9b697296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "# best_params = study.best_trial.params\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 4. 최적 하이퍼파라미터로 모델 정의 및 학습\n",
    "#machinery_model = BertForMachinery(num_machinery_labels=len(machinery_label_encoder.classes_), extra_features_dim=10).to(device)\n",
    "# machinery_model.dropout = nn.Dropout(best_params['dropout_rate'])\n",
    "machinery_model = BertForMachinery(num_machinery_labels=len(machinery_label_encoder.classes_), extra_features_dim=10) \n",
    "machinery_model.to(device)\n",
    "\n",
    "optimizer_machinery = AdamW(machinery_model.parameters(), lr=3e-5)\n",
    "loss_fn_machinery=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b4db600-e114-4be6-834e-5d153ba444b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 및 학습률 스케줄러 설정\n",
    "#optimizer_machinery = (\n",
    "#    AdamW(machinery_model.parameters(), lr=best_params['learning_rate']) \n",
    "#    if best_params['optimizer'] == 'adamw' \n",
    "#    else torch.optim.SGD(machinery_model.parameters(), lr=best_params['learning_rate'], momentum=0.9)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1505a3-0786-4beb-82b8-b897c930f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "381695c8-99af-44f7-b5d6-425661364fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/627 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 2.0721, Val Loss: 1.3901, Val Acc: 0.6356, Test Acc: 0.6323\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 1.2565, Val Loss: 1.0643, Val Acc: 0.7023, Test Acc: 0.6976\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.9909, Val Loss: 0.9139, Val Acc: 0.7390, Test Acc: 0.7331\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.8381, Val Loss: 0.7969, Val Acc: 0.7576, Test Acc: 0.7504\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.7175, Val Loss: 0.7505, Val Acc: 0.7780, Test Acc: 0.7643\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:08<00:00,  3.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.6354, Val Loss: 0.6658, Val Acc: 0.7921, Test Acc: 0.7926\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:07<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.5699, Val Loss: 0.6159, Val Acc: 0.8102, Test Acc: 0.8080\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.5121, Val Loss: 0.6201, Val Acc: 0.8051, Test Acc: 0.8051\n",
      "Trigger Times (Machinery): 1\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:05<00:00,  3.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4584, Val Loss: 0.5659, Val Acc: 0.8254, Test Acc: 0.8248\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:09<00:00,  3.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4281, Val Loss: 0.5486, Val Acc: 0.8260, Test Acc: 0.8301\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:10<00:00,  3.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  8.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.4014, Val Loss: 0.5530, Val Acc: 0.8266, Test Acc: 0.8181\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:11<00:00,  3.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3789, Val Loss: 0.5754, Val Acc: 0.8367, Test Acc: 0.8344\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [05:05<00:00,  2.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:25<00:00,  4.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:21<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3573, Val Loss: 0.5412, Val Acc: 0.8429, Test Acc: 0.8382\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [04:04<00:00,  2.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3326, Val Loss: 0.5363, Val Acc: 0.8446, Test Acc: 0.8377\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.3177, Val Loss: 0.5397, Val Acc: 0.8345, Test Acc: 0.8301\n",
      "Trigger Times (Machinery): 1\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:16<00:00,  3.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:13<00:00,  8.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:11<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2998, Val Loss: 0.5457, Val Acc: 0.8407, Test Acc: 0.8373\n",
      "Trigger Times (Machinery): 2\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 627/627 [03:06<00:00,  3.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 111/111 [00:12<00:00,  8.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machinery - Train Loss: 0.2840, Val Loss: 0.5342, Val Acc: 0.8424, Test Acc: 0.8382\n",
      "Trigger Times (Machinery): 3\n",
      "Early stopping for Machinery!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:10<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy (Machinery): 0.8382\n"
     ]
    }
   ],
   "source": [
    "# Machinery 모델 학습 실행\n",
    "num_epochs = 20\n",
    "best_val_acc_machinery = 0\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Machinery 모델 학습\n",
    "    train_loss_machinery = train_machinery(\n",
    "        machinery_model, \n",
    "        train_loader_machinery, \n",
    "        optimizer_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    \n",
    "    # Machinery 모델 평가\n",
    "    val_loss_machinery, val_acc_machinery, val_preds_machinery = evaluate_machinery(\n",
    "        machinery_model, \n",
    "        val_loader_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    test_loss_machinery, test_acc_machinery, test_preds_machinery = evaluate_machinery(\n",
    "        machinery_model, \n",
    "        test_loader_machinery, \n",
    "        device, \n",
    "        loss_fn_machinery\n",
    "    )\n",
    "    \n",
    "    print(f\"Machinery - Train Loss: {train_loss_machinery:.4f}, Val Loss: {val_loss_machinery:.4f}, Val Acc: {val_acc_machinery:.4f}, Test Acc: {test_acc_machinery:.4f}\")\n",
    "    \n",
    "    # Early Stopping for Machinery\n",
    "    if val_acc_machinery > best_val_acc_machinery:\n",
    "        best_val_acc_machinery = val_acc_machinery\n",
    "        trigger_times = 0\n",
    "        torch.save(machinery_model.state_dict(), \"final_machinery_model.pth\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"Trigger Times (Machinery): {trigger_times}\")\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping for Machinery!\")\n",
    "            break\n",
    "\n",
    "# 최종 테스트 성능 평가\n",
    "final_test_loss_machinery, final_test_acc_machinery, final_machinery_predictions = evaluate_machinery(\n",
    "    machinery_model, \n",
    "    test_loader_machinery, \n",
    "    device, \n",
    "    loss_fn_machinery\n",
    ")\n",
    "print(f\"Final Test Accuracy (Machinery): {final_test_acc_machinery:.4f}\")\n",
    "torch.save(machinery_model.state_dict(), \"final_machinery_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aea936-31d1-4027-8cad-f4c5baa664b7",
   "metadata": {},
   "source": [
    "### BERT 기반 machinery 모델 학습 및 예측값\n",
    "\n",
    "> xgboost assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3fa58e3-c59b-4f5a-a8f3-4d0fefab3977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq_train_final shape: (10029, 50)\n",
      "X_seq_val shape: (1770, 50)\n",
      "X_seq_test shape: (2083, 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1. 텍스트를 정수 시퀀스로 변환\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(data['combined_text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['combined_text'])\n",
    "\n",
    "# 2. 시퀀스 패딩 (X_seq로 변경)\n",
    "max_len = 50\n",
    "X_seq = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# 3. 정수형 레이블 (y)\n",
    "assembly_labels = data['Assembly'].values\n",
    "\n",
    "label_encoder_assembly = LabelEncoder()\n",
    "y_assembly = label_encoder_assembly.fit_transform(assembly_labels)\n",
    "\n",
    "# Train-Test Split을 일관되게 적용\n",
    "X_seq_train, X_seq_test, y_train_assembly, y_test_assembly = train_test_split(\n",
    "    X_seq, y_assembly, test_size=0.15, random_state=42, stratify=y_assembly\n",
    ")\n",
    "\n",
    "X_seq_train_final, X_seq_val, y_train_assembly_final, y_val_assembly = train_test_split(\n",
    "    X_seq_train, y_train_assembly, test_size=0.15, random_state=42, stratify=y_train_assembly\n",
    ")\n",
    "\n",
    "# 분할된 데이터 크기 확인\n",
    "print(f\"X_seq_train_final shape: {X_seq_train_final.shape}\")\n",
    "print(f\"X_seq_val shape: {X_seq_val.shape}\")\n",
    "print(f\"X_seq_test shape: {X_seq_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5999115a-fd7b-448c-939f-a12ebec64c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_machinery_classes(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, extra_features = [b.to(device) for b in batch[:3]]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Get the class with the highest probability\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "    return np.concatenate(all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d65869c-48d8-406c-85d2-b57c3ca5c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Machinery 예측 클래스 가져오기\n",
    "machinery_preds_train = predict_machinery_classes(machinery_model, train_loader_machinery, device)\n",
    "machinery_preds_val = predict_machinery_classes(machinery_model, val_loader_machinery, device)\n",
    "machinery_preds_test = predict_machinery_classes(machinery_model, test_loader_machinery, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7ba890ca-6abd-4aea-a823-fb5caec75758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Machinery 예측값을 시퀀스 데이터에 추가\n",
    "X_seq_train_with_machinery = np.hstack([X_seq_train_final, machinery_preds_train.reshape(-1, 1)])\n",
    "X_seq_val_with_machinery = np.hstack([X_seq_val, machinery_preds_val.reshape(-1, 1)])\n",
    "X_seq_test_with_machinery = np.hstack([X_seq_test, machinery_preds_test.reshape(-1, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6072f45-b22f-4e3e-8889-6a6dce01db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq_train_with_machinery shape: (10029, 51)\n",
      "y_train_assembly_final shape: (10029,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 크기 확인\n",
    "print(f\"X_seq_train_with_machinery shape: {X_seq_train_with_machinery.shape}\")\n",
    "print(f\"y_train_assembly_final shape: {y_train_assembly_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89d880f4-2d82-46f0-8155-354e1c546438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled X shape: (82267, 51)\n",
      "Resampled y shape: (82267,)\n"
     ]
    }
   ],
   "source": [
    "# 크기가 일치하는지 확인\n",
    "assert X_seq_train_with_machinery.shape[0] == y_train_assembly_final.shape[0], \"X_train과 y_train의 크기가 일치하지 않습니다.\"\n",
    "\n",
    "# SMOTE + Tomek Links 적용\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_train, y_resampled_train_assembly = smote_tomek.fit_resample(X_seq_train_with_machinery, y_train_assembly_final)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"Resampled X shape: {X_resampled_train.shape}\")\n",
    "print(f\"Resampled y shape: {y_resampled_train_assembly.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "25e10922-f207-4957-a651-53adb16fffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly Validation Accuracy: 0.7701\n",
      "Assembly Test Accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# 5. XGBoost Assembly 모델 설정 및 학습\n",
    "assembly_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=209,  # Assembly 클래스 수\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1,\n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# SMOTE + Tomek Links로 불균형 데이터를 해결한 후 훈련 세트로 학습\n",
    "assembly_model.fit(X_resampled_train, y_resampled_train_assembly)\n",
    "\n",
    "# 6. 성능 평가 (검증 세트)\n",
    "assembly_preds_val = assembly_model.predict(X_seq_val_with_machinery)\n",
    "assembly_accuracy_val = accuracy_score(y_val_assembly, assembly_preds_val)\n",
    "print(f'Assembly Validation Accuracy: {assembly_accuracy_val:.4f}')\n",
    "\n",
    "# 성능 평가 (테스트 세트)\n",
    "assembly_preds_test = assembly_model.predict(X_seq_test_with_machinery)\n",
    "assembly_accuracy_test = accuracy_score(y_test_assembly, assembly_preds_test)\n",
    "print(f'Assembly Test Accuracy: {assembly_accuracy_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3977014b-6c59-4eca-9d82-093e946f923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best parameters for Assembly: {'colsample_bytree': 0.7687270059423681, 'learning_rate': 0.05852142919229748, 'max_depth': 9, 'n_estimators': 187, 'reg_lambda': 1, 'subsample': 0.8096850157946487}\n",
      "Assembly Validation Accuracy: 0.7983\n",
      "Assembly Test Accuracy: 0.8113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "\n",
    "assembly_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=209,  # Assembly 클래스 수에 맞게 설정\n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': uniform(0.03, 0.03),  # 0.05를 중심으로 ±0.03\n",
    "    'max_depth': randint(7, 10),  # 8을 중심으로 ±1\n",
    "    'n_estimators': randint(180, 220),  # 200을 중심으로 ±20\n",
    "    'subsample': uniform(0.75, 0.1),  # 0.8을 중심으로 ±0.05\n",
    "    'colsample_bytree': uniform(0.75, 0.05),  # 0.8을 중심으로 ±0.05\n",
    "    'reg_lambda': [1, 2],\n",
    "}\n",
    "\n",
    "# 3. RandomizedSearchCV 설정\n",
    "random_search_assembly = RandomizedSearchCV(\n",
    "    estimator=assembly_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # 시도할 파라미터 조합 수\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 교차 검증 fold 수\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # 가능한 모든 코어 사용\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. RandomizedSearchCV 실행 (훈련 세트 사용)\n",
    "random_search_assembly.fit(X_seq_train_with_machinery, y_train_assembly_final)\n",
    "\n",
    "# 5. 최적의 하이퍼파라미터 출력\n",
    "print(f\"Best parameters for Assembly: {random_search_assembly.best_params_}\")\n",
    "\n",
    "# 6. 검증 세트 성능 평가\n",
    "assembly_preds_val = random_search_assembly.best_estimator_.predict(X_seq_val_with_machinery)\n",
    "assembly_accuracy_val = accuracy_score(y_val_assembly, assembly_preds_val)\n",
    "print(f'Assembly Validation Accuracy: {assembly_accuracy_val:.4f}')\n",
    "\n",
    "# 7. 테스트 세트 성능 평가\n",
    "assembly_preds_test = random_search_assembly.best_estimator_.predict(X_seq_test_with_machinery)\n",
    "assembly_accuracy_test = accuracy_score(y_test_assembly, assembly_preds_test)\n",
    "print(f'Assembly Test Accuracy: {assembly_accuracy_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ed052bbc-0a2d-49c8-a8bb-4c1a77c867e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as berttoxgboost_assembly_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 최적의 모델을 파일로 저장\n",
    "joblib.dump(random_search_assembly.best_estimator_, 'berttoxgboost_assembly_model.pkl')\n",
    "print(\"Model saved as berttoxgboost_assembly_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4533b77-9b13-49a5-82a4-0fadabe4c917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
