{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83a08e1-5041-4642-99f5-c82449e37554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6526e20d-c98e-48d0-b5bb-b5f808ede823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663325ee-80a8-448e-9d0d-06d76ae99d18",
   "metadata": {},
   "source": [
    "## 모델이 클래스 특성을 학습하기에 충분한 표본 갯수로 데이터 제거\n",
    "\n",
    "> Machinery에서 데이터가 30개 이하인 클래스 수: 100\n",
    "> \n",
    "> Assembly에서 데이터가 30개 이하인 클래스 수: 1583\n",
    ">\n",
    "> 제거 후, 남은 데이터: 13882, MACHINERY : 62 ASSEMBLY:209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c7432c-d7d4-4f38-8baa-ef842df72dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('filtered_dataset_30.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cb3b8e-7afc-406b-b683-e9fc57c549b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 209\n"
     ]
    }
   ],
   "source": [
    "print(len(data['Machinery'].unique()),len(data['Assembly'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb48e7ee-af89-4345-b401-698b61cafa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13882 entries, 0 to 13881\n",
      "Data columns (total 32 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   청구서번호        13882 non-null  object \n",
      " 1   No.          13882 non-null  int64  \n",
      " 2   Subject      13872 non-null  object \n",
      " 3   Machinery    13882 non-null  object \n",
      " 4   Assembly     13882 non-null  object \n",
      " 5   청구품목         13882 non-null  object \n",
      " 6   Unnamed: 6   0 non-null      float64\n",
      " 7   Part No.1    13881 non-null  object \n",
      " 8   Part No.2    2430 non-null   object \n",
      " 9   청구량          13818 non-null  float64\n",
      " 10  견적           13698 non-null  object \n",
      " 11  견적수량         13818 non-null  float64\n",
      " 12  견적화폐         13818 non-null  object \n",
      " 13  견적단가         13882 non-null  float64\n",
      " 14  발주번호         13882 non-null  object \n",
      " 15  발주처          13882 non-null  object \n",
      " 16  발주           13882 non-null  object \n",
      " 17  발주수량         13818 non-null  float64\n",
      " 18  발주금액         13818 non-null  float64\n",
      " 19  D/T          12461 non-null  object \n",
      " 20  미입고 기간       998 non-null    object \n",
      " 21  창고입고         11867 non-null  object \n",
      " 22  창고입고수량       13882 non-null  int64  \n",
      " 23  Control No.  8571 non-null   object \n",
      " 24  입고창고         11867 non-null  object \n",
      " 25  창고출고         10595 non-null  object \n",
      " 26  창고출고수량       13882 non-null  int64  \n",
      " 27  출고선박         10595 non-null  object \n",
      " 28  출고운반선        10595 non-null  object \n",
      " 29  선박입고         3071 non-null   object \n",
      " 30  선박입고수량       13882 non-null  int64  \n",
      " 31  완료 여부        3065 non-null   object \n",
      "dtypes: float64(6), int64(4), object(22)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e456473-b382-4547-ad15-529b584ad2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GE POWER PACK FORK - E7(B)'\n",
      " 'SAMSON SUPER STRONG DOUBLE BRAID ROPE 1 3/4\", 300FT'\n",
      " 'WIRE ROPE G)6X(S)19 A3 CMP SLPP 28MM X 400M' ... 'BRACKET '\n",
      " 'WASHER, 10 ' 'COVER,MANIFOLD.EXH ']\n"
     ]
    }
   ],
   "source": [
    "print(data['청구품목'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa141-ec18-48b5-9d38-39ea85bdf2bd",
   "metadata": {},
   "source": [
    "### 전처리\n",
    "1. 텍스트 클리닝\n",
    "2. 결합 후 TF-IDF\n",
    "\n",
    "> part.no.1 은 콤마 위치에 따른 세부적인 차이가 많은 텍스트이므로 특수기호 및 문자 유지 필요하다고 판단되어 별도 전처리 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f68d784-6d51-43a8-8ef6-bbad5d5109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)   \n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)    \n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)    \n",
    "    text = text.strip()    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b42583-0c68-48a8-ac07-ac3df468e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 클리닝\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb665627-f3fe-4e78-ad87-29fc63c7ec43",
   "metadata": {},
   "source": [
    "> 청구품목 데이터에서는 각 단어 의미적 연관성보다 주요단어가 있는 것이므로, 가중치 부여하는 것으로 접근함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4cb6a1-43d8-40ce-ade2-57c1bd046dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청구품목 내 주요단어: ['as' 'bearing' 'bolt' 'charges' 'core' 'cover' 'cylinder' 'for' 'fuel'\n",
      " 'gasket' 'gear' 'gp' 'head' 'hex' 'in' 'kit' 'nut' 'oil' 'plate' 'pump'\n",
      " 'ring' 'screw' 'seal' 'sensor' 'set' 'shaft' 'spring' 'valve' 'washer'\n",
      " 'water']\n"
     ]
    }
   ],
   "source": [
    "# 확인용\n",
    "claim_items = data['청구품목'].tolist() \n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30)\n",
    "tfidf_matrix = tfidf.fit_transform(claim_items)\n",
    "\n",
    "# 중요한 단어 추출\n",
    "important_words = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"청구품목 내 주요단어:\", important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978a32ad-6eab-40b1-b6e6-9f0072d24d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2. TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30) \n",
    "tfidf_matrix = tfidf.fit_transform(data['cleaned_item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590b98d-a4ec-4fa7-b9a3-a885f465b885",
   "metadata": {},
   "source": [
    "### 발주처 클리닝\n",
    "\n",
    "> 부가단어 (CORPORATION, Corp, CO., Ltd, GmbH, Co., Inc, 주식회사, 상사, 공사, Co.,Ltd, Ltd, Pte Ltd, LLC) 제거\n",
    "\n",
    "> 핵심 정보(회사명 직접 관련) emphasizing 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a047f01f-acfa-4bf9-b772-c35b47e279e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93715f68-009b-424f-b42b-1e928ec887ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa', 'kti', '대광기업', 'kth mar', 'haein _cheonan', 'korea ucd', 'east wind', '인스알파', 'in international', '한국쉘석유', 'euro kytex engineering bv', '대동베아링', 'marine hydrotec', '금안', 'test', 'port relief engineering', 'caterpillar marine asia pacific', '혜인', 'sanwa mmercial', 'yusinhr', '선진종합', 'furuno', 'nissin refrigeration engineerin', '우림', 'haein _cheonan', 'kemel', 'rexnord -falk marine group', '유신에이치알', 'gea korea', '안에너지', 'sunjin etech', '디에스알제강', '한국에프에이디', 'albert', 'wartsila korea', '선진엔텍', 'piriou naval', '프러스', 'taeyoung enterprise', 'shina', 'ins alfa', 'kemelkomarine', '누리', 'rnk tech', 'os system', '씨코리아', '두원알앤에이', '합동듸젤사', '하이에어코리아', 'desmi pumping technologysuzhou', '한국마이콤', 'human engineering']\n"
     ]
    }
   ],
   "source": [
    "suppliers = [\n",
    "    'MATSUI(U.S.A) COROPRATION', 'KTI', '대광기업(주)', 'K.TH MARCO',\n",
    "    'HAEIN Coporation_Cheonan', 'KOREA UCD CO.,LTD.', 'EAST WIND Gmbh', '인스알파',\n",
    "    'ICON INTERNATIONAL, INC', '한국쉘석유㈜', 'EURO KYTEX ENGINEERING BV', '대동베아링상사',\n",
    "    'MARINE HYDROTEC CO.,LTD.', '금안상사', 'TEST COMPANY',\n",
    "    'PORT RELIEF ENGINEERING CO.,LTD.',\n",
    "    'Caterpillar Marine Asia Pacific Pte Ltd', '(주)혜인',\n",
    "    'SANWA COMMERCIAL CO.,LTD.', 'yusinHR Co., Ltd.', '(주)선진종합', 'FURUNO',\n",
    "    'NISSIN REFRIGERATION  ENGINEERIN', '(주)우림공사',\n",
    "    'HAEIN Coporation_Cheonan(사용금지)', 'KEMEL', 'REXNORD LLC-FALK MARINE GROUP',\n",
    "    '유신에이치알(사용금지)', 'GEA KOREA LTD', '주안에너지㈜', 'SUNJIN ETECH Co.,Ltd.',\n",
    "    '디에스알제강주식회사', '(주)한국에프에이디', 'ALBERT GMBH', 'Wartsila Korea Ltd.',\n",
    "    '(주)선진엔텍(사용금지)', 'PIRIOU NAVAL', '(주)프러스엔지니어링', 'Taeyoung Enterprise',\n",
    "    'SHINA', 'INS ALFA', 'KEMEL(KOMARINE)', '누리엔지니어링', 'RNK TECH CO.,LTD',\n",
    "    'OS SYSTEM CO.,LTD', '씨코리아엔지니어링(주)', '(주)두원알앤에이', '합동듸젤사', '하이에어코리아(주)',\n",
    "    'DESMI PUMPING TECHNOLOGY(SUZHOU) CO.,LTD', '한국마이콤',\n",
    "    'HUMAN & ENGINEERING CO.,LTD'\n",
    "]\n",
    "\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]\n",
    "print(cleaned_suppliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "668b9875-82a8-43c5-bb4f-c1b6bd535e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  HAEIN Corporation => HAEIN\n",
    "def extract_important_part(name):\n",
    "    if re.search(r'[가-힣]', name):\n",
    "        name = re.sub(r'(기업|상사|종합|공사)', '', name)\n",
    "        important_part = name.split()[0]  # 첫 단어 추출\n",
    "    else:\n",
    "        # 영문 이름의 경우 첫 번째 단어만 추출\n",
    "        important_part = name.split()[0]\n",
    "    \n",
    "    return important_part\n",
    "\n",
    "# 한번더 반복 HAEIN HAEIN Corporation\n",
    "def emphasize_supplier_name(name):\n",
    "    important_part = extract_important_part(name)\n",
    "    emphasized_name = f\"{important_part} {important_part} {name}\"  # 중요한 부분을 반복\n",
    "    return emphasized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece38a1f-a83e-4021-afb4-057883d6e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa matsui_usa matsui_usa', 'taeyoung taeyoung taeyoung enterprise', 'haein haein haein _cheonan']\n"
     ]
    }
   ],
   "source": [
    "suppliers = ['MATSUI(U.S.A) COROPRATION', 'taeyoung enterprise','HAEIN Coporation_Cheonan(사용금지)']\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]  # 전처리\n",
    "emphasized_suppliers = [emphasize_supplier_name(supplier) for supplier in cleaned_suppliers]  # 강조\n",
    "\n",
    "print(emphasized_suppliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8078a0c-6a95-46d3-bb74-ac2798e556fd",
   "metadata": {},
   "source": [
    "### 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1977ab6f-cdc6-4bef-a91f-2bbb62b77a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 전처리 (TF-IDF 벡터화 적용)\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "\n",
    "# 파트 넘버 전처리 (별도 전처리 없음)\n",
    "data['Part No.1'] = data['Part No.1'].astype(str)\n",
    "\n",
    "# 발주처 전처리\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "# data['emphasized_supplier'] = data['cleaned_supplier'].apply(emphasize_supplier_name)\n",
    "\n",
    "# 4. 청구품목 + Part No.1 + 발주처 결합 (증강 없이)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "867bc16f-a891-4527-9db4-392aa3569d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "X = tfidf.fit_transform(data['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf009e4d-8dd6-4e58-a3ad-df4efd1bdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np shape: (8884, 500)\n",
      "X_train_tensor shape: torch.Size([8884, 500])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "# 1. combined_text 벡터화 (청구품목 + Part No.1 + 발주처 결합된 텍스트)\n",
    "tfidf = TfidfVectorizer(max_features=500)  # 필요에 따라 max_features 조정 가능\n",
    "X = tfidf.fit_transform(data['combined_text'])  # combined_text 벡터화\n",
    "\n",
    "# 2. 레이블 준비 \n",
    "machinery_labels = data['Machinery'].values\n",
    "assembly_labels = data['Assembly'].values\n",
    "\n",
    "label_encoder_machinery = LabelEncoder()\n",
    "y_machinery = label_encoder_machinery.fit_transform(machinery_labels)\n",
    "\n",
    "label_encoder_assembly = LabelEncoder()\n",
    "y_assembly = label_encoder_assembly.fit_transform(assembly_labels)\n",
    "\n",
    "# 3. 스케일러 \n",
    "# TF-IDF 벡터는 이미 스케일링된 값(0~1)\n",
    "\n",
    "X_scaled = X.toarray()\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train_val, X_test, y_train_val_machinery, y_test_machinery, y_train_val_assembly, y_test_assembly = train_test_split(\n",
    "    X_scaled, y_machinery, y_assembly, test_size=0.2, random_state=42, stratify=y_machinery\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train_machinery, y_val_machinery, y_train_assembly, y_val_assembly = train_test_split(\n",
    "    X_train_val, y_train_val_machinery, y_train_val_assembly, test_size=0.2, random_state=42, stratify=y_train_val_machinery\n",
    ")\n",
    "\n",
    "# 5. CNN 모델용 텐서로 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_machinery, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_machinery, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_machinery, dtype=torch.long)\n",
    "\n",
    "# 6. XGBoost 모델용 NumPy 배열 준비 (이미 X_scaled는 NumPy 배열)\n",
    "X_train_np = X_train\n",
    "X_val_np = X_val\n",
    "X_test_np = X_test\n",
    "\n",
    "y_train_np = y_train_machinery\n",
    "y_val_np = y_val_machinery\n",
    "y_test_np = y_test_machinery\n",
    "\n",
    "print(f\"X_train_np shape: {X_train_np.shape}\")\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cb8b0-7a6c-4f48-9792-dc44cbe61a9e",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5eee6727-d855-41bb-be38-1fe540793f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_mlp_model(input_shape, dropout_rate=0.3, learning_rate=0.0001):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),  # TF-IDF 입력 크기에 맞춤\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(32, activation='relu'),  # 추가된 레이어\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(62, activation='softmax')  # Machinery 클래스 수\n",
    "    ])\n",
    "\n",
    "    # 옵티마이저와 학습률 설정\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bebfc072-09a3-4c80-966b-83d81d18a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "def train_and_evaluate(dropout_rate, learning_rate, batch_size):\n",
    "    model = build_mlp_model(dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
    "    \n",
    "    # 콜백 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train, y_train_machinery, \n",
    "        epochs=100, batch_size=batch_size, \n",
    "        validation_data=(X_val, y_val_machinery),  \n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    # 성능 평가\n",
    "    accuracy = model.evaluate(X_test, y_test_machinery, verbose=0)\n",
    "    print(f\"Test Accuracy: {accuracy[1]:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "489a4e4b-69c4-4723-a26a-952677bd44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0337 - loss: 4.2428 - val_accuracy: 0.0594 - val_loss: 4.0824 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3454 - loss: 3.1767 - val_accuracy: 0.3751 - val_loss: 3.2652 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4853 - loss: 2.4738 - val_accuracy: 0.5349 - val_loss: 2.2727 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5263 - loss: 2.1119 - val_accuracy: 0.5754 - val_loss: 1.7611 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5382 - loss: 1.9305 - val_accuracy: 0.6029 - val_loss: 1.5467 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5752 - loss: 1.7347 - val_accuracy: 0.6182 - val_loss: 1.4372 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 1.7053 - val_accuracy: 0.6362 - val_loss: 1.3607 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 1.5988 - val_accuracy: 0.6533 - val_loss: 1.2967 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 1.5554 - val_accuracy: 0.6565 - val_loss: 1.2460 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6163 - loss: 1.4857 - val_accuracy: 0.6709 - val_loss: 1.1977 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6276 - loss: 1.4003 - val_accuracy: 0.6803 - val_loss: 1.1523 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6288 - loss: 1.3674 - val_accuracy: 0.6907 - val_loss: 1.1155 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6494 - loss: 1.3069 - val_accuracy: 0.7033 - val_loss: 1.0750 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 1.2748 - val_accuracy: 0.7109 - val_loss: 1.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 1.2206 - val_accuracy: 0.7208 - val_loss: 1.0270 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6708 - loss: 1.2124 - val_accuracy: 0.7249 - val_loss: 0.9915 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 1.1511 - val_accuracy: 0.7267 - val_loss: 0.9834 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 1.1234 - val_accuracy: 0.7262 - val_loss: 0.9621 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 1.0904 - val_accuracy: 0.7308 - val_loss: 0.9445 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 1.0830 - val_accuracy: 0.7339 - val_loss: 0.9280 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 1.0441 - val_accuracy: 0.7348 - val_loss: 0.9208 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 1.0112 - val_accuracy: 0.7339 - val_loss: 0.9137 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.9985 - val_accuracy: 0.7380 - val_loss: 0.8930 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.9787 - val_accuracy: 0.7429 - val_loss: 0.8867 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.9618 - val_accuracy: 0.7375 - val_loss: 0.8862 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7298 - loss: 0.9434 - val_accuracy: 0.7380 - val_loss: 0.8812 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7193 - loss: 0.9670 - val_accuracy: 0.7357 - val_loss: 0.8843 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.9331 - val_accuracy: 0.7429 - val_loss: 0.8725 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.9388 - val_accuracy: 0.7452 - val_loss: 0.8690 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7385 - loss: 0.9155 - val_accuracy: 0.7456 - val_loss: 0.8701 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.8798 - val_accuracy: 0.7479 - val_loss: 0.8512 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.8925 - val_accuracy: 0.7524 - val_loss: 0.8498 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.8821 - val_accuracy: 0.7546 - val_loss: 0.8522 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.9061 - val_accuracy: 0.7555 - val_loss: 0.8516 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.8749 - val_accuracy: 0.7587 - val_loss: 0.8394 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.8913 - val_accuracy: 0.7560 - val_loss: 0.8515 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.8584 - val_accuracy: 0.7573 - val_loss: 0.8412 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.8410 - val_accuracy: 0.7564 - val_loss: 0.8464 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.8015 - val_accuracy: 0.7605 - val_loss: 0.8389 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.8360 - val_accuracy: 0.7542 - val_loss: 0.8387 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.8075 - val_accuracy: 0.7596 - val_loss: 0.8379 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.7995 - val_accuracy: 0.7600 - val_loss: 0.8354 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.8050 - val_accuracy: 0.7623 - val_loss: 0.8348 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.8228 - val_accuracy: 0.7582 - val_loss: 0.8275 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.8175 - val_accuracy: 0.7578 - val_loss: 0.8338 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7580 - loss: 0.8093 - val_accuracy: 0.7582 - val_loss: 0.8295 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.7937 - val_accuracy: 0.7596 - val_loss: 0.8267 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.8141 - val_accuracy: 0.7609 - val_loss: 0.8248 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.7973 - val_accuracy: 0.7641 - val_loss: 0.8262 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 0.7826 - val_accuracy: 0.7582 - val_loss: 0.8249 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.7915 - val_accuracy: 0.7632 - val_loss: 0.8321 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.8004 - val_accuracy: 0.7614 - val_loss: 0.8292 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.7789 - val_accuracy: 0.7627 - val_loss: 0.8297 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.7647 - val_accuracy: 0.7636 - val_loss: 0.8273 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.7792 - val_accuracy: 0.7632 - val_loss: 0.8263 - learning_rate: 6.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7619 - loss: 0.7620 - val_accuracy: 0.7623 - val_loss: 0.8266 - learning_rate: 6.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 0.7795 - val_accuracy: 0.7636 - val_loss: 0.8283 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7659 - loss: 0.7674 - val_accuracy: 0.7627 - val_loss: 0.8282 - learning_rate: 3.1250e-05\n",
      "Test Accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "model, history = train_and_evaluate(dropout_rate=0.3, learning_rate=0.0005, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d41084a8-2ba7-4c8a-9677-7fbf9d361119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        model = build_mlp_model(input_shape=X_train.shape[1])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50, batch_size=64,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        print(f\"Fold Accuracy: {val_accuracy}\")\n",
    "\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    print(f\"Average K-Fold Accuracy: {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19cb7497-e8c7-4187-a76e-3df92ace1365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.7133597135543823\n",
      "Fold Accuracy: 0.7320849895477295\n",
      "Fold Accuracy: 0.7377521395683289\n",
      "Fold Accuracy: 0.7172189950942993\n",
      "Fold Accuracy: 0.7244236469268799\n",
      "Average K-Fold Accuracy: 0.724967896938324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = tfidf.fit_transform(data['combined_text']).toarray() \n",
    "y_machinery = label_encoder_machinery.fit_transform(data['Machinery'])\n",
    "y_assembly = label_encoder_assembly.fit_transform(data['Assembly'])\n",
    "\n",
    "# K-Fold 교차 검증 수행\n",
    "k_fold_cross_validation(X, y_machinery, k=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f58f7348-77b8-43c6-a400-2c3710f0943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the optimized model: 0.7515\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "machinery_optimized_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=62,\n",
    "    learning_rate=0.0746,\n",
    "    max_depth=10,\n",
    "    n_estimators=148,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.6804,\n",
    "    reg_lambda=1,\n",
    "    random_state=42,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "machinery_optimized_model.fit(X_train, y_train_machinery)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_machinery = machinery_optimized_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test_machinery, y_pred_machinery)\n",
    "print(f\"Accuracy of the optimized model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da03f7c-faf8-4c73-9789-1e46497274a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
