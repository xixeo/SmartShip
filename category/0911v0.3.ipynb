{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e83a08e1-5041-4642-99f5-c82449e37554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "Device 0: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6526e20d-c98e-48d0-b5bb-b5f808ede823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663325ee-80a8-448e-9d0d-06d76ae99d18",
   "metadata": {},
   "source": [
    "## 모델이 클래스 특성을 학습하기에 충분한 표본 갯수로 데이터 제거\n",
    "\n",
    "> Machinery에서 데이터가 30개 이하인 클래스 수: 100\n",
    "> \n",
    "> Assembly에서 데이터가 30개 이하인 클래스 수: 1583\n",
    ">\n",
    "> 제거 후, 남은 데이터: 13882, MACHINERY : 62 ASSEMBLY:209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c7432c-d7d4-4f38-8baa-ef842df72dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('filtered_dataset_30.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cb3b8e-7afc-406b-b683-e9fc57c549b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 209\n"
     ]
    }
   ],
   "source": [
    "print(len(data['Machinery'].unique()),len(data['Assembly'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb48e7ee-af89-4345-b401-698b61cafa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13882 entries, 0 to 13881\n",
      "Data columns (total 32 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   청구서번호        13882 non-null  object \n",
      " 1   No.          13882 non-null  int64  \n",
      " 2   Subject      13872 non-null  object \n",
      " 3   Machinery    13882 non-null  object \n",
      " 4   Assembly     13882 non-null  object \n",
      " 5   청구품목         13882 non-null  object \n",
      " 6   Unnamed: 6   0 non-null      float64\n",
      " 7   Part No.1    13881 non-null  object \n",
      " 8   Part No.2    2430 non-null   object \n",
      " 9   청구량          13818 non-null  float64\n",
      " 10  견적           13698 non-null  object \n",
      " 11  견적수량         13818 non-null  float64\n",
      " 12  견적화폐         13818 non-null  object \n",
      " 13  견적단가         13882 non-null  float64\n",
      " 14  발주번호         13882 non-null  object \n",
      " 15  발주처          13882 non-null  object \n",
      " 16  발주           13882 non-null  object \n",
      " 17  발주수량         13818 non-null  float64\n",
      " 18  발주금액         13818 non-null  float64\n",
      " 19  D/T          12461 non-null  object \n",
      " 20  미입고 기간       998 non-null    object \n",
      " 21  창고입고         11867 non-null  object \n",
      " 22  창고입고수량       13882 non-null  int64  \n",
      " 23  Control No.  8571 non-null   object \n",
      " 24  입고창고         11867 non-null  object \n",
      " 25  창고출고         10595 non-null  object \n",
      " 26  창고출고수량       13882 non-null  int64  \n",
      " 27  출고선박         10595 non-null  object \n",
      " 28  출고운반선        10595 non-null  object \n",
      " 29  선박입고         3071 non-null   object \n",
      " 30  선박입고수량       13882 non-null  int64  \n",
      " 31  완료 여부        3065 non-null   object \n",
      "dtypes: float64(6), int64(4), object(22)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e456473-b382-4547-ad15-529b584ad2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GE POWER PACK FORK - E7(B)'\n",
      " 'SAMSON SUPER STRONG DOUBLE BRAID ROPE 1 3/4\", 300FT'\n",
      " 'WIRE ROPE G)6X(S)19 A3 CMP SLPP 28MM X 400M' ... 'BRACKET '\n",
      " 'WASHER, 10 ' 'COVER,MANIFOLD.EXH ']\n"
     ]
    }
   ],
   "source": [
    "print(data['청구품목'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa141-ec18-48b5-9d38-39ea85bdf2bd",
   "metadata": {},
   "source": [
    "### 전처리\n",
    "1. 텍스트 클리닝\n",
    "2. 결합 후 TF-IDF\n",
    "\n",
    "> part.no.1 은 콤마 위치에 따른 세부적인 차이가 많은 텍스트이므로 특수기호 및 문자 유지 필요하다고 판단되어 별도 전처리 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f68d784-6d51-43a8-8ef6-bbad5d5109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)   \n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)    \n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)    \n",
    "    text = text.strip()    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b42583-0c68-48a8-ac07-ac3df468e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 클리닝\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb665627-f3fe-4e78-ad87-29fc63c7ec43",
   "metadata": {},
   "source": [
    "> 청구품목 데이터에서는 각 단어 의미적 연관성보다 주요단어가 있는 것이므로, 가중치 부여하는 것으로 접근함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4cb6a1-43d8-40ce-ade2-57c1bd046dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청구품목 내 주요단어: ['as' 'bearing' 'bolt' 'charges' 'core' 'cover' 'cylinder' 'for' 'fuel'\n",
      " 'gasket' 'gear' 'gp' 'head' 'hex' 'in' 'kit' 'nut' 'oil' 'plate' 'pump'\n",
      " 'ring' 'screw' 'seal' 'sensor' 'set' 'shaft' 'spring' 'valve' 'washer'\n",
      " 'water']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 확인용\n",
    "claim_items = data['청구품목'].tolist() \n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30)\n",
    "tfidf_matrix = tfidf.fit_transform(claim_items)\n",
    "\n",
    "# 중요한 단어 추출\n",
    "important_words = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"청구품목 내 주요단어:\", important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978a32ad-6eab-40b1-b6e6-9f0072d24d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 2. TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=30) \n",
    "tfidf_matrix = tfidf.fit_transform(data['cleaned_item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590b98d-a4ec-4fa7-b9a3-a885f465b885",
   "metadata": {},
   "source": [
    "### 발주처 클리닝\n",
    "\n",
    "> 부가단어 (CORPORATION, Corp, CO., Ltd, GmbH, Co., Inc, 주식회사, 상사, 공사, Co.,Ltd, Ltd, Pte Ltd, LLC) 제거\n",
    "\n",
    "> 핵심 정보(회사명 직접 관련) emphasizing 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a047f01f-acfa-4bf9-b772-c35b47e279e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93715f68-009b-424f-b42b-1e928ec887ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa', 'kti', '대광기업', 'kth mar', 'haein _cheonan', 'korea ucd', 'east wind', '인스알파', 'in international', '한국쉘석유', 'euro kytex engineering bv', '대동베아링', 'marine hydrotec', '금안', 'test', 'port relief engineering', 'caterpillar marine asia pacific', '혜인', 'sanwa mmercial', 'yusinhr', '선진종합', 'furuno', 'nissin refrigeration engineerin', '우림', 'haein _cheonan', 'kemel', 'rexnord -falk marine group', '유신에이치알', 'gea korea', '안에너지', 'sunjin etech', '디에스알제강', '한국에프에이디', 'albert', 'wartsila korea', '선진엔텍', 'piriou naval', '프러스', 'taeyoung enterprise', 'shina', 'ins alfa', 'kemelkomarine', '누리', 'rnk tech', 'os system', '씨코리아', '두원알앤에이', '합동듸젤사', '하이에어코리아', 'desmi pumping technologysuzhou', '한국마이콤', 'human engineering']\n"
     ]
    }
   ],
   "source": [
    "suppliers = [\n",
    "    'MATSUI(U.S.A) COROPRATION', 'KTI', '대광기업(주)', 'K.TH MARCO',\n",
    "    'HAEIN Coporation_Cheonan', 'KOREA UCD CO.,LTD.', 'EAST WIND Gmbh', '인스알파',\n",
    "    'ICON INTERNATIONAL, INC', '한국쉘석유㈜', 'EURO KYTEX ENGINEERING BV', '대동베아링상사',\n",
    "    'MARINE HYDROTEC CO.,LTD.', '금안상사', 'TEST COMPANY',\n",
    "    'PORT RELIEF ENGINEERING CO.,LTD.',\n",
    "    'Caterpillar Marine Asia Pacific Pte Ltd', '(주)혜인',\n",
    "    'SANWA COMMERCIAL CO.,LTD.', 'yusinHR Co., Ltd.', '(주)선진종합', 'FURUNO',\n",
    "    'NISSIN REFRIGERATION  ENGINEERIN', '(주)우림공사',\n",
    "    'HAEIN Coporation_Cheonan(사용금지)', 'KEMEL', 'REXNORD LLC-FALK MARINE GROUP',\n",
    "    '유신에이치알(사용금지)', 'GEA KOREA LTD', '주안에너지㈜', 'SUNJIN ETECH Co.,Ltd.',\n",
    "    '디에스알제강주식회사', '(주)한국에프에이디', 'ALBERT GMBH', 'Wartsila Korea Ltd.',\n",
    "    '(주)선진엔텍(사용금지)', 'PIRIOU NAVAL', '(주)프러스엔지니어링', 'Taeyoung Enterprise',\n",
    "    'SHINA', 'INS ALFA', 'KEMEL(KOMARINE)', '누리엔지니어링', 'RNK TECH CO.,LTD',\n",
    "    'OS SYSTEM CO.,LTD', '씨코리아엔지니어링(주)', '(주)두원알앤에이', '합동듸젤사', '하이에어코리아(주)',\n",
    "    'DESMI PUMPING TECHNOLOGY(SUZHOU) CO.,LTD', '한국마이콤',\n",
    "    'HUMAN & ENGINEERING CO.,LTD'\n",
    "]\n",
    "\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]\n",
    "print(cleaned_suppliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "668b9875-82a8-43c5-bb4f-c1b6bd535e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  HAEIN Corporation => HAEIN\n",
    "def extract_important_part(name):\n",
    "    if re.search(r'[가-힣]', name):\n",
    "        name = re.sub(r'(기업|상사|종합|공사)', '', name)\n",
    "        important_part = name.split()[0]  # 첫 단어 추출\n",
    "    else:\n",
    "        # 영문 이름의 경우 첫 번째 단어만 추출\n",
    "        important_part = name.split()[0]\n",
    "    \n",
    "    return important_part\n",
    "\n",
    "# 한번더 반복 HAEIN HAEIN Corporation\n",
    "def emphasize_supplier_name(name):\n",
    "    important_part = extract_important_part(name)\n",
    "    emphasized_name = f\"{important_part} {important_part} {name}\"  # 중요한 부분을 반복\n",
    "    return emphasized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece38a1f-a83e-4021-afb4-057883d6e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matsui_usa matsui_usa matsui_usa', 'taeyoung taeyoung taeyoung enterprise', 'haein haein haein _cheonan']\n"
     ]
    }
   ],
   "source": [
    "suppliers = ['MATSUI(U.S.A) COROPRATION', 'taeyoung enterprise','HAEIN Coporation_Cheonan(사용금지)']\n",
    "cleaned_suppliers = [clean_supplier_name(supplier) for supplier in suppliers]  # 전처리\n",
    "emphasized_suppliers = [emphasize_supplier_name(supplier) for supplier in cleaned_suppliers]  # 강조\n",
    "\n",
    "print(emphasized_suppliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8078a0c-6a95-46d3-bb74-ac2798e556fd",
   "metadata": {},
   "source": [
    "### tf-idf / 정수 시퀀스 임베딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1977ab6f-cdc6-4bef-a91f-2bbb62b77a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청구품목 전처리 (TF-IDF 벡터화 적용)\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "\n",
    "# 파트 넘버 전처리 (별도 전처리 없음)\n",
    "data['Part No.1'] = data['Part No.1'].astype(str)\n",
    "\n",
    "# 발주처 전처리\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "# data['emphasized_supplier'] = data['cleaned_supplier'].apply(emphasize_supplier_name)\n",
    "\n",
    "# 4. 청구품목 + Part No.1 + 발주처 결합 (증강 없이)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68c2de11-0683-4f6d-a370-fe080d11f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "X_tfidf = tfidf.fit_transform(data['combined_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "867bc16f-a891-4527-9db4-392aa3569d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 2. 정수 시퀀스 임베딩\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(data['combined_text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['combined_text'])\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "X_sequences = np.array([np.pad(seq, (0, max_length - len(seq)), mode='constant') for seq in sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf009e4d-8dd6-4e58-a3ad-df4efd1bdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([8884, 100])\n",
      "X_val_tensor shape: torch.Size([2221, 100])\n",
      "X_test_tensor shape: torch.Size([2777, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6876\\1629723737.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6876\\1629723737.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6876\\1629723737.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "# 2. 레이블 준비 \n",
    "machinery_labels = data['Machinery'].values\n",
    "assembly_labels = data['Assembly'].values\n",
    "\n",
    "label_encoder_machinery = LabelEncoder()\n",
    "y_machinery = label_encoder_machinery.fit_transform(machinery_labels)\n",
    "\n",
    "label_encoder_assembly = LabelEncoder()\n",
    "y_assembly = label_encoder_assembly.fit_transform(assembly_labels)\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_machinery, y_test_machinery = train_test_split(\n",
    "    X_tfidf, y_machinery, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_sequences, X_test_sequences, _, _ = train_test_split(\n",
    "    X_sequences, y_machinery, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Tensor로 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_machinery, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_machinery, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_machinery, dtype=torch.long)\n",
    "\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"X_val_tensor shape: {X_val_tensor.shape}\")\n",
    "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cb8b0-7a6c-4f48-9792-dc44cbe61a9e",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f1df75c-6574-49ac-b824-d1cbdc7bb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "input_tfidf = Input(shape=(X_tfidf.shape[1],), name='tfidf_input')\n",
    "input_sequences = Input(shape=(max_length,), name='sequences_input')\n",
    "\n",
    "embedding_layer = Embedding(input_dim=20000, output_dim=50, input_length=max_length)(input_sequences)\n",
    "embedding_flattened = Flatten()(embedding_layer)\n",
    "\n",
    "concat = Concatenate()([input_tfidf, embedding_flattened])\n",
    "\n",
    "dense1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(concat)  # L2 정규화 추가\n",
    "batch_norm1 = BatchNormalization()(dense1)\n",
    "dropout1 = Dropout(0.4)(batch_norm1)\n",
    "\n",
    "dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(dropout1)  # L2 정규화 추가\n",
    "batch_norm2 = BatchNormalization()(dense2)\n",
    "dropout2 = Dropout(0.4)(batch_norm2)\n",
    "\n",
    "dense3 = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(dropout2)\n",
    "batch_norm3 = BatchNormalization()(dense3)\n",
    "dropout3 = Dropout(0.4)(batch_norm2)\n",
    "\n",
    "# 출력층\n",
    "output = Dense(62, activation='softmax')(dropout3)  # 62 클래스 예측\n",
    "\n",
    "model = Model(inputs=[input_tfidf, input_sequences], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "182145f9-3cc3-439c-9ab5-52332afd8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c97a2139-89c6-415f-ae08-5f069c0c0b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.4507 - loss: 3.5764 - val_accuracy: 0.2292 - val_loss: 3.7574\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7370 - loss: 1.7063 - val_accuracy: 0.4791 - val_loss: 2.8044\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8046 - loss: 1.3069 - val_accuracy: 0.7348 - val_loss: 1.7971\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8482 - loss: 1.0340 - val_accuracy: 0.8001 - val_loss: 1.2401\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8730 - loss: 0.8790 - val_accuracy: 0.8095 - val_loss: 1.1046\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8831 - loss: 0.7894 - val_accuracy: 0.8073 - val_loss: 1.0771\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8809 - loss: 0.7115 - val_accuracy: 0.8064 - val_loss: 1.0770\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8944 - loss: 0.6417 - val_accuracy: 0.8109 - val_loss: 1.0333\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8981 - loss: 0.5888 - val_accuracy: 0.8086 - val_loss: 1.0246\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8961 - loss: 0.5675 - val_accuracy: 0.8136 - val_loss: 0.9967\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8988 - loss: 0.5238 - val_accuracy: 0.8050 - val_loss: 0.9942\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8981 - loss: 0.4960 - val_accuracy: 0.8109 - val_loss: 0.9741\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8969 - loss: 0.4843 - val_accuracy: 0.8131 - val_loss: 0.9652\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8953 - loss: 0.4759 - val_accuracy: 0.8095 - val_loss: 0.9751\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9037 - loss: 0.4354 - val_accuracy: 0.8068 - val_loss: 0.9596\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9028 - loss: 0.4323 - val_accuracy: 0.8086 - val_loss: 0.9687\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8983 - loss: 0.4233 - val_accuracy: 0.8082 - val_loss: 0.9264\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9032 - loss: 0.4030 - val_accuracy: 0.8140 - val_loss: 0.9246\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8988 - loss: 0.4013 - val_accuracy: 0.8122 - val_loss: 0.9365\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9082 - loss: 0.3875 - val_accuracy: 0.8082 - val_loss: 0.9745\n",
      "Epoch 21/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9049 - loss: 0.3949 - val_accuracy: 0.8068 - val_loss: 0.9045\n",
      "Epoch 22/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9033 - loss: 0.3828 - val_accuracy: 0.8113 - val_loss: 0.9721\n",
      "Epoch 23/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9030 - loss: 0.3837 - val_accuracy: 0.8086 - val_loss: 0.9229\n",
      "Epoch 24/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9051 - loss: 0.3639 - val_accuracy: 0.8118 - val_loss: 0.9563\n",
      "Epoch 25/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9065 - loss: 0.3864 - val_accuracy: 0.7978 - val_loss: 1.0018\n",
      "Epoch 26/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9097 - loss: 0.3697 - val_accuracy: 0.8005 - val_loss: 0.9950\n",
      "Epoch 27/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8965 - loss: 0.3826 - val_accuracy: 0.8023 - val_loss: 0.9628\n",
      "Epoch 28/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9050 - loss: 0.3738 - val_accuracy: 0.8046 - val_loss: 0.9818\n",
      "Epoch 29/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9015 - loss: 0.3656 - val_accuracy: 0.8104 - val_loss: 0.9781\n",
      "Epoch 30/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9067 - loss: 0.3687 - val_accuracy: 0.8037 - val_loss: 0.9719\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.8294\n",
      "Test loss: 0.8908743858337402, Test accuracy: 0.8170687556266785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    [X_train_tfidf, X_train_sequences], y_train_machinery,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate([X_test_tfidf, X_test_sequences], y_test_machinery)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117436ae-1e31-4cbb-8227-522e4b2b8686",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d41084a8-2ba7-4c8a-9677-7fbf9d361119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input_tfidf = Input(shape=(X_tfidf.shape[1],), name='tfidf_input')\n",
    "input_sequences = Input(shape=(max_length,), name='sequences_input')\n",
    "\n",
    "embedding_layer = Embedding(input_dim=20000, output_dim=50, input_length=max_length)(input_sequences)\n",
    "conv_layer = Conv1D(128, 3, activation='relu')(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "\n",
    "concat = Concatenate()([input_tfidf, pooling_layer])\n",
    "dense1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(concat)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)\n",
    "output = Dense(62, activation='softmax')(dropout2)\n",
    "\n",
    "model = Model(inputs=[input_tfidf, input_sequences], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2da03f7c-faf8-4c73-9789-1e46497274a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dfcf7daa-d1f7-405f-aeb0-c7e17e7154d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3601 - loss: 3.2431 - val_accuracy: 0.6047 - val_loss: 1.7203\n",
      "Epoch 2/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6308 - loss: 1.5863 - val_accuracy: 0.6997 - val_loss: 1.3185\n",
      "Epoch 3/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7404 - loss: 1.1440 - val_accuracy: 0.7492 - val_loss: 1.1122\n",
      "Epoch 4/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7955 - loss: 0.9087 - val_accuracy: 0.7636 - val_loss: 1.0204\n",
      "Epoch 5/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.7701 - val_accuracy: 0.7816 - val_loss: 0.9662\n",
      "Epoch 6/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.6625 - val_accuracy: 0.7834 - val_loss: 0.9280\n",
      "Epoch 7/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8475 - loss: 0.6093 - val_accuracy: 0.7965 - val_loss: 0.9297\n",
      "Epoch 8/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8614 - loss: 0.5548 - val_accuracy: 0.7924 - val_loss: 0.9264\n",
      "Epoch 9/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8701 - loss: 0.5059 - val_accuracy: 0.7983 - val_loss: 0.9444\n",
      "Epoch 10/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8784 - loss: 0.4803 - val_accuracy: 0.7974 - val_loss: 0.9640\n",
      "Epoch 11/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8789 - loss: 0.4743 - val_accuracy: 0.7897 - val_loss: 0.9845\n",
      "Epoch 12/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8792 - loss: 0.4612 - val_accuracy: 0.8010 - val_loss: 0.9661\n",
      "Epoch 13/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8913 - loss: 0.4367 - val_accuracy: 0.7978 - val_loss: 0.9355\n",
      "Epoch 14/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.4115 - val_accuracy: 0.7942 - val_loss: 0.9867\n",
      "Epoch 15/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8949 - loss: 0.4094 - val_accuracy: 0.7956 - val_loss: 0.9679\n",
      "Epoch 16/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8920 - loss: 0.3987 - val_accuracy: 0.7812 - val_loss: 1.0172\n",
      "Epoch 17/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8921 - loss: 0.3914 - val_accuracy: 0.8010 - val_loss: 0.9917\n",
      "Epoch 18/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8936 - loss: 0.3975 - val_accuracy: 0.8046 - val_loss: 1.0317\n",
      "Epoch 19/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8902 - loss: 0.3951 - val_accuracy: 0.7956 - val_loss: 0.9861\n",
      "Epoch 20/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.3830 - val_accuracy: 0.7645 - val_loss: 1.0187\n",
      "Epoch 21/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.3882 - val_accuracy: 0.7996 - val_loss: 1.0461\n",
      "Epoch 22/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8958 - loss: 0.3751 - val_accuracy: 0.7812 - val_loss: 1.0202\n",
      "Epoch 23/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8957 - loss: 0.3680 - val_accuracy: 0.7960 - val_loss: 1.0199\n",
      "Epoch 24/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8901 - loss: 0.3777 - val_accuracy: 0.8014 - val_loss: 1.0377\n",
      "Epoch 25/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.3651 - val_accuracy: 0.7978 - val_loss: 1.0325\n",
      "Epoch 26/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.3611 - val_accuracy: 0.7875 - val_loss: 1.0506\n",
      "Epoch 27/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.3554 - val_accuracy: 0.7978 - val_loss: 1.0922\n",
      "Epoch 28/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9007 - loss: 0.3517 - val_accuracy: 0.8019 - val_loss: 1.0563\n",
      "Epoch 29/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9042 - loss: 0.3465 - val_accuracy: 0.7942 - val_loss: 1.0023\n",
      "Epoch 30/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9026 - loss: 0.3399 - val_accuracy: 0.7969 - val_loss: 1.0285\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8139 - loss: 0.8856  \n",
      "Test loss: 0.9468538165092468, Test accuracy: 0.8087864518165588\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    [X_train_tfidf, X_train_sequences], y_train_machinery,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate([X_test_tfidf, X_test_sequences], y_test_machinery)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fcd65-bac1-44ed-8dce-52a915a99197",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09b06f0e-9133-4085-b352-33f8f12e68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "# 1. 입력 레이어 정의\n",
    "input_tfidf = Input(shape=(X_tfidf.shape[1],), name='tfidf_input')  # TF-IDF 입력\n",
    "input_sequences = Input(shape=(max_length,), name='sequences_input')  # 정수 시퀀스 입력\n",
    "\n",
    "# 2. 임베딩 레이어와 LSTM 레이어\n",
    "embedding_layer = Embedding(input_dim=20000, output_dim=50, input_length=max_length)(input_sequences)\n",
    "lstm_layer = LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)(embedding_layer)\n",
    "\n",
    "# 3. TF-IDF와 LSTM 출력을 결합\n",
    "concat = Concatenate()([input_tfidf, lstm_layer])\n",
    "\n",
    "# 4. 밀집 레이어\n",
    "dense1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(concat)\n",
    "dropout1 = Dropout(0.4)(dense1)\n",
    "dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(dropout1)\n",
    "dropout2 = Dropout(0.4)(dense2)\n",
    "\n",
    "# 5. 출력 레이어 (62개 클래스 예측)\n",
    "output = Dense(62, activation='softmax')(dropout2)\n",
    "\n",
    "# 6. 모델 컴파일\n",
    "model = Model(inputs=[input_tfidf, input_sequences], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06e24da1-e167-43f8-b851-fc1819c153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. EarlyStopping과 ReduceLROnPlateau 콜백 추가\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a1bbcb1-54ce-4f90-b070-6736a5e2586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1842 - loss: 4.3134 - val_accuracy: 0.3147 - val_loss: 3.2659 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.3901 - loss: 3.1607 - val_accuracy: 0.5250 - val_loss: 2.5683 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5089 - loss: 2.5526 - val_accuracy: 0.5471 - val_loss: 2.2050 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5539 - loss: 2.1866 - val_accuracy: 0.5727 - val_loss: 2.0089 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5712 - loss: 2.0271 - val_accuracy: 0.6020 - val_loss: 1.8777 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.5994 - loss: 1.8666 - val_accuracy: 0.6285 - val_loss: 1.7754 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6218 - loss: 1.7633 - val_accuracy: 0.6677 - val_loss: 1.6851 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6414 - loss: 1.6645 - val_accuracy: 0.6700 - val_loss: 1.5992 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6649 - loss: 1.5902 - val_accuracy: 0.6916 - val_loss: 1.5397 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6872 - loss: 1.4744 - val_accuracy: 0.7042 - val_loss: 1.4732 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7025 - loss: 1.4310 - val_accuracy: 0.7141 - val_loss: 1.4285 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7141 - loss: 1.3595 - val_accuracy: 0.7271 - val_loss: 1.3944 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7120 - loss: 1.3309 - val_accuracy: 0.7271 - val_loss: 1.3575 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7288 - loss: 1.2699 - val_accuracy: 0.7195 - val_loss: 1.3379 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7397 - loss: 1.2062 - val_accuracy: 0.7411 - val_loss: 1.2899 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7464 - loss: 1.1983 - val_accuracy: 0.7384 - val_loss: 1.2653 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7424 - loss: 1.1819 - val_accuracy: 0.7393 - val_loss: 1.2691 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7592 - loss: 1.1398 - val_accuracy: 0.7402 - val_loss: 1.2416 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7571 - loss: 1.1180 - val_accuracy: 0.7371 - val_loss: 1.2070 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7704 - loss: 1.0745 - val_accuracy: 0.7519 - val_loss: 1.1874 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7704 - loss: 1.0711 - val_accuracy: 0.7497 - val_loss: 1.1781 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7740 - loss: 1.0293 - val_accuracy: 0.7497 - val_loss: 1.1630 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7851 - loss: 1.0045 - val_accuracy: 0.7497 - val_loss: 1.1718 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7803 - loss: 0.9912 - val_accuracy: 0.7569 - val_loss: 1.1594 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7833 - loss: 0.9851 - val_accuracy: 0.7573 - val_loss: 1.1436 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7924 - loss: 0.9485 - val_accuracy: 0.7596 - val_loss: 1.1326 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.7953 - loss: 0.9255 - val_accuracy: 0.7627 - val_loss: 1.1184 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7988 - loss: 0.8986 - val_accuracy: 0.7654 - val_loss: 1.1207 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7956 - loss: 0.9026 - val_accuracy: 0.7618 - val_loss: 1.1226 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8040 - loss: 0.8823 - val_accuracy: 0.7659 - val_loss: 1.0988 - learning_rate: 1.0000e-04\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 1.0092\n",
      "Test loss: 1.0522531270980835, Test accuracy: 0.769535481929779\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 학습\n",
    "history = model.fit(\n",
    "    [X_train_tfidf, X_train_sequences], y_train_machinery,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# 9. 모델 평가\n",
    "loss, accuracy = model.evaluate([X_test_tfidf, X_test_sequences], y_test_machinery)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65235536-750c-4fd5-9014-3dbc12f853ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "input_tfidf = Input(shape=(X_tfidf.shape[1],), name='tfidf_input')\n",
    "input_sequences = Input(shape=(max_length,), name='sequences_input')\n",
    "\n",
    "embedding_layer = Embedding(input_dim=20000, output_dim=50, input_length=max_length)(input_sequences)\n",
    "embedding_flattened = Flatten()(embedding_layer)\n",
    "\n",
    "concat = Concatenate()([input_tfidf, embedding_flattened])\n",
    "\n",
    "dense1 = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(concat)  # 유닛 수를 줄임\n",
    "batch_norm1 = BatchNormalization()(dense1)\n",
    "dropout1 = Dropout(0.4)(batch_norm1)\n",
    "\n",
    "# 출력층\n",
    "output = Dense(62, activation='softmax')(dropout1)  \n",
    "\n",
    "model = Model(inputs=[input_tfidf, input_sequences], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ea4364d-65a4-4fe4-8471-1695a39b7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a3067be-3c7f-4f78-92c8-fe7a6e9054d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3321 - loss: 3.3425 - val_accuracy: 0.6348 - val_loss: 3.6239\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7263 - loss: 1.3002 - val_accuracy: 0.7425 - val_loss: 2.7700\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7895 - loss: 0.9237 - val_accuracy: 0.7812 - val_loss: 1.7119\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8329 - loss: 0.7267 - val_accuracy: 0.8019 - val_loss: 0.9696\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8740 - loss: 0.5706 - val_accuracy: 0.7969 - val_loss: 0.8391\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8830 - loss: 0.5038 - val_accuracy: 0.8086 - val_loss: 0.7772\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.4406 - val_accuracy: 0.8077 - val_loss: 0.7843\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9018 - loss: 0.4006 - val_accuracy: 0.8104 - val_loss: 0.7702\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8999 - loss: 0.3777 - val_accuracy: 0.8028 - val_loss: 0.7755\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.3859 - val_accuracy: 0.8073 - val_loss: 0.7663\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9003 - loss: 0.3521 - val_accuracy: 0.8091 - val_loss: 0.7732\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9121 - loss: 0.3300 - val_accuracy: 0.8082 - val_loss: 0.7891\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9046 - loss: 0.3330 - val_accuracy: 0.8005 - val_loss: 0.7752\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.3375 - val_accuracy: 0.8073 - val_loss: 0.7834\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9057 - loss: 0.3174 - val_accuracy: 0.8010 - val_loss: 0.7553\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.3075 - val_accuracy: 0.7897 - val_loss: 0.7713\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9011 - loss: 0.3084 - val_accuracy: 0.8046 - val_loss: 0.7650\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9070 - loss: 0.2985 - val_accuracy: 0.8136 - val_loss: 0.7717\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9095 - loss: 0.2855 - val_accuracy: 0.8023 - val_loss: 0.7639\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9040 - loss: 0.2932 - val_accuracy: 0.8082 - val_loss: 0.7604\n",
      "Epoch 21/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9044 - loss: 0.2848 - val_accuracy: 0.8041 - val_loss: 0.7486\n",
      "Epoch 22/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9048 - loss: 0.2754 - val_accuracy: 0.8082 - val_loss: 0.7577\n",
      "Epoch 23/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.2755 - val_accuracy: 0.8010 - val_loss: 0.7594\n",
      "Epoch 24/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9071 - loss: 0.2809 - val_accuracy: 0.8019 - val_loss: 0.7641\n",
      "Epoch 25/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9095 - loss: 0.2683 - val_accuracy: 0.8104 - val_loss: 0.7459\n",
      "Epoch 26/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9107 - loss: 0.2653 - val_accuracy: 0.8023 - val_loss: 0.7569\n",
      "Epoch 27/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9040 - loss: 0.2739 - val_accuracy: 0.8104 - val_loss: 0.7451\n",
      "Epoch 28/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9130 - loss: 0.2586 - val_accuracy: 0.7960 - val_loss: 0.7560\n",
      "Epoch 29/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9080 - loss: 0.2598 - val_accuracy: 0.8068 - val_loss: 0.7491\n",
      "Epoch 30/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9072 - loss: 0.2593 - val_accuracy: 0.8023 - val_loss: 0.7506\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.8317 - loss: 0.6383\n",
      "Test loss: 0.679698646068573, Test accuracy: 0.8177889585494995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    [X_train_tfidf, X_train_sequences], y_train_machinery,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate([X_test_tfidf, X_test_sequences], y_test_machinery)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326120e-813e-4373-909d-48aede04759d",
   "metadata": {},
   "source": [
    "### attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7072debd-83fc-40a2-a546-c140243d268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Dropout, BatchNormalization, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input_tfidf = Input(shape=(X_tfidf.shape[1],), name='tfidf_input')\n",
    "input_sequences = Input(shape=(max_length,), name='sequences_input')\n",
    "\n",
    "# 임베딩 레이어\n",
    "embedding_layer = Embedding(input_dim=20000, output_dim=50, input_length=max_length)(input_sequences)\n",
    "\n",
    "# Attention 메커니즘 적용\n",
    "attention = Attention()([embedding_layer, embedding_layer])\n",
    "attention_pooled = GlobalAveragePooling1D()(attention)\n",
    "\n",
    "# TF-IDF와 Attention 결합\n",
    "concat = Concatenate()([input_tfidf, attention_pooled])\n",
    "\n",
    "# 밀집 레이어 추가\n",
    "dense1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(concat)\n",
    "dropout1 = Dropout(0.4)(dense1)\n",
    "dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)\n",
    "\n",
    "# 출력층\n",
    "output = Dense(62, activation='softmax')(dropout2)\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model(inputs=[input_tfidf, input_sequences], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d796fcd1-1238-4d1b-88a9-790ea402eb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3479 - loss: 3.3222 - val_accuracy: 0.5912 - val_loss: 1.8494\n",
      "Epoch 2/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6100 - loss: 1.7920 - val_accuracy: 0.6452 - val_loss: 1.5575\n",
      "Epoch 3/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6639 - loss: 1.5056 - val_accuracy: 0.6812 - val_loss: 1.3965\n",
      "Epoch 4/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7054 - loss: 1.3353 - val_accuracy: 0.7217 - val_loss: 1.2889\n",
      "Epoch 5/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7303 - loss: 1.2109 - val_accuracy: 0.7380 - val_loss: 1.1968\n",
      "Epoch 6/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 1.1035 - val_accuracy: 0.7492 - val_loss: 1.1533\n",
      "Epoch 7/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7794 - loss: 1.0296 - val_accuracy: 0.7578 - val_loss: 1.1134\n",
      "Epoch 8/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7900 - loss: 0.9566 - val_accuracy: 0.7632 - val_loss: 1.0594\n",
      "Epoch 9/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7920 - loss: 0.9215 - val_accuracy: 0.7762 - val_loss: 1.0180\n",
      "Epoch 10/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8194 - loss: 0.8385 - val_accuracy: 0.7767 - val_loss: 1.0024\n",
      "Epoch 11/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8266 - loss: 0.8008 - val_accuracy: 0.7713 - val_loss: 0.9778\n",
      "Epoch 12/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8235 - loss: 0.7758 - val_accuracy: 0.7794 - val_loss: 0.9898\n",
      "Epoch 13/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8356 - loss: 0.7152 - val_accuracy: 0.7906 - val_loss: 0.9544\n",
      "Epoch 14/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8378 - loss: 0.7076 - val_accuracy: 0.7933 - val_loss: 0.9334\n",
      "Epoch 15/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8469 - loss: 0.6708 - val_accuracy: 0.7996 - val_loss: 0.9117\n",
      "Epoch 16/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8476 - loss: 0.6607 - val_accuracy: 0.7933 - val_loss: 0.9083\n",
      "Epoch 17/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8582 - loss: 0.6205 - val_accuracy: 0.7978 - val_loss: 0.9007\n",
      "Epoch 18/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8593 - loss: 0.6089 - val_accuracy: 0.7861 - val_loss: 0.9080\n",
      "Epoch 19/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.5957 - val_accuracy: 0.8032 - val_loss: 0.9280\n",
      "Epoch 20/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8701 - loss: 0.5690 - val_accuracy: 0.8050 - val_loss: 0.9123\n",
      "Epoch 21/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8788 - loss: 0.5459 - val_accuracy: 0.8019 - val_loss: 0.8800\n",
      "Epoch 22/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8752 - loss: 0.5414 - val_accuracy: 0.7996 - val_loss: 0.8842\n",
      "Epoch 23/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8799 - loss: 0.5282 - val_accuracy: 0.8095 - val_loss: 0.8766\n",
      "Epoch 24/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8751 - loss: 0.5161 - val_accuracy: 0.7870 - val_loss: 0.8927\n",
      "Epoch 25/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8801 - loss: 0.4971 - val_accuracy: 0.8019 - val_loss: 0.8945\n",
      "Epoch 26/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8703 - loss: 0.5059 - val_accuracy: 0.8032 - val_loss: 0.8976\n",
      "Epoch 27/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.4800 - val_accuracy: 0.7938 - val_loss: 0.8805\n",
      "Epoch 28/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.4751 - val_accuracy: 0.7992 - val_loss: 0.8879\n",
      "Epoch 29/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.4682 - val_accuracy: 0.8091 - val_loss: 0.8871\n",
      "Epoch 30/30\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8824 - loss: 0.4676 - val_accuracy: 0.8104 - val_loss: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ed5c0b32c0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit([X_train_tfidf, X_train_sequences], y_train_machinery, validation_split=0.2, epochs=30, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80a913a3-806f-4cf0-a3a3-2905b37ca78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8266 - loss: 0.7453\n",
      "Test loss: 0.8006126880645752, Test accuracy: 0.8170687556266785\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate([X_test_tfidf, X_test_sequences], y_test_machinery)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e558f1-25ea-4c80-ac26-fb5c9e08f654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
