{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de827958-8584-401f-9d62-1c3ecb4de85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9715e073-3876-4b8a-8d27-9987e232a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('filtered_30_filled_money.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94099074-a4c5-4800-877c-2d657cd73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bd270e-abd8-44ab-a486-48469d26853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "data['cleaned_item'] = data['청구품목'].apply(preprocess_text)\n",
    "data['cleaned_supplier'] = data['발주처'].apply(clean_supplier_name)\n",
    "data['combined_text'] = data['cleaned_item'].fillna('') + \" \" + data['Part No.1'].fillna('') + \" \" + data['cleaned_supplier'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f5153d-187c-494f-bc74-1194a8f7c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates = {'USD': 1, 'KRW': 0.00078, 'EUR': 1.18, 'JPY': 0.0091}\n",
    "\n",
    "# usd기준해서 금액 통일함 \n",
    "data['converted_price'] = data.apply(lambda x: x['견적단가'] * exchange_rates[x['견적화폐']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b45129-3e52-490c-a953-21ef3b1756d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USD' 'KRW' 'EUR' 'JPY'] 0\n"
     ]
    }
   ],
   "source": [
    "print(data['견적화폐'].unique(), data['견적화폐'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c8df14-38bf-4da4-9c92-3f8a5305c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_ohe = OneHotEncoder(sparse_output=False) \n",
    "currency_encoded = currency_ohe.fit_transform(data[['견적화폐']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4655b8ab-ae1b-4280-b44b-1d0d2ae15695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y= label_encoder.fit_transform(data['Machinery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8522452-bdfc-4c8a-9027-d460b64428bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_text shape: (13882,)\n",
      "currency_encoded shape: (13882, 4)\n",
      "converted_price shape: (13882,)\n",
      "X shape after concatenation: (13882, 6)\n",
      "X_train size: (10029, 6)\n",
      "X_val size: (1770, 6)\n",
      "X_test size: (2083, 6)\n"
     ]
    }
   ],
   "source": [
    "# train_test split 을 위해 하나로 모으고, 분할하고 다시 텍스트랑 추가피쳐로 분리해줄거임 \n",
    "\n",
    "# 1. 텍스트 + 추가 피처 결합\n",
    "X = np.concatenate([\n",
    "    data['combined_text'].values.reshape(-1, 1),  # 2차원 배열로 바꿔서 결합해줌 \n",
    "    currency_encoded, \n",
    "    data['converted_price'].values.reshape(-1, 1)  # 통일한단가\n",
    "], axis=1)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# 크기 확인\n",
    "print(f\"combined_text shape: {data['combined_text'].shape}\")\n",
    "print(f\"currency_encoded shape: {currency_encoded.shape}\")\n",
    "print(f\"converted_price shape: {data['converted_price'].shape}\")\n",
    "print(f\"X shape after concatenation: {X.shape}\")\n",
    "\n",
    "print(f\"X_train size: {X_train.shape}\")\n",
    "print(f\"X_val size: {X_val.shape}\")\n",
    "print(f\"X_test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1205a554-0603-4f20-b3b1-bbf075614ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_extra_features size: (10029, 5)\n",
      "val_extra_features size: (1770, 5)\n",
      "test_extra_features size: (2083, 5)\n"
     ]
    }
   ],
   "source": [
    "#텍스트분리\n",
    "train_combined_text = X_train[:, 0] \n",
    "val_combined_text = X_val[:, 0]\n",
    "test_combined_text = X_test[:, 0]\n",
    "\n",
    "train_extra_features = X_train[:, 1:]  # 이 부분에서 이미 2차원으로 분리됨\n",
    "val_extra_features = X_val[:, 1:]\n",
    "test_extra_features = X_test[:, 1:]\n",
    "\n",
    "# object타입이 섞여있다고 해서 astype float 명시해줌\n",
    "train_extra_features = np.nan_to_num(train_extra_features, nan=0.0).astype(float)\n",
    "val_extra_features = np.nan_to_num(val_extra_features, nan=0.0).astype(float)\n",
    "test_extra_features = np.nan_to_num(test_extra_features, nan=0.0).astype(float)\n",
    "\n",
    "# Torch Tensor로 변환 - 추가로 변환할 필요 없이 2차원 유지\n",
    "train_extra_features_tensor = torch.tensor(train_extra_features, dtype=torch.float32)  # 이미 2차원\n",
    "val_extra_features_tensor = torch.tensor(val_extra_features, dtype=torch.float32)\n",
    "test_extra_features_tensor = torch.tensor(test_extra_features, dtype=torch.float32)\n",
    "\n",
    "# 크기 확인\n",
    "print(f\"train_extra_features size: {train_extra_features.shape}\")\n",
    "print(f\"val_extra_features size: {val_extra_features.shape}\")\n",
    "print(f\"test_extra_features size: {test_extra_features.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecdda32-f4f2-43c5-825a-dd17b34b404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_extra_features dtype: float64\n",
      "val_extra_features dtype: float64\n",
      "test_extra_features dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 확인\n",
    "print(f\"train_extra_features dtype: {train_extra_features.dtype}\")\n",
    "print(f\"val_extra_features dtype: {val_extra_features.dtype}\")\n",
    "print(f\"test_extra_features dtype: {test_extra_features.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12affe13-a536-4714-913c-70912dd1abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저 (텍스트처리)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44558653-ff97-42cb-a192-c6b0dd9e8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X중 텍스트만 BERT 입력 형식으로 변환\n",
    "def encode_data(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_encodings = encode_data(train_combined_text)\n",
    "val_encodings = encode_data(val_combined_text)\n",
    "test_encodings = encode_data(test_combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e97158-70b4-4ece-99f5-8bf3c78f476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 텍스트 인코딩 + 추가 피처 더해서 dataset 생성\n",
    "train_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'],\n",
    "    train_encodings['attention_mask'],\n",
    "    train_extra_features_tensor,\n",
    "    torch.tensor(y_train),\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'],\n",
    "    val_encodings['attention_mask'],\n",
    "    val_extra_features_tensor,\n",
    "    torch.tensor(y_val),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'],\n",
    "    test_encodings['attention_mask'],\n",
    "    test_extra_features_tensor,\n",
    "    torch.tensor(y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c6fc79-7f45-4a76-b7ca-001707c64f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train size: (10029,)\n",
      "y_val size: (1770,)\n",
      "y_test size: (2083,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train size: {y_train.shape}\")\n",
    "print(f\"y_val size: {y_val.shape}\")\n",
    "print(f\"y_test size: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c5b89d-d987-4d05-9d72-e1ba20c3e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a8452c-0350-448f-b5c5-641b8e512ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMachinery(nn.Module):\n",
    "    def __init__(self, num_machinery_labels, extra_features_dim):\n",
    "        super(BertForMachinery, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.machinery_classifier = nn.Linear(self.bert.config.hidden_size + extra_features_dim, num_machinery_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, extra_features):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        # 2차원으로 만듦 (batch_size, 1)\n",
    "        if extra_features.dim() == 1:\n",
    "            extra_features = extra_features.unsqueeze(1)\n",
    "            \n",
    "        machinery_combined_features = torch.cat((pooled_output, extra_features), dim=1)\n",
    "        machinery_outputs = self.machinery_classifier(machinery_combined_features)\n",
    "\n",
    "        return machinery_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f8589d-d1e7-4fcd-9d91-0634e8e6249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62779f71-0ceb-44dd-be47-bf9b697296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMachinery(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (machinery_classifier): Linear(in_features=773, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "machinery_model = BertForMachinery(num_machinery_labels=len(label_encoder.classes_), extra_features_dim=5) \n",
    "machinery_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1757acf9-d3fc-45a2-9387-9823089c2016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: torch.Size([10029])\n",
      "y_val shape: torch.Size([1770])\n",
      "y_test shape: torch.Size([2083])\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train shape: {torch.tensor(y_train).shape}\")\n",
    "print(f\"y_val shape: {torch.tensor(y_val).shape}\")\n",
    "print(f\"y_test shape: {torch.tensor(y_test).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4db600-e114-4be6-834e-5d153ba444b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 학습률 스케줄러 설정\n",
    "optimizer = AdamW(machinery_model.parameters(), lr=2e-5)\n",
    "loss_fn=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772d3add-051f-4e5c-b5d0-c9c7ce008715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]  # 순서 수정\n",
    "        \n",
    "        if labels.dim() > 1:\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "        labels = labels.to(torch.int64)  # CrossEntropyLoss에 맞게 변환\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9990e338-c952-4a12-ba6e-b5d960e884ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# 평가 함수 - logits-62개짜리 각각의 자신감\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    machinery_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, attention_mask, extra_features, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, extra_features=extra_features)\n",
    "            \n",
    "            # logits를 사용하여 정확한 예측값 계산\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            # 예측값을 저장\n",
    "            machinery_predictions.append(predicted.cpu().numpy())  # 리스트에 추가\n",
    "            \n",
    "            # 정확도 계산\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    machinery_predictions = np.concatenate(machinery_predictions, axis=0)  \n",
    "    return accuracy, machinery_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381695c8-99af-44f7-b5d6-425661364fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/627 [00:00<?, ?it/s]C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      " 53%|██████████████████████████████████████████▏                                     | 331/627 [01:40<01:28,  3.36it/s]"
     ]
    }
   ],
   "source": [
    "# 학습 실행\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(machinery_model, train_loader, optimizer, device)\n",
    "    train_acc, train_machinery_predictions = evaluate(machinery_model, train_loader, device)  \n",
    "    val_acc, val_machinery_predictions = evaluate(machinery_model, val_loader, device)        \n",
    "    test_acc, test_machinery_predictions = evaluate(machinery_model, test_loader, device)    \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc : {val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 최종 테스트 성능 평가\n",
    "final_test_acc, final_machinery_predictions = evaluate(machinery_model, test_loader, device)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(machinery_model.state_dict(), \"machinery_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aea936-31d1-4027-8cad-f4c5baa664b7",
   "metadata": {},
   "source": [
    "### 전이 학습으로 Assembly 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa58e3-c59b-4f5a-a8f3-4d0fefab3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machinery 모델 로드 및 가중치 고정\n",
    "machinery_model = BertForMachinery(num_machinery_labels=len(label_encoder.classes_), extra_features_dim=5)\n",
    "machinery_model.load_state_dict(torch.load(\"machinery_model.pth\"))\n",
    "machinery_model.eval() \n",
    "\n",
    "for param in machinery_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76142c-7b47-4d8e-a923-9ed194d8fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_label_encoder = LabelEncoder()\n",
    "y_assembly = assembly_label_encoder.fit_transform(data['Assembly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df8fea-34da-4f8d-ac19-6dadc7c7e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#텍스트 + 추가 피처 결합-machinery에서 썼던거 그대로임 \n",
    "X = np.concatenate([\n",
    "    data['combined_text'].values.reshape(-1, 1), \n",
    "    currency_encoded, \n",
    "    data['converted_price'].values.reshape(-1, 1)\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062d158-60d9-4024-9fd5-7db4b4ba091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_assembly, X_test_assembly, y_train_val_assembly, y_test_assembly = train_test_split(\n",
    "    X, y_assembly, test_size=0.15, random_state=42, stratify=y_assembly)\n",
    "\n",
    "X_train_assembly, X_val_assembly, y_train_assembly, y_val_assembly = train_test_split(\n",
    "    X_train_val_assembly, y_train_val_assembly, test_size=0.15, stratify=y_train_val_assembly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95b5f4-9a58-4847-9a77-912339d74561",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_machinery_predictions = train_machinery_predictions.reshape(-1, 1)\n",
    "val_machinery_predictions = val_machinery_predictions.reshape(-1, 1)\n",
    "test_machinery_predictions = test_machinery_predictions.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f974e-3e04-4c55-ae8b-e16ba60cde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_encodings['input_ids'] shape:\", train_encodings['input_ids'].shape)\n",
    "print(\"train_encodings['attention_mask'] shape:\", train_encodings['attention_mask'].shape)\n",
    "print(\"train_extra_features_tensor shape:\", train_extra_features_tensor.shape)\n",
    "print(\"train_machinery_predictions shape:\", train_machinery_predictions.shape)\n",
    "print(\"y_train_assembly shape:\", torch.tensor(y_train_assembly, dtype=torch.long).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fbef1-7449-455a-9b68-cc97c4041a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch Tensor로 변환\n",
    "train_assembly_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'],                \n",
    "    train_encodings['attention_mask'],           \n",
    "    train_extra_features_tensor,                 \n",
    "    torch.tensor(train_machinery_predictions, dtype=torch.float32), \n",
    "    torch.tensor(y_train_assembly, dtype=torch.long)  # Assembly 레이블\n",
    ")\n",
    "\n",
    "val_assembly_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'],\n",
    "    val_encodings['attention_mask'],\n",
    "    val_extra_features_tensor,\n",
    "    torch.tensor(val_machinery_predictions, dtype=torch.float32),\n",
    "    torch.tensor(y_val_assembly, dtype=torch.long)\n",
    ")\n",
    "\n",
    "test_assembly_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'],\n",
    "    test_encodings['attention_mask'],\n",
    "    test_extra_features_tensor,\n",
    "    torch.tensor(test_machinery_predictions, dtype=torch.float32),\n",
    "    torch.tensor(y_test_assembly, dtype=torch.long)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac01ed3-277c-4d3d-8062-6d369086a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader_assembly = DataLoader(train_assembly_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_assembly  = DataLoader(val_assembly_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader_assembly = DataLoader(test_assembly_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062254c-9995-4dfb-be22-86cab02dc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_assembly_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    input_ids, attention_mask, extra_features, machinery_predictions, labels = batch\n",
    "    print(f\"Batch size: {len(batch)}\")\n",
    "    print(f\"input_ids shape: {input_ids.shape}\")\n",
    "    print(f\"attention_mask shape: {attention_mask.shape}\")\n",
    "    print(f\"extra_features shape: {extra_features.shape}\")\n",
    "    print(f\"machinery_predictions shape: {machinery_predictions.shape}\")\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "    break  # 확인 후 반복을 중지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62ef79-9b6b-4eff-a048-20bdb64957a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(\"Batch length:\", len(batch))\n",
    "    print(\"First element shape (input_ids):\", batch[0].shape)\n",
    "    print(\"Second element shape (attention_mask):\", batch[1].shape)\n",
    "    print(\"Third element shape (extra_features):\", batch[2].shape)\n",
    "    print(\"Fourth element shape (machinery_predictions):\", batch[3].shape)\n",
    "    print(\"Fifth element shape (labels):\", batch[4].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5489b7-800a-4735-9aa6-55039e95e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assembly_labels = len(assembly_label_encoder.classes_)\n",
    "machinery_output_dim = 62 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28355938-0a2c-4317-bdef-6fe2504aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssemblyModel(nn.Module):\n",
    "    def __init__(self, num_assembly_labels, extra_features_dim, machinery_output_dim):\n",
    "        super(AssemblyModel, self).__init__()\n",
    "        self.assembly_classifier = nn.Linear(extra_features_dim + machinery_output_dim, num_assembly_labels)\n",
    "    \n",
    "    def forward(self, machinery_predictions, extra_features):\n",
    "        machinery_predictions = machinery_predictions.view(-1, machinery_predictions.size(1))\n",
    "        \n",
    "        # extra_features와 결합\n",
    "        combined_features = torch.cat((machinery_predictions, extra_features), dim=1)\n",
    "        \n",
    "        # 어셈블리 예측\n",
    "        assembly_outputs = self.assembly_classifier(combined_features)\n",
    "        return assembly_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1f66b-0ada-4bac-8def-d65fd51cda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_model = AssemblyModel(num_assembly_labels=len(assembly_label_encoder.classes_), extra_features_dim=5, machinery_output_dim=machinery_output_dim)\n",
    "assembly_model.to(device)\n",
    "\n",
    "optimizer_assembly = AdamW(assembly_model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52308b-f51a-452d-9bcb-5ecc80e826cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "assembly_model.to(device)\n",
    "machinery_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65cc0-a1b1-4143-aa6c-25ae3d5ec897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly 모델 학습 함수\n",
    "def train_assembly(model, machinery_model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, extra_features, machinery_predictions, labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            machinery_outputs = machinery_model(input_ids, attention_mask, extra_features)\n",
    "\n",
    "        outputs = model(machinery_outputs, extra_features)\n",
    "        labels = labels.to(torch.int64)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df772767-a7b4-48de-b958-3f7df967744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_assembly(model, dataloader, device):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, extra_features, machinery_predictions, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # 머신러닝 모델에서 출력값 얻기\n",
    "            machinery_outputs = machinery_model(input_ids, attention_mask, extra_features)\n",
    "            \n",
    "            # Assembly 모델에서 예측값 얻기\n",
    "            outputs = model(machinery_outputs, extra_features)\n",
    "            \n",
    "            # 예측값과 실제값 비교\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2420e-989b-463d-adef-b0ab856965ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_assembly(assembly_model, machinery_model, train_loader_assembly, optimizer_assembly, device)\n",
    "    train_acc = evaluate_assembly(assembly_model, train_loader_assembly, device)\n",
    "    val_acc = evaluate_assembly(assembly_model, val_loader_assembly, device)\n",
    "    test_acc = evaluate_assembly(assembly_model, test_loader_assembly, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999115a-fd7b-448c-939f-a12ebec64c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
