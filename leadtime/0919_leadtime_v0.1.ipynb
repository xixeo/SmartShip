{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496f2a9e-661c-4800-af46-a4eeefc9998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead46d44-e3c4-464b-9c55-8e68b61685f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('dataset_filledsupplier_currency_orderday.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05aef43a-0b3e-408b-ba95-70285b38f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24621 entries, 0 to 24620\n",
      "Data columns (total 32 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   청구서번호        24621 non-null  object \n",
      " 1   No.          24621 non-null  int64  \n",
      " 2   Subject      24599 non-null  object \n",
      " 3   Machinery    24621 non-null  object \n",
      " 4   Assembly     24621 non-null  object \n",
      " 5   청구품목         24621 non-null  object \n",
      " 6   Unnamed: 6   0 non-null      float64\n",
      " 7   Part No.1    24602 non-null  object \n",
      " 8   Part No.2    3592 non-null   object \n",
      " 9   청구량          24517 non-null  float64\n",
      " 10  견적           24171 non-null  object \n",
      " 11  견적수량         24517 non-null  float64\n",
      " 12  견적화폐         24621 non-null  object \n",
      " 13  견적단가         24621 non-null  float64\n",
      " 14  발주번호         24621 non-null  object \n",
      " 15  발주처          24621 non-null  object \n",
      " 16  발주           24621 non-null  object \n",
      " 17  발주수량         24621 non-null  int64  \n",
      " 18  발주금액         24621 non-null  float64\n",
      " 19  D/T          22292 non-null  object \n",
      " 20  미입고 기간       1620 non-null   object \n",
      " 21  창고입고         21302 non-null  object \n",
      " 22  창고입고수량       24621 non-null  int64  \n",
      " 23  Control No.  15433 non-null  object \n",
      " 24  입고창고         21302 non-null  object \n",
      " 25  창고출고         19258 non-null  object \n",
      " 26  창고출고수량       24621 non-null  int64  \n",
      " 27  출고선박         19258 non-null  object \n",
      " 28  출고운반선        19258 non-null  object \n",
      " 29  선박입고         5374 non-null   object \n",
      " 30  선박입고수량       24621 non-null  int64  \n",
      " 31  완료 여부        5362 non-null   object \n",
      "dtypes: float64(5), int64(5), object(22)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2089545-cb02-4012-88a9-0da4869c274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발주 일자는 있지만 미입고 기간, 창고 입고, 선박 입고도 없는 경우: 1699개\n",
      "삭제된 행의 개수: 1699개\n",
      "남은 데이터프레임의 크기: (22922, 32)\n"
     ]
    }
   ],
   "source": [
    "missing_conditions = df[\n",
    "    df['발주'].notnull() &  # 발주 일자는 비어있지 않음\n",
    "    df['미입고 기간'].isnull() &  # 미입고 기간은 비어있음\n",
    "    df['창고입고'].isnull() & # 창고 입고도 비어있음\n",
    "    df['선박입고'].isnull()  # 선박 입고도 비어있음\n",
    "\n",
    "]\n",
    "\n",
    "print(f\"발주 일자는 있지만 미입고 기간, 창고 입고, 선박 입고도 없는 경우: {len(missing_conditions)}개\")\n",
    "# 해당 조건의 행 삭제\n",
    "df = df.drop(missing_conditions.index)\n",
    "\n",
    "print(f\"삭제된 행의 개수: {len(missing_conditions)}개\")\n",
    "print(f\"남은 데이터프레임의 크기: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116fd26a-b562-4f62-a379-b2f3c8de8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "창고 입고일은 없고 미입고 기간은 명시되어 있어 미입고 기간으로 분류해야 할 경우 : 1620개\n"
     ]
    }
   ],
   "source": [
    "#미입고기간으로 처리.\n",
    "missing_both = df[df['창고입고'].isnull() & df['미입고 기간'].notnull()]\n",
    "\n",
    "print(f\"창고 입고일은 없고 미입고 기간은 명시되어 있어 미입고 기간으로 분류해야 할 경우 : {len(missing_both)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5bfc4-84f3-4bd3-9331-c7b2fbb369e0",
   "metadata": {},
   "source": [
    "# 리드타임 계산\n",
    "\n",
    "> 1. 발주와 입고가 같은 경우 리드타임을 1로 설정\n",
    "> 2. 발주 수량과 입고 수량이 같은 경우, 일반 계산\n",
    "> 3. 발주 수량과 입고 수량이 다른 경우에는 가중 평균을 리드타임을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7c6f0d-1824-4137-b59c-b9b42303c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "창고입고와 발주 날짜가 같은 행의 개수: 292\n"
     ]
    }
   ],
   "source": [
    "df['발주'] = pd.to_datetime(df['발주'])\n",
    "df['창고입고'] = pd.to_datetime(df['창고입고'])\n",
    "\n",
    "same_date_df = df[df['발주'] == df['창고입고']]\n",
    "\n",
    "# 필터링된 행의 수를 세기\n",
    "count_same_date = same_date_df.shape[0]\n",
    "\n",
    "print(f\"창고입고와 발주 날짜가 같은 행의 개수: {count_same_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6ec9ef-10a1-4bac-ae90-1d40b4649942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['발주'] = pd.to_datetime(df['발주'], errors='coerce')\n",
    "df['창고입고'] = pd.to_datetime(df['창고입고'], errors='coerce')\n",
    "\n",
    "# 미입고기간 처리\n",
    "def convert_leadtime(기간):\n",
    "    if 기간 == '1개월':\n",
    "        return 1001\n",
    "    elif 기간 == '3개월':\n",
    "        return 1002\n",
    "    elif 기간 == '6개월':\n",
    "        return 1003\n",
    "    elif 기간 == '6개월 초과':\n",
    "        return 1004\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "df['delay'] = df['미입고 기간'].apply(convert_leadtime)\n",
    "\n",
    "# 리드타임 계산 \n",
    "def calculate_leadtime(row):\n",
    "    if pd.isna(row['창고입고']):\n",
    "        return None  # 입고가 없는 경우\n",
    "    elif row['발주'] == row['창고입고']:\n",
    "        return 1  # 발주와 입고가 같은 경우 리드타임 1\n",
    "    else:\n",
    "        return (row['창고입고'] - row['발주']).days \n",
    "\n",
    "# 미입고기간이 없는 경우 리드타임 계산\n",
    "df['leadtime'] = df.apply(lambda row: calculate_leadtime(row) if pd.isna(row['미입고 기간']) else None, axis=1)\n",
    "\n",
    "# 가중리드타임 초기화\n",
    "df['weighted_leadtime'] = None\n",
    "\n",
    "# 미입고기간이 없는 데이터에 대해 가중 평균 리드타임 계산\n",
    "df_filtered = df[df['미입고 기간'].isna()]\n",
    "grouped = df_filtered.groupby(['발주처', '발주', '발주수량', '발주금액'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    if len(group) > 1 and group['창고입고수량'].nunique() > 1:\n",
    "        weighted_leadtime = (group['leadtime'] * group['창고입고수량']).sum() / group['창고입고수량'].sum()\n",
    "        df.loc[group.index, 'weighted_leadtime'] = weighted_leadtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1343e7a-3837-43d8-80a5-a0ff561132fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weighted_leadtime'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e852486-e2da-4a1a-8611-e792008814d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'target' 열 정의 (weighted_leadtime이 있으면 사용, 없으면 leadtime 사용)\n",
    "df['target'] = df['weighted_leadtime'].combine_first(df['leadtime'])\n",
    "df['y'] = df['target'].combine_first(df['delay'])  # 미입고 기간 값도 함께 결합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603b7e9c-fbf8-45d8-9c07-69011af476f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  target  delay      y\n",
      "0  112.0    NaN  112.0\n",
      "1   97.0    NaN   97.0\n",
      "2  112.0    NaN  112.0\n",
      "3    1.0    NaN    1.0\n",
      "4    1.0    NaN    1.0\n"
     ]
    }
   ],
   "source": [
    "# 'y' 열에 결측값이 있는지 확인\n",
    "print(df['y'].isnull().sum())  # 결측값이 몇 개인지 확인\n",
    "\n",
    "# 'y' 열이 잘 생성되었는지 데이터프레임 확인\n",
    "print(df[['target', 'delay', 'y']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd1e44-29c5-4b66-960b-2358e2e5fc02",
   "metadata": {},
   "source": [
    "> XGBRegressor로 특성 중요도 분석 결과 > 견적화폐 0.6 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315aaac3-23bc-4114-aa65-724a5fdaac0d",
   "metadata": {},
   "source": [
    "# 다중 출력 모델\n",
    "### 리드타임 예측 (회귀) / 미입고 기간 예측 (분류) \n",
    "1. 텍스트 칼럼 결합 및 BERT 임베딩\n",
    "2. ( 수치형 데이터(견적단가 및 발주량) Scaling )\n",
    "3. 범주형 데이터(견적화폐) onehotEncoding\n",
    "4. BERT 임베딩 유사도 => 모델의 입력, 2.3데이터 결합 => 리드타임 OR 미입고 기간 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d70ed1-77d4-4466-9716-5a2f4ebe6eb1",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81e9c88-d80d-45b4-b343-f433a440d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\*/\\-\\+.,#&]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\b(사용금지|사)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def clean_supplier_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'coporation|coropration|coproration|corporration', 'corporation', name)\n",
    "    name = re.sub(r'\\(사용금지\\)', '', name)\n",
    "    name = re.sub(r'u\\.s\\.a', '_usa', name)\n",
    "    name = re.sub(r'\\.', '', name)\n",
    "    suffixes = r'(corporation|corp|company|co|incorporated|inc|limited|ltd|상사|공사|엔지니어링|주식회사|주|gmbh|pte ltd|llc)'\n",
    "    name = re.sub(suffixes, '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f08286-d27f-4c2a-afca-dce765e72b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 컬럼 리스트\n",
    "text_columns = ['Machinery', 'Assembly', '청구품목', 'Part No.1', '발주처']\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "df['cleaned_machinery'] = df['Machinery'].apply(preprocess_text)\n",
    "df['cleaned_assembly'] = df['Assembly'].apply(preprocess_text)\n",
    "df['cleaned_item'] = df['청구품목'].apply(preprocess_text)\n",
    "df['cleaned_supplier'] = df['발주처'].apply(clean_supplier_name)\n",
    "\n",
    "df['combined_text'] = (\n",
    "    df['cleaned_machinery'].fillna('') + \" \" +\n",
    "    df['cleaned_assembly'].fillna('') + \" \" +\n",
    "    df['cleaned_item'].fillna('') + \" \" +\n",
    "    df['Part No.1'].fillna('') + \" \" +\n",
    "    df['cleaned_supplier'].fillna('')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4db833-ea51-454c-b7f2-53e772c872e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22922, 16)\n",
      "                          Machinery       Assembly  \\\n",
      "0    CARGO BOOM VANG BLOCK (STBD 하)          BLOCK   \n",
      "1  SPANISH BOOM VANG BLOCK (PORT 상)          BLOCK   \n",
      "2                       PURSE BLOCK      TOW BLOCK   \n",
      "3                       MAIN ENGINE  POWER PACK AS   \n",
      "4                       MAIN ENGINE  POWER PACK AS   \n",
      "\n",
      "                                               청구품목               Part No.1  \\\n",
      "0  MCKISSICK CONSTRUCTION BLOCKS (WIRE SIZE : 5/8\")                C15S10BS   \n",
      "1  MCKISSICK CONSTRUCTION BLOCKS (WIRE SIZE : 5/8\")                C15D10BS   \n",
      "2                            WESTEC 20TON TOW BLOCK  WESTEC 20TON TOW BLOCK   \n",
      "3                        GE POWER PACK FORK - E7(B)                40028340   \n",
      "4                        GE POWER PACK FORK - E7(B)                40028340   \n",
      "\n",
      "                         발주처 견적화폐  발주수량          발주금액 미입고 기간       창고입고  \\\n",
      "0  MATSUI(U.S.A) COROPRATION  USD     2  2.288732e+06    NaN 2019-05-03   \n",
      "1  MATSUI(U.S.A) COROPRATION  USD     1  1.917750e+06    NaN 2019-04-18   \n",
      "2  MATSUI(U.S.A) COROPRATION  USD     1  6.538572e+06    NaN 2019-05-03   \n",
      "3  MATSUI(U.S.A) COROPRATION  USD     8  3.680000e+07    NaN 2019-04-01   \n",
      "4  MATSUI(U.S.A) COROPRATION  USD     8  3.680000e+07    NaN 2019-04-01   \n",
      "\n",
      "   leadtime weighted_leadtime  delay  \\\n",
      "0     112.0              None    NaN   \n",
      "1      97.0              None    NaN   \n",
      "2     112.0              None    NaN   \n",
      "3       1.0              None    NaN   \n",
      "4       1.0              None    NaN   \n",
      "\n",
      "                                       combined_text target      y  \n",
      "0  cargo boom vang block block mckissick construc...  112.0  112.0  \n",
      "1  spanish boom vang block block mckissick constr...   97.0   97.0  \n",
      "2  purse block tow block westec 20ton tow block W...  112.0  112.0  \n",
      "3  main engine power pack as ge power pack fork -...    1.0    1.0  \n",
      "4  main engine power pack as ge power pack fork -...    1.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "# 최종 데이터프레임 선택\n",
    "final_df = df[['Machinery', 'Assembly', '청구품목', 'Part No.1', '발주처', '견적화폐', \n",
    "               '발주수량', '발주금액', '미입고 기간', '창고입고', 'leadtime', \n",
    "               'weighted_leadtime', 'delay', 'combined_text', 'target', 'y']].copy()\n",
    "\n",
    "# 최종 데이터프레임 확인\n",
    "print(final_df.shape)\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2a5214-632b-47cc-abf4-703fe3a81105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder 초기화 및 변환 (final_df에 적용)\n",
    "currency_ohe = OneHotEncoder(sparse_output=False)\n",
    "currency_encoded = currency_ohe.fit_transform(final_df[['견적화폐']])\n",
    "currency_encoded_df = pd.DataFrame(currency_encoded, columns=currency_ohe.get_feature_names_out(['견적화폐']))\n",
    "\n",
    "# 원본 데이터프레임에 원-핫 인코딩된 화폐 정보 추가\n",
    "data = pd.concat([final_df.reset_index(drop=True), currency_encoded_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e2a9db-7a53-4dcf-8537-47233a694719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_df shape: (22922, 16)\n",
      "Currency_encoded_df shape: (22922, 4)\n",
      "Data shape after concat: (22922, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final_df shape: {final_df.shape}\")\n",
    "print(f\"Currency_encoded_df shape: {currency_encoded_df.shape}\")\n",
    "print(f\"Data shape after concat: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7596faee-a71b-47d5-9d53-0f7fb46ff55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['leadtime'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616a4b88-d4f6-40cf-933a-5fa76101ac70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['미입고 기간'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09e80597-4500-44ad-860f-b8b47630ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea612f1-3192-4263-bccb-40dc435ebd1d",
   "metadata": {},
   "source": [
    "### 데이터 분할\n",
    "\n",
    "> 리드타임 예측 데이터와 미입고 기간 분류 데이터로 나누어서 각각 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbbd380a-07de-42d9-8df0-c9b6399434fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "256dfcee-5422-4415-88ec-1524ff526e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba3b437a-f7c4-4f67-9dd5-5953083de550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59be1439-060e-42fb-8169-f6693d6c4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batchwise(encodings, model, batch_size=16):\n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], encodings['token_type_ids'])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    all_embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, token_type_ids = [t.to(device) for t in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            all_embeddings.append(outputs.pooler_output.cpu())\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "331936e9-f40b-4751-a31b-ecaf5f6be7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 리드타임 예측용 데이터\n",
    "train_leadtime = data[~data['target'].isnull()]\n",
    "X_leadtime_text = train_leadtime['combined_text']\n",
    "X_leadtime_features = train_leadtime[currency_encoded_df.columns]\n",
    "y_leadtime = train_leadtime['target']\n",
    "\n",
    "# 미입고 기간 분류용 데이터\n",
    "train_delay = data[~data['delay'].isnull()]\n",
    "X_delay_text = train_delay['combined_text']\n",
    "X_delay_features = train_delay[currency_encoded_df.columns]\n",
    "y_delay = train_delay['delay']\n",
    "\n",
    "# 리드타임용 train/val/test 분할\n",
    "X_train_leadtime_text, X_temp_leadtime_text, X_train_leadtime_features, X_temp_leadtime_features, y_train_leadtime, y_temp_leadtime = train_test_split(\n",
    "    X_leadtime_text, X_leadtime_features, y_leadtime, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val_leadtime_text, X_test_leadtime_text, X_val_leadtime_features, X_test_leadtime_features, y_val_leadtime, y_test_leadtime = train_test_split(\n",
    "    X_temp_leadtime_text, X_temp_leadtime_features, y_temp_leadtime, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 미입고 기간용 train/val/test 분할\n",
    "X_train_delay_text, X_temp_delay_text, X_train_delay_features, X_temp_delay_features, y_train_delay, y_temp_delay = train_test_split(\n",
    "    X_delay_text, X_delay_features, y_delay, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val_delay_text, X_test_delay_text, X_val_delay_features, X_test_delay_features, y_val_delay, y_test_delay = train_test_split(\n",
    "    X_temp_delay_text, X_temp_delay_features, y_temp_delay, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb92742-1f3c-4add-a2d5-77c530ce65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리드타임 예측용 데이터에서 null 값 확인:\n",
      "y_leadtime null 개수: 0\n",
      "미입고 기간 분류용 데이터에서 null 값 확인:\n",
      "y_delay null 개수: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"리드타임 예측용 데이터에서 null 값 확인:\")\n",
    "print(f\"y_leadtime null 개수: {y_leadtime.isnull().sum()}\")\n",
    "print(\"미입고 기간 분류용 데이터에서 null 값 확인:\")\n",
    "print(f\"y_delay null 개수: {y_delay.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0951c580-82b6-4607-928a-91cbc4f2d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test 데이터에 null 값 확인 (리드타임 예측용):\n",
      "y_train_leadtime null 개수: 0\n",
      "y_val_leadtime null 개수: 0\n",
      "y_test_leadtime null 개수: 0\n",
      "Train/Val/Test 데이터에 null 값 확인 (미입고 기간 분류용):\n",
      "y_train_delay null 개수: 0\n",
      "y_val_delay null 개수: 0\n",
      "y_test_delay null 개수: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train/Val/Test 데이터에 null 값 확인 (리드타임 예측용):\")\n",
    "print(f\"y_train_leadtime null 개수: {y_train_leadtime.isnull().sum()}\")\n",
    "print(f\"y_val_leadtime null 개수: {y_val_leadtime.isnull().sum()}\")\n",
    "print(f\"y_test_leadtime null 개수: {y_test_leadtime.isnull().sum()}\")\n",
    "\n",
    "print(\"Train/Val/Test 데이터에 null 값 확인 (미입고 기간 분류용):\")\n",
    "print(f\"y_train_delay null 개수: {y_train_delay.isnull().sum()}\")\n",
    "print(f\"y_val_delay null 개수: {y_val_delay.isnull().sum()}\")\n",
    "print(f\"y_test_delay null 개수: {y_test_delay.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d8b7b5a-7686-4f2a-8038-45c668e5afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\ship\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# 리드타임 예측용 임베딩\n",
    "train_leadtime_encodings = encode_data(X_train_leadtime_text)\n",
    "val_leadtime_encodings = encode_data(X_val_leadtime_text)\n",
    "test_leadtime_encodings = encode_data(X_test_leadtime_text)\n",
    "\n",
    "train_leadtime_embeddings = get_embeddings_batchwise(train_leadtime_encodings, bert_model, batch_size=8).to(device)\n",
    "val_leadtime_embeddings = get_embeddings_batchwise(val_leadtime_encodings, bert_model, batch_size=8).to(device)\n",
    "test_leadtime_embeddings = get_embeddings_batchwise(test_leadtime_encodings, bert_model, batch_size=8).to(device)\n",
    "\n",
    "# 미입고 기간 예측용 임베딩\n",
    "train_delay_encodings = encode_data(X_train_delay_text)\n",
    "val_delay_encodings = encode_data(X_val_delay_text)\n",
    "test_delay_encodings = encode_data(X_test_delay_text)\n",
    "\n",
    "train_delay_embeddings = get_embeddings_batchwise(train_delay_encodings, bert_model, batch_size=8).to(device)\n",
    "val_delay_embeddings = get_embeddings_batchwise(val_delay_encodings, bert_model, batch_size=8).to(device)\n",
    "test_delay_embeddings = get_embeddings_batchwise(test_delay_encodings, bert_model, batch_size=8).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb2744c-4f02-4a6b-85fa-58bb82e4bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 피처 (화폐 정보 등)를 임베딩과 결합\n",
    "train_leadtime_input = torch.cat((train_leadtime_embeddings.to(device), torch.tensor(X_train_leadtime_features.values, dtype=torch.float).to(device)), dim=1)\n",
    "val_leadtime_input = torch.cat((val_leadtime_embeddings.to(device), torch.tensor(X_val_leadtime_features.values, dtype=torch.float).to(device)), dim=1)\n",
    "test_leadtime_input = torch.cat((test_leadtime_embeddings.to(device), torch.tensor(X_test_leadtime_features.values, dtype=torch.float).to(device)), dim=1)\n",
    "\n",
    "train_delay_input = torch.cat((train_delay_embeddings.to(device), torch.tensor(X_train_delay_features.values, dtype=torch.float).to(device)), dim=1)\n",
    "val_delay_input = torch.cat((val_delay_embeddings.to(device), torch.tensor(X_val_delay_features.values, dtype=torch.float).to(device)), dim=1)\n",
    "test_delay_input = torch.cat((test_delay_embeddings.to(device), torch.tensor(X_test_delay_features.values, dtype=torch.float).to(device)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8c56221-cc4a-4add-b262-303abbd4a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_leadtime과 y_train_delay를 텐서로 변환\n",
    "y_train_leadtime_tensor = torch.tensor(y_train_leadtime.values.astype(float), dtype=torch.float).to(device)\n",
    "y_train_delay_tensor = torch.tensor(y_train_delay.values.astype(int), dtype=torch.long).to(device)\n",
    "\n",
    "# y_val과 y_test도 마찬가지로 변환\n",
    "y_val_leadtime_tensor = torch.tensor(y_val_leadtime.values.astype(float), dtype=torch.float).to(device)\n",
    "y_val_delay_tensor = torch.tensor(y_val_delay.values.astype(int), dtype=torch.long).to(device)\n",
    "\n",
    "y_test_leadtime_tensor = torch.tensor(y_test_leadtime.values.astype(float), dtype=torch.float).to(device)\n",
    "y_test_delay_tensor = torch.tensor(y_test_delay.values.astype(int), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f9f5ee9-33b0-4a4d-ab74-cf5910d76043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape (Leadtime): torch.Size([17041, 772])\n",
      "Train target shape (Leadtime): torch.Size([17041])\n",
      "Train input shape (Delay): torch.Size([1296, 772])\n",
      "Train target shape (Delay): torch.Size([1296])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train input shape (Leadtime): {train_leadtime_input.shape}\")\n",
    "print(f\"Train target shape (Leadtime): {y_train_leadtime_tensor.shape}\")\n",
    "print(f\"Train input shape (Delay): {train_delay_input.shape}\")\n",
    "print(f\"Train target shape (Delay): {y_train_delay_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "846139f4-d922-404c-8107-38852c79451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_regression = nn.Linear(hidden_dim, 1)  # 리드타임 회귀\n",
    "        self.fc_classification = nn.Linear(hidden_dim, 4)  # 미입고 기간 분류\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        regression_output = self.fc_regression(x)\n",
    "        classification_output = self.fc_classification(x)\n",
    "        return regression_output, classification_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e45944b-03d2-4004-a013-fdc902370d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_leadtime_input.shape[1]\n",
    "hidden_dim = 128\n",
    "num_classes = 4\n",
    "\n",
    "model = MultiOutputModel(input_dim=input_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a94a8cd1-0bec-4f19-a9be-473ad7aebf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_regression = torch.nn.MSELoss()  # 리드타임 회귀\n",
    "loss_fn_classification = torch.nn.CrossEntropyLoss()  # 미입고 기간 분류\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dfb62bd-8fe4-409d-b379-ff1653bd979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리드타임 학습\n",
    "def train_leadtime_model(model, train_input, target_regression, optimizer, device):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_input = train_input.to(device)\n",
    "    target_regression = target_regression.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    regression_output, _ = model(train_input)  # 미입고 분류는 무시하고 리드타임만 학습\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_regression = loss_fn_regression(regression_output, target_regression)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss_regression.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_regression.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "990b80c9-3ad7-4d96-b4f5-6250a326056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미입고 기간 학습\n",
    "def train_delay_model(model, train_input, target_classification, optimizer, device):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_input = train_input.to(device)\n",
    "    target_classification = target_classification.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    _, classification_output = model(train_input)  # 리드타임은 무시하고 미입고 기간만 학습\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_classification = loss_fn_classification(classification_output, target_classification)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss_classification.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_classification.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "880a1e18-0b08-4b45-ae6d-57d16689f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, val_input, val_target_regression, val_target_classification, device):\n",
    "    model.eval()\n",
    "    \n",
    "    val_input = val_input.to(device)\n",
    "    val_target_regression = val_target_regression.to(device)\n",
    "    val_target_classification = val_target_classification.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        regression_output, classification_output = model(val_input)\n",
    "    \n",
    "    # 리드타임 회귀 손실 및 평가 지표 계산\n",
    "    val_loss_regression = loss_fn_regression(regression_output, val_target_regression)\n",
    "    mae = mean_absolute_error(val_target_regression.cpu().numpy(), regression_output.cpu().numpy())\n",
    "    rmse = mean_squared_error(val_target_regression.cpu().numpy(), regression_output.cpu().numpy(), squared=False)\n",
    "    \n",
    "    # 미입고 기간 분류 손실 및 평가 지표 계산\n",
    "    val_loss_classification = loss_fn_classification(classification_output, val_target_classification)\n",
    "    acc = accuracy_score(val_target_classification.cpu().numpy(), classification_output.argmax(dim=1).cpu().numpy())\n",
    "    f1 = f1_score(val_target_classification.cpu().numpy(), classification_output.argmax(dim=1).cpu().numpy(), average='weighted')\n",
    "    \n",
    "    total_loss = val_loss_regression.item() + val_loss_classification.item()\n",
    "    \n",
    "    print(f\"Validation Loss: {total_loss:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f72322f-7b3f-4095-8311-3de9fe139191",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 65.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 리드타임 데이터 학습\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     train_loss_leadtime \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_leadtime_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_leadtime_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_leadtime_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 미입고 기간 데이터 학습\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     train_loss_delay \u001b[38;5;241m=\u001b[39m train_delay_model(model, train_delay_input, y_train_delay_tensor, optimizer, device)\n",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m, in \u001b[0;36mtrain_leadtime_model\u001b[1;34m(model, train_input, target_regression, optimizer, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m regression_output, _ \u001b[38;5;241m=\u001b[39m model(train_input)  \u001b[38;5;66;03m# 미입고 분류는 무시하고 리드타임만 학습\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m loss_regression \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregression_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_regression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss_regression\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ship\\Lib\\site-packages\\torch\\nn\\functional.py:3384\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3381\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3383\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 65.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 학습 및 평가 실행\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # 리드타임 데이터 학습\n",
    "    train_loss_leadtime = train_leadtime_model(model, train_leadtime_input, y_train_leadtime_tensor, optimizer, device)\n",
    "    \n",
    "    # 미입고 기간 데이터 학습\n",
    "    train_loss_delay = train_delay_model(model, train_delay_input, y_train_delay_tensor, optimizer, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss (Leadtime): {train_loss_leadtime:.4f}, Train Loss (Delay): {train_loss_delay:.4f}\")\n",
    "    \n",
    "    # 평가\n",
    "    val_loss, val_mae, val_rmse, val_acc, val_f1 = evaluate_model(model, val_leadtime_input, y_val_leadtime_tensor, y_val_delay_tensor, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, Accuracy: {val_acc:.4f}, F1-Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df478ed-eddf-473e-87ac-b082e3c22700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_data, device):\n",
    "    model.eval()  # 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        regression_output, classification_output = model(input_data)\n",
    "    return regression_output, classification_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97b907-6464-4631-9151-f2351a2d3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 코사인 유사도 계산 함수\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2, dim=1)\n",
    "\n",
    "# 최종 예측 함수: 임베딩 유사도를 기준으로 더 신뢰할 수 있는 예측을 선택\n",
    "def predict_with_embedding_similarity(model, leadtime_input, delay_input, leadtime_embedding, delay_embedding):\n",
    "    # 모델을 통해 리드타임과 미입고 기간 예측\n",
    "    leadtime_pred, _ = model(leadtime_input)\n",
    "    _, delay_pred = model(delay_input)\n",
    "\n",
    "    # 리드타임 예측과 미입고 기간 예측의 임베딩 유사도 계산\n",
    "    leadtime_similarity = cosine_similarity(leadtime_input, leadtime_embedding)\n",
    "    delay_similarity = cosine_similarity(delay_input, delay_embedding)\n",
    "\n",
    "    # 유사도를 비교하여 더 높은 쪽의 예측을 선택\n",
    "    if torch.mean(leadtime_similarity) > torch.mean(delay_similarity):\n",
    "        return leadtime_pred, \"Leadtime prediction\"\n",
    "    else:\n",
    "        return delay_pred, \"Delay prediction\"\n",
    "\n",
    "# 예측 예시 (train_leadtime_input, train_delay_input는 입력 데이터)\n",
    "final_prediction, chosen_model = predict_with_embedding_similarity(\n",
    "    model, train_leadtime_input, train_delay_input, train_leadtime_embeddings, train_delay_embeddings\n",
    ")\n",
    "\n",
    "print(f\"Chosen Model: {chosen_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ship)",
   "language": "python",
   "name": "ship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
